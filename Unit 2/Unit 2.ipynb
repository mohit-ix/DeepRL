{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d691da8-9312-4f3d-b922-cddc727ac42c",
   "metadata": {},
   "source": [
    "# Unit 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddb58d8-e394-4a2a-832f-f2bfc765dfca",
   "metadata": {},
   "source": [
    "## Agent Anatomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8f6f57-26de-4293-9902-8e7224602d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6019df3b-12ea-4819-b399-20c703073993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a class for Enviroment\n",
    "class Environment:\n",
    "    # initiating the class with total set of moves agent can take\n",
    "    def __init__(self):\n",
    "        self.steps_left = 10\n",
    "        \n",
    "    # observation indicates the frame\n",
    "    def get_observation(self) -> List[float]:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "    \n",
    "    # action indicates the move taken according to the observation\n",
    "    def get_actions(self) -> List[int]:\n",
    "        return [0, 1]\n",
    "    \n",
    "    # indication when environment is complete\n",
    "    def is_done(self) -> bool:\n",
    "        return self.steps_left == 0\n",
    "    \n",
    "    # receiving a random action to take\n",
    "    def action(self, action:int) ->float:\n",
    "        if self.is_done():\n",
    "            raise Exception(\"Game is over\")\n",
    "        self.steps_left -= 1\n",
    "        return random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c20e1536-4c4a-4c2b-b777-f5b72d4c416d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a class for Agent\n",
    "class Agent:\n",
    "    # initalizing class with 0 reward\n",
    "    def __init__(self):\n",
    "        self.total_reward = 0.0\n",
    "        \n",
    "    # getting the observation and action from environemnt and stepping it\n",
    "    def step(self, env: Environment):\n",
    "        current_obs = env.get_observation()\n",
    "        actions = env.get_actions()\n",
    "        reward = env.action(random.choice(actions))\n",
    "        self.total_reward += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0779bb-b39a-4e73-a455-7b7d3899586a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward got: 4.4392\n"
     ]
    }
   ],
   "source": [
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "while not env.is_done():\n",
    "    agent.step(env)\n",
    "    \n",
    "print(\"Total reward got: %.4f\" % agent.total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb613fff-348a-47e2-8490-1428430935b3",
   "metadata": {},
   "source": [
    "## Cartpole Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea2b3461-9916-41d1-88bf-967da01eb84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87121ab7-b74e-45d7-98ed-b58e869608fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode done in 22 steps, total reward 22.00\n"
     ]
    }
   ],
   "source": [
    "# Loading the CartPole-vo through gym \n",
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "total_reward = 0.0\n",
    "total_steps = 0\n",
    "obs = env.reset()\n",
    "\n",
    "# getting the action and step in environment until the game is over\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    total_steps += 1\n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "print(\"Episode done in %d steps, total reward %.2f\" % (\n",
    "    total_steps, total_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801fd539-867d-43de-8114-320d3253210b",
   "metadata": {},
   "source": [
    "# Random Action Wrapper\n",
    "Wrapper is the adding additional logics or set of rules, like preprocessing and changing image of frame so that agent can process it bettor, to an existing gym environment for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96912e0d-4a19-4bfa-9cf0-21aa35b0210f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from typing import TypeVar\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de070d64-39cc-4b78-8566-64080a89fabd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing a datatype named Action\n",
    "Action = TypeVar('Action')\n",
    "\n",
    "# Creating a class for Random Action Wrapper\n",
    "class RandomActionWrapper(gym.ActionWrapper):\n",
    "    # introducing epsilon function\n",
    "    def __init__(self, env, epsilon=0.1):\n",
    "        super(RandomActionWrapper, self).__init__(env)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    # for every step action function is called it generated random no. and compare it with epsilon\n",
    "    def action(self, action: Action) -> Action:\n",
    "        if random.random() < self.epsilon:\n",
    "            print(\"Random!\")\n",
    "            return self.env.action_space.sample()\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ee875e4-3e9e-483a-a695-717e0c1efcea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random!\n",
      "Random!\n",
      "Reward got: 10.00\n"
     ]
    }
   ],
   "source": [
    "env = RandomActionWrapper(gym.make(\"CartPole-v0\"))\n",
    "\n",
    "obs = env.reset()\n",
    "total_reward = 0.0\n",
    "\n",
    "while True:\n",
    "    obs, reward, done, _ = env.step(0)\n",
    "    total_reward += reward\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(\"Reward got: %.2f\" % total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af09f62f-f57d-419f-8675-357bba683ad9",
   "metadata": {},
   "source": [
    "As we can see, every thing is same except for initializing for environment. But still on the call of step function, it works as instructed iin the action fuction of RandomActionWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f08570-a82a-4592-9302-02d14d0a7c2f",
   "metadata": {},
   "source": [
    "# Cartpole Random Monitor\n",
    "Monitoring is the process of recording the performance of agent and saving in a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cdac2af-82e7-4171-b15e-c0e2758a101f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "421d528d-815c-42bf-aefd-b6262fa961c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode done in 23 steps, total reward 23.00\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "env = gym.wrappers.Monitor(env, \"recording\")\n",
    "\n",
    "total_reward = 0.0\n",
    "total_steps = 0\n",
    "obs = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    total_steps += 1\n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "print(\"Episode done in %d steps, total reward %.2f\" % (\n",
    "    total_steps, total_reward))\n",
    "env.close()\n",
    "env.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c6b6a-1812-40cb-abf8-d2ba1fbb173f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprl",
   "language": "python",
   "name": "deeprl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226088fa-fd7a-485a-9310-79c792717c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import ptan\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from ignite.engine import Engine\n",
    "\n",
    "from lib import common, dqn_extra\n",
    "\n",
    "NAME = \"06_dueling\"\n",
    "STATES_TO_EVALUATE = 1000\n",
    "EVAL_EVERY_FRAME = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "927d7cc2-4060-4e0c-ac7d-24d0961c8e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_states(states, net, device, engine):\n",
    "    s_v = torch.tensor(states).to(device)\n",
    "    adv, val = net.adv_val(s_v)\n",
    "    engine.state.metrics['adv'] = adv.mean().item()\n",
    "    engine.state.metrics['val'] = val.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "372657b6-8390-47d7-972c-69b5127de80b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[123, 151010689]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(common.SEED)\n",
    "torch.manual_seed(common.SEED)\n",
    "params = common.HYPERPARAMS['pong']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make(\"PongNoFrameskip-v4\")\n",
    "env = ptan.common.wrappers.wrap_dqn(env)\n",
    "env.seed(common.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db9113fb-fe86-4960-acbc-c4cec8daa285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = dqn_extra.DuelingDQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "\n",
    "tgt_net = ptan.agent.TargetNet(net)\n",
    "selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params.epsilon_start)\n",
    "epsilon_tracker = common.EpsilonTracker(selector, params)\n",
    "agent = ptan.agent.DQNAgent(net, selector, device = device)\n",
    "\n",
    "exp_source = ptan.experience.ExperienceSourceFirstLast(\n",
    "    env, agent, gamma=params.gamma)\n",
    "buffer = ptan.experience.ExperienceReplayBuffer(\n",
    "    exp_source, buffer_size=params.replay_size)\n",
    "optimizer = optim.Adam(net.parameters(), lr=params.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ef725c4-9d48-44fb-87d8-803bf8a9db49",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: reward=-19, steps=929, speed=0.0 f/s, elapsed=0:01:00\n",
      "Episode 2: reward=-21, steps=968, speed=0.0 f/s, elapsed=0:01:00\n",
      "Episode 3: reward=-19, steps=1020, speed=0.0 f/s, elapsed=0:01:00\n",
      "Episode 4: reward=-20, steps=896, speed=0.0 f/s, elapsed=0:01:00\n",
      "Episode 5: reward=-19, steps=1066, speed=0.0 f/s, elapsed=0:01:00\n",
      "Episode 6: reward=-19, steps=935, speed=0.0 f/s, elapsed=0:01:00\n",
      "Episode 7: reward=-21, steps=760, speed=0.0 f/s, elapsed=0:01:00\n",
      "Episode 8: reward=-21, steps=847, speed=0.0 f/s, elapsed=0:01:00\n",
      "Episode 9: reward=-19, steps=969, speed=0.0 f/s, elapsed=0:01:00\n",
      "Episode 10: reward=-21, steps=878, speed=0.0 f/s, elapsed=0:01:00\n",
      "Episode 11: reward=-21, steps=944, speed=0.0 f/s, elapsed=0:01:00\n",
      "Episode 12: reward=-21, steps=759, speed=60.0 f/s, elapsed=0:01:11\n",
      "Episode 13: reward=-21, steps=819, speed=60.0 f/s, elapsed=0:01:24\n",
      "Episode 14: reward=-20, steps=938, speed=60.1 f/s, elapsed=0:01:39\n",
      "Episode 15: reward=-18, steps=1224, speed=60.1 f/s, elapsed=0:01:59\n",
      "Episode 16: reward=-21, steps=907, speed=60.1 f/s, elapsed=0:02:13\n",
      "Episode 17: reward=-20, steps=894, speed=60.2 f/s, elapsed=0:02:28\n",
      "Episode 18: reward=-20, steps=922, speed=60.2 f/s, elapsed=0:02:42\n",
      "Episode 19: reward=-21, steps=952, speed=60.3 f/s, elapsed=0:02:58\n",
      "Episode 20: reward=-18, steps=1308, speed=60.3 f/s, elapsed=0:03:19\n",
      "Episode 21: reward=-21, steps=1025, speed=60.3 f/s, elapsed=0:03:35\n",
      "Episode 22: reward=-20, steps=1047, speed=60.4 f/s, elapsed=0:03:52\n",
      "Episode 23: reward=-19, steps=1071, speed=60.4 f/s, elapsed=0:04:09\n",
      "Episode 24: reward=-21, steps=814, speed=60.4 f/s, elapsed=0:04:23\n",
      "Episode 25: reward=-21, steps=844, speed=60.4 f/s, elapsed=0:04:36\n",
      "Episode 26: reward=-21, steps=821, speed=60.5 f/s, elapsed=0:04:50\n",
      "Episode 27: reward=-20, steps=942, speed=60.5 f/s, elapsed=0:05:05\n",
      "Episode 28: reward=-20, steps=893, speed=60.5 f/s, elapsed=0:05:19\n",
      "Episode 29: reward=-20, steps=913, speed=60.5 f/s, elapsed=0:05:34\n",
      "Episode 30: reward=-21, steps=818, speed=60.5 f/s, elapsed=0:05:48\n",
      "Episode 31: reward=-20, steps=828, speed=60.6 f/s, elapsed=0:06:01\n",
      "Episode 32: reward=-18, steps=1177, speed=60.6 f/s, elapsed=0:06:20\n",
      "Episode 33: reward=-21, steps=916, speed=60.6 f/s, elapsed=0:06:35\n",
      "Episode 34: reward=-21, steps=903, speed=60.7 f/s, elapsed=0:06:49\n",
      "Episode 35: reward=-21, steps=1024, speed=60.7 f/s, elapsed=0:07:06\n",
      "Episode 36: reward=-20, steps=895, speed=60.7 f/s, elapsed=0:07:20\n",
      "Episode 37: reward=-21, steps=759, speed=60.7 f/s, elapsed=0:07:33\n",
      "Episode 38: reward=-21, steps=938, speed=60.8 f/s, elapsed=0:07:48\n",
      "Episode 39: reward=-20, steps=915, speed=60.8 f/s, elapsed=0:08:03\n",
      "Episode 40: reward=-21, steps=822, speed=60.8 f/s, elapsed=0:08:16\n",
      "Episode 41: reward=-19, steps=1101, speed=60.8 f/s, elapsed=0:08:34\n",
      "Episode 42: reward=-20, steps=974, speed=60.8 f/s, elapsed=0:08:49\n",
      "Episode 43: reward=-21, steps=777, speed=60.9 f/s, elapsed=0:09:02\n",
      "Episode 44: reward=-21, steps=761, speed=60.9 f/s, elapsed=0:09:14\n",
      "Episode 45: reward=-19, steps=975, speed=60.9 f/s, elapsed=0:09:30\n",
      "Episode 46: reward=-21, steps=807, speed=60.9 f/s, elapsed=0:09:43\n",
      "Episode 47: reward=-21, steps=936, speed=60.9 f/s, elapsed=0:09:58\n",
      "Episode 48: reward=-19, steps=916, speed=60.9 f/s, elapsed=0:10:13\n",
      "Episode 49: reward=-21, steps=788, speed=60.9 f/s, elapsed=0:10:26\n",
      "Episode 50: reward=-20, steps=964, speed=60.9 f/s, elapsed=0:10:42\n",
      "Episode 51: reward=-19, steps=990, speed=61.0 f/s, elapsed=0:10:58\n",
      "Episode 52: reward=-20, steps=929, speed=61.0 f/s, elapsed=0:11:13\n",
      "Episode 53: reward=-20, steps=852, speed=61.0 f/s, elapsed=0:11:27\n",
      "Episode 54: reward=-21, steps=819, speed=61.0 f/s, elapsed=0:11:40\n",
      "Episode 55: reward=-20, steps=833, speed=61.0 f/s, elapsed=0:11:54\n",
      "Episode 56: reward=-19, steps=1013, speed=61.0 f/s, elapsed=0:12:10\n",
      "Episode 57: reward=-20, steps=890, speed=61.0 f/s, elapsed=0:12:24\n",
      "Episode 58: reward=-20, steps=891, speed=61.1 f/s, elapsed=0:12:39\n",
      "Episode 59: reward=-21, steps=787, speed=61.1 f/s, elapsed=0:12:51\n",
      "Episode 60: reward=-20, steps=927, speed=61.1 f/s, elapsed=0:13:07\n",
      "Episode 61: reward=-19, steps=1082, speed=61.1 f/s, elapsed=0:13:24\n",
      "Episode 62: reward=-19, steps=1040, speed=61.1 f/s, elapsed=0:13:41\n",
      "Episode 63: reward=-21, steps=879, speed=61.1 f/s, elapsed=0:13:55\n",
      "Episode 64: reward=-21, steps=835, speed=61.1 f/s, elapsed=0:14:09\n",
      "Episode 65: reward=-19, steps=956, speed=61.1 f/s, elapsed=0:14:24\n",
      "Episode 66: reward=-21, steps=808, speed=61.1 f/s, elapsed=0:14:37\n",
      "Episode 67: reward=-20, steps=973, speed=61.1 f/s, elapsed=0:14:53\n",
      "Episode 68: reward=-19, steps=1029, speed=61.2 f/s, elapsed=0:15:10\n",
      "Episode 69: reward=-20, steps=1066, speed=61.2 f/s, elapsed=0:15:27\n",
      "Episode 70: reward=-21, steps=777, speed=61.2 f/s, elapsed=0:15:40\n",
      "Episode 71: reward=-20, steps=937, speed=61.2 f/s, elapsed=0:15:55\n",
      "Episode 72: reward=-19, steps=1173, speed=61.2 f/s, elapsed=0:16:14\n",
      "Episode 73: reward=-20, steps=965, speed=61.2 f/s, elapsed=0:16:30\n",
      "Episode 74: reward=-21, steps=823, speed=61.2 f/s, elapsed=0:16:43\n",
      "Episode 75: reward=-20, steps=864, speed=61.2 f/s, elapsed=0:16:57\n",
      "Episode 76: reward=-20, steps=893, speed=61.2 f/s, elapsed=0:17:12\n",
      "Episode 77: reward=-20, steps=1002, speed=61.2 f/s, elapsed=0:17:28\n",
      "Episode 78: reward=-19, steps=1028, speed=61.2 f/s, elapsed=0:17:45\n",
      "Episode 79: reward=-21, steps=819, speed=61.2 f/s, elapsed=0:17:59\n",
      "Episode 80: reward=-21, steps=959, speed=61.2 f/s, elapsed=0:18:14\n",
      "Episode 81: reward=-21, steps=844, speed=61.2 f/s, elapsed=0:18:28\n",
      "Episode 82: reward=-20, steps=895, speed=61.2 f/s, elapsed=0:18:43\n",
      "Episode 83: reward=-21, steps=815, speed=61.2 f/s, elapsed=0:18:56\n",
      "Episode 84: reward=-21, steps=865, speed=61.2 f/s, elapsed=0:19:10\n",
      "Episode 85: reward=-21, steps=847, speed=61.2 f/s, elapsed=0:19:24\n",
      "Episode 86: reward=-21, steps=835, speed=61.2 f/s, elapsed=0:19:38\n",
      "Episode 87: reward=-21, steps=822, speed=61.2 f/s, elapsed=0:19:51\n",
      "Episode 88: reward=-21, steps=784, speed=61.2 f/s, elapsed=0:20:04\n",
      "Episode 89: reward=-21, steps=786, speed=61.2 f/s, elapsed=0:20:17\n",
      "Episode 90: reward=-20, steps=1020, speed=61.2 f/s, elapsed=0:20:34\n",
      "Episode 91: reward=-19, steps=944, speed=61.2 f/s, elapsed=0:20:49\n",
      "Episode 92: reward=-21, steps=905, speed=61.1 f/s, elapsed=0:21:04\n",
      "Episode 93: reward=-20, steps=953, speed=61.1 f/s, elapsed=0:21:20\n",
      "Episode 94: reward=-19, steps=934, speed=61.1 f/s, elapsed=0:21:35\n",
      "Episode 95: reward=-20, steps=855, speed=61.1 f/s, elapsed=0:21:49\n",
      "Episode 96: reward=-20, steps=895, speed=61.1 f/s, elapsed=0:22:04\n",
      "Episode 97: reward=-20, steps=992, speed=61.1 f/s, elapsed=0:22:20\n",
      "Episode 98: reward=-21, steps=808, speed=61.1 f/s, elapsed=0:22:34\n",
      "Episode 99: reward=-20, steps=829, speed=61.1 f/s, elapsed=0:22:47\n",
      "Episode 100: reward=-20, steps=909, speed=61.1 f/s, elapsed=0:23:02\n",
      "Episode 101: reward=-19, steps=964, speed=61.1 f/s, elapsed=0:23:18\n",
      "Episode 102: reward=-20, steps=1156, speed=61.1 f/s, elapsed=0:23:37\n",
      "Episode 103: reward=-21, steps=822, speed=61.1 f/s, elapsed=0:23:51\n",
      "Episode 104: reward=-20, steps=951, speed=61.1 f/s, elapsed=0:24:06\n",
      "Episode 105: reward=-20, steps=930, speed=61.1 f/s, elapsed=0:24:21\n",
      "Episode 106: reward=-21, steps=862, speed=61.1 f/s, elapsed=0:24:36\n",
      "Episode 107: reward=-21, steps=849, speed=61.1 f/s, elapsed=0:24:50\n",
      "Episode 108: reward=-21, steps=981, speed=61.0 f/s, elapsed=0:25:06\n",
      "Episode 109: reward=-20, steps=913, speed=61.0 f/s, elapsed=0:25:21\n",
      "Episode 110: reward=-21, steps=937, speed=61.0 f/s, elapsed=0:25:36\n",
      "Episode 111: reward=-21, steps=779, speed=61.0 f/s, elapsed=0:25:49\n",
      "Episode 112: reward=-21, steps=784, speed=61.0 f/s, elapsed=0:26:02\n",
      "Episode 113: reward=-21, steps=755, speed=61.0 f/s, elapsed=0:26:15\n",
      "Episode 114: reward=-19, steps=1054, speed=61.0 f/s, elapsed=0:26:32\n",
      "Episode 115: reward=-21, steps=971, speed=61.0 f/s, elapsed=0:26:48\n",
      "Episode 116: reward=-21, steps=908, speed=61.0 f/s, elapsed=0:27:02\n",
      "Episode 117: reward=-21, steps=867, speed=61.0 f/s, elapsed=0:27:17\n",
      "Episode 118: reward=-20, steps=941, speed=61.0 f/s, elapsed=0:27:32\n",
      "Episode 119: reward=-20, steps=834, speed=61.0 f/s, elapsed=0:27:46\n",
      "Episode 120: reward=-21, steps=787, speed=61.0 f/s, elapsed=0:27:59\n",
      "Episode 121: reward=-20, steps=879, speed=61.0 f/s, elapsed=0:28:13\n",
      "Episode 122: reward=-21, steps=758, speed=61.0 f/s, elapsed=0:28:26\n",
      "Episode 123: reward=-20, steps=1020, speed=61.0 f/s, elapsed=0:28:42\n",
      "Episode 124: reward=-21, steps=760, speed=61.0 f/s, elapsed=0:28:55\n",
      "Episode 125: reward=-21, steps=778, speed=61.0 f/s, elapsed=0:29:08\n",
      "Episode 126: reward=-21, steps=821, speed=61.0 f/s, elapsed=0:29:21\n",
      "Episode 127: reward=-20, steps=965, speed=61.0 f/s, elapsed=0:29:37\n",
      "Episode 128: reward=-21, steps=822, speed=61.0 f/s, elapsed=0:29:51\n",
      "Episode 129: reward=-21, steps=879, speed=61.0 f/s, elapsed=0:30:05\n",
      "Episode 130: reward=-21, steps=966, speed=61.0 f/s, elapsed=0:30:21\n",
      "Episode 131: reward=-21, steps=998, speed=61.0 f/s, elapsed=0:30:37\n",
      "Episode 132: reward=-21, steps=761, speed=61.0 f/s, elapsed=0:30:50\n",
      "Episode 133: reward=-21, steps=876, speed=61.0 f/s, elapsed=0:31:04\n",
      "Episode 134: reward=-20, steps=858, speed=61.0 f/s, elapsed=0:31:18\n",
      "Episode 135: reward=-20, steps=852, speed=61.0 f/s, elapsed=0:31:32\n",
      "Episode 136: reward=-21, steps=820, speed=61.0 f/s, elapsed=0:31:45\n",
      "Episode 137: reward=-21, steps=878, speed=61.0 f/s, elapsed=0:31:59\n",
      "Episode 138: reward=-21, steps=879, speed=61.0 f/s, elapsed=0:32:14\n",
      "Episode 139: reward=-21, steps=756, speed=61.0 f/s, elapsed=0:32:27\n",
      "Episode 140: reward=-20, steps=840, speed=61.0 f/s, elapsed=0:32:41\n",
      "Episode 141: reward=-21, steps=788, speed=61.0 f/s, elapsed=0:32:54\n",
      "Episode 142: reward=-21, steps=822, speed=61.0 f/s, elapsed=0:33:07\n",
      "Episode 143: reward=-21, steps=784, speed=61.0 f/s, elapsed=0:33:20\n",
      "Episode 144: reward=-20, steps=835, speed=60.9 f/s, elapsed=0:33:34\n",
      "Episode 145: reward=-21, steps=972, speed=61.0 f/s, elapsed=0:33:50\n",
      "Episode 146: reward=-20, steps=975, speed=61.0 f/s, elapsed=0:34:06\n",
      "Episode 147: reward=-21, steps=835, speed=61.0 f/s, elapsed=0:34:19\n",
      "Episode 148: reward=-20, steps=974, speed=61.0 f/s, elapsed=0:34:35\n",
      "Episode 149: reward=-20, steps=907, speed=61.0 f/s, elapsed=0:34:50\n",
      "Episode 150: reward=-21, steps=902, speed=61.0 f/s, elapsed=0:35:05\n",
      "Episode 151: reward=-21, steps=818, speed=61.0 f/s, elapsed=0:35:18\n",
      "Episode 152: reward=-21, steps=925, speed=61.0 f/s, elapsed=0:35:33\n",
      "Episode 153: reward=-21, steps=808, speed=61.0 f/s, elapsed=0:35:46\n",
      "Episode 154: reward=-20, steps=867, speed=61.0 f/s, elapsed=0:36:00\n",
      "Episode 155: reward=-21, steps=785, speed=61.0 f/s, elapsed=0:36:13\n",
      "Episode 156: reward=-21, steps=879, speed=61.0 f/s, elapsed=0:36:28\n",
      "Episode 157: reward=-21, steps=816, speed=61.0 f/s, elapsed=0:36:41\n",
      "Episode 158: reward=-21, steps=879, speed=61.0 f/s, elapsed=0:36:56\n",
      "Episode 159: reward=-21, steps=844, speed=61.0 f/s, elapsed=0:37:09\n",
      "Episode 160: reward=-20, steps=839, speed=61.0 f/s, elapsed=0:37:23\n",
      "Episode 161: reward=-21, steps=774, speed=60.9 f/s, elapsed=0:37:37\n",
      "Episode 162: reward=-20, steps=958, speed=60.9 f/s, elapsed=0:37:53\n",
      "Episode 163: reward=-21, steps=906, speed=60.9 f/s, elapsed=0:38:08\n",
      "Episode 164: reward=-21, steps=820, speed=60.9 f/s, elapsed=0:38:21\n",
      "Episode 165: reward=-20, steps=1015, speed=60.9 f/s, elapsed=0:38:38\n",
      "Episode 166: reward=-21, steps=762, speed=60.9 f/s, elapsed=0:38:50\n",
      "Episode 167: reward=-21, steps=821, speed=60.9 f/s, elapsed=0:39:04\n",
      "Episode 168: reward=-21, steps=755, speed=60.9 f/s, elapsed=0:39:16\n",
      "Episode 169: reward=-20, steps=962, speed=60.9 f/s, elapsed=0:39:32\n",
      "Episode 170: reward=-21, steps=847, speed=60.9 f/s, elapsed=0:39:46\n",
      "Episode 171: reward=-20, steps=834, speed=60.9 f/s, elapsed=0:40:00\n",
      "Episode 172: reward=-21, steps=778, speed=60.9 f/s, elapsed=0:40:13\n",
      "Episode 173: reward=-21, steps=1002, speed=60.9 f/s, elapsed=0:40:29\n",
      "Episode 174: reward=-20, steps=1016, speed=60.9 f/s, elapsed=0:40:46\n",
      "Episode 175: reward=-20, steps=876, speed=60.9 f/s, elapsed=0:41:00\n",
      "Episode 176: reward=-20, steps=838, speed=60.8 f/s, elapsed=0:41:14\n",
      "Episode 177: reward=-21, steps=817, speed=60.8 f/s, elapsed=0:41:28\n",
      "Episode 178: reward=-21, steps=761, speed=60.8 f/s, elapsed=0:41:40\n",
      "Episode 179: reward=-21, steps=846, speed=60.8 f/s, elapsed=0:41:54\n",
      "Episode 180: reward=-21, steps=817, speed=60.8 f/s, elapsed=0:42:08\n",
      "Episode 181: reward=-21, steps=820, speed=60.8 f/s, elapsed=0:42:22\n",
      "Episode 182: reward=-21, steps=788, speed=60.8 f/s, elapsed=0:42:35\n",
      "Episode 183: reward=-21, steps=905, speed=60.8 f/s, elapsed=0:42:49\n",
      "Episode 184: reward=-21, steps=817, speed=60.8 f/s, elapsed=0:43:03\n",
      "Episode 185: reward=-19, steps=1011, speed=60.8 f/s, elapsed=0:43:20\n",
      "Episode 186: reward=-21, steps=845, speed=60.8 f/s, elapsed=0:43:33\n",
      "Episode 187: reward=-20, steps=921, speed=60.8 f/s, elapsed=0:43:48\n",
      "Episode 188: reward=-20, steps=944, speed=60.8 f/s, elapsed=0:44:04\n",
      "Episode 189: reward=-20, steps=834, speed=60.8 f/s, elapsed=0:44:18\n",
      "Episode 190: reward=-21, steps=937, speed=60.8 f/s, elapsed=0:44:33\n",
      "Episode 191: reward=-21, steps=910, speed=60.8 f/s, elapsed=0:44:48\n",
      "Episode 192: reward=-20, steps=981, speed=60.8 f/s, elapsed=0:45:04\n",
      "Episode 193: reward=-20, steps=958, speed=60.8 f/s, elapsed=0:45:20\n",
      "Episode 194: reward=-20, steps=1009, speed=60.8 f/s, elapsed=0:45:36\n",
      "Episode 195: reward=-20, steps=926, speed=60.8 f/s, elapsed=0:45:52\n",
      "Episode 196: reward=-20, steps=892, speed=60.8 f/s, elapsed=0:46:06\n",
      "Episode 197: reward=-21, steps=790, speed=60.8 f/s, elapsed=0:46:19\n",
      "Episode 198: reward=-21, steps=760, speed=60.8 f/s, elapsed=0:46:32\n",
      "Episode 199: reward=-21, steps=783, speed=60.8 f/s, elapsed=0:46:45\n",
      "Episode 200: reward=-20, steps=868, speed=60.8 f/s, elapsed=0:46:59\n",
      "Episode 201: reward=-20, steps=864, speed=60.8 f/s, elapsed=0:47:13\n",
      "Episode 202: reward=-21, steps=819, speed=60.8 f/s, elapsed=0:47:27\n",
      "Episode 203: reward=-20, steps=897, speed=60.8 f/s, elapsed=0:47:42\n",
      "Episode 204: reward=-20, steps=923, speed=60.8 f/s, elapsed=0:47:57\n",
      "Episode 205: reward=-20, steps=880, speed=60.8 f/s, elapsed=0:48:11\n",
      "Episode 206: reward=-21, steps=816, speed=60.8 f/s, elapsed=0:48:24\n",
      "Episode 207: reward=-21, steps=755, speed=60.8 f/s, elapsed=0:48:37\n",
      "Episode 208: reward=-21, steps=819, speed=60.8 f/s, elapsed=0:48:50\n",
      "Episode 209: reward=-21, steps=881, speed=60.8 f/s, elapsed=0:49:05\n",
      "Episode 210: reward=-20, steps=1076, speed=60.9 f/s, elapsed=0:49:22\n",
      "Episode 211: reward=-20, steps=942, speed=60.8 f/s, elapsed=0:49:38\n",
      "Episode 212: reward=-19, steps=960, speed=60.8 f/s, elapsed=0:49:54\n",
      "Episode 213: reward=-21, steps=847, speed=60.8 f/s, elapsed=0:50:08\n",
      "Episode 214: reward=-21, steps=1003, speed=60.8 f/s, elapsed=0:50:24\n",
      "Episode 215: reward=-21, steps=878, speed=60.8 f/s, elapsed=0:50:38\n",
      "Episode 216: reward=-20, steps=913, speed=60.8 f/s, elapsed=0:50:53\n",
      "Episode 217: reward=-21, steps=776, speed=60.8 f/s, elapsed=0:51:06\n",
      "Episode 218: reward=-20, steps=856, speed=60.8 f/s, elapsed=0:51:21\n",
      "Episode 219: reward=-21, steps=967, speed=60.8 f/s, elapsed=0:51:37\n",
      "Episode 220: reward=-21, steps=758, speed=60.8 f/s, elapsed=0:51:49\n",
      "Episode 221: reward=-21, steps=787, speed=60.8 f/s, elapsed=0:52:02\n",
      "Episode 222: reward=-21, steps=851, speed=60.8 f/s, elapsed=0:52:16\n",
      "Episode 223: reward=-21, steps=816, speed=60.8 f/s, elapsed=0:52:29\n",
      "Episode 224: reward=-21, steps=822, speed=60.8 f/s, elapsed=0:52:42\n",
      "Episode 225: reward=-21, steps=760, speed=60.8 f/s, elapsed=0:52:55\n",
      "Episode 226: reward=-20, steps=913, speed=60.8 f/s, elapsed=0:53:10\n",
      "Episode 227: reward=-21, steps=817, speed=60.8 f/s, elapsed=0:53:24\n",
      "Episode 228: reward=-21, steps=778, speed=60.8 f/s, elapsed=0:53:36\n",
      "Episode 229: reward=-21, steps=822, speed=60.8 f/s, elapsed=0:53:50\n",
      "Episode 230: reward=-21, steps=756, speed=60.8 f/s, elapsed=0:54:02\n",
      "Episode 231: reward=-21, steps=816, speed=60.8 f/s, elapsed=0:54:16\n",
      "Episode 232: reward=-21, steps=940, speed=60.8 f/s, elapsed=0:54:31\n",
      "Episode 233: reward=-20, steps=858, speed=60.8 f/s, elapsed=0:54:45\n",
      "Episode 234: reward=-21, steps=786, speed=60.8 f/s, elapsed=0:54:58\n",
      "Episode 235: reward=-21, steps=933, speed=60.8 f/s, elapsed=0:55:13\n",
      "Episode 236: reward=-20, steps=836, speed=60.8 f/s, elapsed=0:55:27\n",
      "Episode 237: reward=-21, steps=883, speed=60.8 f/s, elapsed=0:55:42\n",
      "Episode 238: reward=-20, steps=833, speed=60.8 f/s, elapsed=0:55:56\n",
      "Episode 239: reward=-21, steps=756, speed=60.8 f/s, elapsed=0:56:08\n",
      "Episode 240: reward=-21, steps=1068, speed=60.8 f/s, elapsed=0:56:26\n",
      "Episode 241: reward=-21, steps=817, speed=60.8 f/s, elapsed=0:56:39\n",
      "Episode 242: reward=-21, steps=940, speed=60.8 f/s, elapsed=0:56:55\n",
      "Episode 243: reward=-21, steps=938, speed=60.8 f/s, elapsed=0:57:10\n",
      "Episode 244: reward=-21, steps=788, speed=60.8 f/s, elapsed=0:57:23\n",
      "Episode 245: reward=-20, steps=939, speed=60.8 f/s, elapsed=0:57:38\n",
      "Episode 246: reward=-19, steps=912, speed=60.8 f/s, elapsed=0:57:53\n",
      "Episode 247: reward=-21, steps=761, speed=60.9 f/s, elapsed=0:58:05\n",
      "Episode 248: reward=-21, steps=778, speed=60.8 f/s, elapsed=0:58:18\n",
      "Episode 249: reward=-21, steps=813, speed=60.9 f/s, elapsed=0:58:31\n",
      "Episode 250: reward=-21, steps=998, speed=60.9 f/s, elapsed=0:58:48\n",
      "Episode 251: reward=-21, steps=996, speed=60.9 f/s, elapsed=0:59:04\n",
      "Episode 252: reward=-21, steps=779, speed=60.9 f/s, elapsed=0:59:17\n",
      "Episode 253: reward=-21, steps=815, speed=60.9 f/s, elapsed=0:59:31\n",
      "Episode 254: reward=-21, steps=817, speed=60.9 f/s, elapsed=0:59:44\n",
      "Episode 255: reward=-21, steps=762, speed=60.8 f/s, elapsed=0:59:57\n",
      "Episode 256: reward=-21, steps=808, speed=60.8 f/s, elapsed=1:00:10\n",
      "Episode 257: reward=-21, steps=871, speed=60.8 f/s, elapsed=1:00:24\n",
      "Episode 258: reward=-21, steps=758, speed=60.9 f/s, elapsed=1:00:36\n",
      "Episode 259: reward=-21, steps=880, speed=60.9 f/s, elapsed=1:00:51\n",
      "Episode 260: reward=-21, steps=823, speed=60.8 f/s, elapsed=1:01:05\n",
      "Episode 261: reward=-21, steps=818, speed=60.8 f/s, elapsed=1:01:18\n",
      "Episode 262: reward=-20, steps=910, speed=60.8 f/s, elapsed=1:01:33\n",
      "Episode 263: reward=-21, steps=840, speed=60.8 f/s, elapsed=1:01:47\n",
      "Episode 264: reward=-21, steps=818, speed=60.8 f/s, elapsed=1:02:00\n",
      "Episode 265: reward=-20, steps=1001, speed=60.8 f/s, elapsed=1:02:17\n",
      "Episode 266: reward=-20, steps=922, speed=60.9 f/s, elapsed=1:02:32\n",
      "Episode 267: reward=-21, steps=783, speed=60.9 f/s, elapsed=1:02:45\n",
      "Episode 268: reward=-21, steps=906, speed=60.9 f/s, elapsed=1:02:59\n",
      "Episode 269: reward=-19, steps=946, speed=60.8 f/s, elapsed=1:03:15\n",
      "Episode 270: reward=-21, steps=847, speed=60.8 f/s, elapsed=1:03:29\n",
      "Episode 271: reward=-20, steps=915, speed=60.9 f/s, elapsed=1:03:44\n",
      "Episode 272: reward=-21, steps=838, speed=60.9 f/s, elapsed=1:03:58\n",
      "Episode 273: reward=-21, steps=787, speed=60.9 f/s, elapsed=1:04:10\n",
      "Episode 274: reward=-20, steps=835, speed=60.9 f/s, elapsed=1:04:24\n",
      "Episode 275: reward=-19, steps=994, speed=60.9 f/s, elapsed=1:04:41\n",
      "Episode 276: reward=-21, steps=956, speed=60.9 f/s, elapsed=1:04:56\n",
      "Episode 277: reward=-21, steps=818, speed=60.9 f/s, elapsed=1:05:10\n",
      "Episode 278: reward=-20, steps=898, speed=60.9 f/s, elapsed=1:05:24\n",
      "Episode 279: reward=-20, steps=1051, speed=60.9 f/s, elapsed=1:05:42\n",
      "Episode 280: reward=-20, steps=886, speed=60.9 f/s, elapsed=1:05:56\n",
      "Episode 281: reward=-21, steps=822, speed=60.9 f/s, elapsed=1:06:09\n",
      "Episode 282: reward=-21, steps=909, speed=60.9 f/s, elapsed=1:06:24\n",
      "Episode 283: reward=-21, steps=787, speed=60.9 f/s, elapsed=1:06:37\n",
      "Episode 284: reward=-21, steps=816, speed=60.9 f/s, elapsed=1:06:51\n",
      "Episode 285: reward=-21, steps=779, speed=60.9 f/s, elapsed=1:07:04\n",
      "Episode 286: reward=-20, steps=916, speed=60.9 f/s, elapsed=1:07:19\n",
      "Episode 287: reward=-21, steps=847, speed=60.9 f/s, elapsed=1:07:32\n",
      "Episode 288: reward=-21, steps=779, speed=60.9 f/s, elapsed=1:07:45\n",
      "Episode 289: reward=-21, steps=995, speed=60.9 f/s, elapsed=1:08:01\n",
      "Episode 290: reward=-21, steps=900, speed=60.9 f/s, elapsed=1:08:16\n",
      "Episode 291: reward=-21, steps=822, speed=60.9 f/s, elapsed=1:08:30\n",
      "Episode 292: reward=-19, steps=1050, speed=60.9 f/s, elapsed=1:08:47\n",
      "Episode 293: reward=-21, steps=909, speed=60.9 f/s, elapsed=1:09:02\n",
      "Episode 294: reward=-21, steps=904, speed=60.9 f/s, elapsed=1:09:17\n",
      "Episode 295: reward=-21, steps=806, speed=60.9 f/s, elapsed=1:09:30\n",
      "Episode 296: reward=-21, steps=959, speed=60.9 f/s, elapsed=1:09:46\n",
      "Episode 297: reward=-21, steps=817, speed=60.9 f/s, elapsed=1:09:59\n",
      "Episode 298: reward=-20, steps=917, speed=60.9 f/s, elapsed=1:10:14\n",
      "Episode 299: reward=-21, steps=877, speed=60.9 f/s, elapsed=1:10:29\n",
      "Episode 300: reward=-20, steps=1138, speed=60.9 f/s, elapsed=1:10:47\n",
      "Episode 301: reward=-20, steps=923, speed=60.9 f/s, elapsed=1:11:03\n",
      "Episode 302: reward=-21, steps=777, speed=60.9 f/s, elapsed=1:11:15\n",
      "Episode 303: reward=-21, steps=785, speed=60.9 f/s, elapsed=1:11:28\n",
      "Episode 304: reward=-21, steps=755, speed=60.9 f/s, elapsed=1:11:41\n",
      "Episode 305: reward=-21, steps=847, speed=60.9 f/s, elapsed=1:11:55\n",
      "Episode 306: reward=-21, steps=989, speed=60.9 f/s, elapsed=1:12:11\n",
      "Episode 307: reward=-21, steps=761, speed=60.9 f/s, elapsed=1:12:23\n",
      "Episode 308: reward=-21, steps=877, speed=60.9 f/s, elapsed=1:12:38\n",
      "Episode 309: reward=-20, steps=854, speed=60.9 f/s, elapsed=1:12:52\n",
      "Episode 310: reward=-21, steps=818, speed=60.9 f/s, elapsed=1:13:05\n",
      "Episode 311: reward=-21, steps=910, speed=60.9 f/s, elapsed=1:13:20\n",
      "Episode 312: reward=-20, steps=839, speed=60.9 f/s, elapsed=1:13:34\n",
      "Episode 313: reward=-21, steps=879, speed=60.9 f/s, elapsed=1:13:49\n",
      "Episode 314: reward=-21, steps=755, speed=60.9 f/s, elapsed=1:14:01\n",
      "Episode 315: reward=-20, steps=833, speed=60.8 f/s, elapsed=1:14:15\n",
      "Episode 316: reward=-21, steps=822, speed=60.8 f/s, elapsed=1:14:29\n",
      "Episode 317: reward=-21, steps=877, speed=60.8 f/s, elapsed=1:14:43\n",
      "Episode 318: reward=-20, steps=928, speed=60.8 f/s, elapsed=1:14:58\n",
      "Episode 319: reward=-21, steps=822, speed=60.8 f/s, elapsed=1:15:12\n",
      "Episode 320: reward=-20, steps=912, speed=60.8 f/s, elapsed=1:15:27\n",
      "Episode 321: reward=-21, steps=944, speed=60.8 f/s, elapsed=1:15:42\n",
      "Episode 322: reward=-21, steps=820, speed=60.8 f/s, elapsed=1:15:56\n",
      "Episode 323: reward=-19, steps=1032, speed=60.8 f/s, elapsed=1:16:13\n",
      "Episode 324: reward=-20, steps=919, speed=60.8 f/s, elapsed=1:16:28\n",
      "Episode 325: reward=-19, steps=1122, speed=60.8 f/s, elapsed=1:16:46\n",
      "Episode 326: reward=-21, steps=818, speed=60.8 f/s, elapsed=1:17:00\n",
      "Episode 327: reward=-20, steps=1001, speed=60.8 f/s, elapsed=1:17:16\n",
      "Episode 328: reward=-20, steps=892, speed=60.8 f/s, elapsed=1:17:31\n",
      "Episode 329: reward=-21, steps=761, speed=60.8 f/s, elapsed=1:17:43\n",
      "Episode 330: reward=-20, steps=975, speed=60.9 f/s, elapsed=1:17:59\n",
      "Episode 331: reward=-21, steps=957, speed=60.9 f/s, elapsed=1:18:15\n",
      "Episode 332: reward=-21, steps=760, speed=60.9 f/s, elapsed=1:18:27\n",
      "Episode 333: reward=-21, steps=853, speed=60.9 f/s, elapsed=1:18:41\n",
      "Episode 334: reward=-21, steps=781, speed=60.9 f/s, elapsed=1:18:54\n",
      "Episode 335: reward=-21, steps=881, speed=60.9 f/s, elapsed=1:19:08\n",
      "Episode 336: reward=-21, steps=821, speed=60.9 f/s, elapsed=1:19:22\n",
      "Episode 337: reward=-21, steps=776, speed=60.9 f/s, elapsed=1:19:34\n",
      "Episode 338: reward=-21, steps=909, speed=60.9 f/s, elapsed=1:19:49\n",
      "Episode 339: reward=-21, steps=818, speed=60.9 f/s, elapsed=1:20:03\n",
      "Episode 340: reward=-21, steps=820, speed=60.9 f/s, elapsed=1:20:16\n",
      "Episode 341: reward=-20, steps=956, speed=60.9 f/s, elapsed=1:20:32\n",
      "Episode 342: reward=-21, steps=911, speed=60.9 f/s, elapsed=1:20:47\n",
      "Episode 343: reward=-21, steps=760, speed=60.9 f/s, elapsed=1:20:59\n",
      "Episode 344: reward=-21, steps=1028, speed=60.9 f/s, elapsed=1:21:16\n",
      "Episode 345: reward=-21, steps=849, speed=60.9 f/s, elapsed=1:21:30\n",
      "Episode 346: reward=-21, steps=835, speed=60.9 f/s, elapsed=1:21:44\n",
      "Episode 347: reward=-21, steps=881, speed=60.9 f/s, elapsed=1:21:58\n",
      "Episode 348: reward=-21, steps=811, speed=60.9 f/s, elapsed=1:22:12\n",
      "Episode 349: reward=-21, steps=876, speed=60.9 f/s, elapsed=1:22:26\n",
      "Episode 350: reward=-21, steps=897, speed=60.9 f/s, elapsed=1:22:41\n",
      "Episode 351: reward=-20, steps=894, speed=60.9 f/s, elapsed=1:22:55\n",
      "Episode 352: reward=-21, steps=911, speed=60.9 f/s, elapsed=1:23:11\n",
      "Episode 353: reward=-21, steps=786, speed=60.9 f/s, elapsed=1:23:24\n",
      "Episode 354: reward=-21, steps=1045, speed=60.9 f/s, elapsed=1:23:41\n",
      "Episode 355: reward=-20, steps=854, speed=60.9 f/s, elapsed=1:23:55\n",
      "Episode 356: reward=-21, steps=880, speed=60.9 f/s, elapsed=1:24:09\n",
      "Episode 357: reward=-21, steps=817, speed=60.9 f/s, elapsed=1:24:23\n",
      "Episode 358: reward=-21, steps=862, speed=60.9 f/s, elapsed=1:24:37\n",
      "Episode 359: reward=-21, steps=823, speed=60.9 f/s, elapsed=1:24:50\n",
      "Episode 360: reward=-21, steps=757, speed=60.9 f/s, elapsed=1:25:03\n",
      "Episode 361: reward=-21, steps=762, speed=60.9 f/s, elapsed=1:25:15\n",
      "Episode 362: reward=-20, steps=913, speed=60.9 f/s, elapsed=1:25:30\n",
      "Episode 363: reward=-21, steps=851, speed=60.9 f/s, elapsed=1:25:44\n",
      "Episode 364: reward=-20, steps=878, speed=60.9 f/s, elapsed=1:25:59\n",
      "Episode 365: reward=-19, steps=926, speed=60.9 f/s, elapsed=1:26:14\n",
      "Episode 366: reward=-21, steps=851, speed=60.9 f/s, elapsed=1:26:28\n",
      "Episode 367: reward=-21, steps=821, speed=60.9 f/s, elapsed=1:26:41\n",
      "Episode 368: reward=-21, steps=755, speed=60.9 f/s, elapsed=1:26:54\n",
      "Episode 369: reward=-20, steps=954, speed=60.9 f/s, elapsed=1:27:09\n",
      "Episode 370: reward=-20, steps=838, speed=60.9 f/s, elapsed=1:27:23\n",
      "Episode 371: reward=-21, steps=877, speed=60.9 f/s, elapsed=1:27:38\n",
      "Episode 372: reward=-21, steps=881, speed=60.9 f/s, elapsed=1:27:52\n",
      "Episode 373: reward=-21, steps=821, speed=60.9 f/s, elapsed=1:28:06\n",
      "Episode 374: reward=-21, steps=785, speed=60.9 f/s, elapsed=1:28:19\n",
      "Episode 375: reward=-21, steps=756, speed=60.9 f/s, elapsed=1:28:31\n",
      "Episode 376: reward=-21, steps=820, speed=60.9 f/s, elapsed=1:28:45\n",
      "Episode 377: reward=-21, steps=760, speed=60.9 f/s, elapsed=1:28:57\n",
      "Episode 378: reward=-20, steps=833, speed=60.9 f/s, elapsed=1:29:11\n",
      "Episode 379: reward=-20, steps=837, speed=60.9 f/s, elapsed=1:29:25\n",
      "Episode 380: reward=-20, steps=923, speed=60.9 f/s, elapsed=1:29:40\n",
      "Episode 381: reward=-19, steps=932, speed=60.9 f/s, elapsed=1:29:55\n",
      "Episode 382: reward=-21, steps=818, speed=60.9 f/s, elapsed=1:30:08\n",
      "Episode 383: reward=-21, steps=817, speed=60.9 f/s, elapsed=1:30:22\n",
      "Episode 384: reward=-20, steps=857, speed=60.9 f/s, elapsed=1:30:36\n",
      "Episode 385: reward=-21, steps=815, speed=60.9 f/s, elapsed=1:30:49\n",
      "Episode 386: reward=-20, steps=837, speed=60.9 f/s, elapsed=1:31:03\n",
      "Episode 387: reward=-19, steps=949, speed=60.9 f/s, elapsed=1:31:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20440\\338186196.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEngine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_ignite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"adv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"val\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_initial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Engine run is terminating due to exception: %s.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    695\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                 \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m                 \u001b[1;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    744\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AIProjects\\DeepRL\\Unit 8\\lib\\common.py\u001b[0m in \u001b[0;36mbatch_generator\u001b[1;34m(buffer, initial, batch_size)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\experience.py\u001b[0m in \u001b[0;36mpopulate\u001b[1;34m(self, samples)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \"\"\"\n\u001b[0;32m    367\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[0mentry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperience_source_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\experience.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mexp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mExperienceSourceFirstLast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[0mlast_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\experience.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m                     \u001b[0mnext_state_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_done_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_n\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                     \u001b[0mnext_state_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_done_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mis_done\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\common\\wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_ob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\common\\wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\common\\wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\common\\wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\common\\wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwas_real_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# check current lives, make loss of life terminal,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mnum_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mreward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[0mob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\atari_py\\ale_python_interface.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0male_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_batch(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    loss_v = common.calc_loss_dqn(batch, net, tgt_net.target_model,\n",
    "                                  gamma=params.gamma, device=device)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    epsilon_tracker.frame(engine.state.iteration)\n",
    "    if engine.state.iteration % EVAL_EVERY_FRAME == 0:\n",
    "        eval_states = getattr(engine.state, \"eval_states\", None)\n",
    "        if eval_states is None:\n",
    "            eval_states = buffer.sample(STATES_TO_EVALUATE)\n",
    "            eval_states = [np.array(transition.state, copy=False) for transition in eval_states]\n",
    "            eval_states = np.array(eval_states, copy=False)\n",
    "            engine.state.eval_states = eval_states\n",
    "        evaluate_states(eval_states, net, device, engine)\n",
    "    return {\n",
    "        \"loss\" : loss_v.item(),\n",
    "        \"epsilon\": selector.epsilon,\n",
    "    }\n",
    "\n",
    "engine = Engine(process_batch)\n",
    "common.setup_ignite(engine, params, exp_source, NAME, extra_metrics=(\"adv\", \"val\"))\n",
    "engine.run(common.batch_generator(buffer, params.replay_initial, params.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744ff7a-a67c-4716-b37f-1152374dd851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprl",
   "language": "python",
   "name": "deeprl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

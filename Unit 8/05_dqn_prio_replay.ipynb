{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe866f0d-cc02-42b0-b137-1027eb4b262b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import ptan\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from ignite.engine import Engine\n",
    "\n",
    "from lib import dqn_model, common, dqn_extra\n",
    "\n",
    "NAME = \"05_prio_replay\"\n",
    "PRIO_REPLAY_ALPHA = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9db0748-69b0-4bc2-b445-cfaa2b0300aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_loss(batch, batch_weights, net, tgt_net,\n",
    "              gamma, device=\"cpu\"):\n",
    "    states, actions, rewards, dones, next_states = \\\n",
    "        common.unpack_batch(batch)\n",
    "\n",
    "    states_v = torch.tensor(states).to(device)\n",
    "    actions_v = torch.tensor(actions).to(device)\n",
    "    rewards_v = torch.tensor(rewards).to(device)\n",
    "    done_mask = torch.BoolTensor(dones).to(device)\n",
    "    batch_weights_v = torch.tensor(batch_weights).to(device)\n",
    "\n",
    "    actions_v = actions_v.unsqueeze(-1)\n",
    "    state_action_vals = net(states_v).gather(1, actions_v)\n",
    "    state_action_vals = state_action_vals.squeeze(-1)\n",
    "    with torch.no_grad():\n",
    "        next_states_v = torch.tensor(next_states).to(device)\n",
    "        next_s_vals = tgt_net(next_states_v).max(1)[0]\n",
    "        next_s_vals[done_mask] = 0.0\n",
    "        exp_sa_vals = next_s_vals.detach() * gamma + rewards_v\n",
    "    l = (state_action_vals - exp_sa_vals) ** 2\n",
    "    losses_v = batch_weights_v * l\n",
    "    return losses_v.mean(), \\\n",
    "           (losses_v + 1e-5).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd759673-aed1-45ff-b1e6-6698cd7a2320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[123, 151010689]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(common.SEED)\n",
    "torch.manual_seed(common.SEED)\n",
    "params = common.HYPERPARAMS['pong']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make(\"PongNoFrameskip-v4\")\n",
    "env = ptan.common.wrappers.wrap_dqn(env)\n",
    "env.seed(common.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6edff0-73ce-4d99-9ce8-6ff048c3c653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "\n",
    "tgt_net = ptan.agent.TargetNet(net)\n",
    "selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params.epsilon_start)\n",
    "epsilon_tracker = common.EpsilonTracker(selector, params)\n",
    "agent = ptan.agent.DQNAgent(net, selector, device = device)\n",
    "\n",
    "exp_source = ptan.experience.ExperienceSourceFirstLast(\n",
    "    env, agent, gamma=params.gamma)\n",
    "buffer = dqn_extra.PrioReplayBuffer(\n",
    "    exp_source, params.replay_size, PRIO_REPLAY_ALPHA)\n",
    "optimizer = optim.Adam(net.parameters(), lr=params.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc74349-bdab-4407-93cb-170b29f38462",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: reward=-20, steps=1110, speed=0.0 f/s, elapsed=0:01:04\n",
      "Episode 2: reward=-21, steps=825, speed=0.0 f/s, elapsed=0:01:04\n",
      "Episode 3: reward=-19, steps=989, speed=0.0 f/s, elapsed=0:01:04\n",
      "Episode 4: reward=-21, steps=783, speed=0.0 f/s, elapsed=0:01:04\n",
      "Episode 5: reward=-21, steps=787, speed=0.0 f/s, elapsed=0:01:04\n",
      "Episode 6: reward=-21, steps=878, speed=0.0 f/s, elapsed=0:01:04\n",
      "Episode 7: reward=-19, steps=1035, speed=0.0 f/s, elapsed=0:01:04\n",
      "Episode 8: reward=-20, steps=896, speed=0.0 f/s, elapsed=0:01:04\n",
      "Episode 9: reward=-19, steps=1019, speed=0.0 f/s, elapsed=0:01:04\n",
      "Episode 10: reward=-21, steps=876, speed=0.0 f/s, elapsed=0:01:04\n",
      "Episode 11: reward=-19, steps=1079, speed=71.3 f/s, elapsed=0:01:08\n",
      "Episode 12: reward=-21, steps=820, speed=71.3 f/s, elapsed=0:01:20\n",
      "Episode 13: reward=-20, steps=833, speed=71.2 f/s, elapsed=0:01:32\n",
      "Episode 14: reward=-21, steps=927, speed=71.2 f/s, elapsed=0:01:45\n",
      "Episode 15: reward=-20, steps=991, speed=71.0 f/s, elapsed=0:02:01\n",
      "Episode 16: reward=-20, steps=1059, speed=70.8 f/s, elapsed=0:02:19\n",
      "Episode 17: reward=-19, steps=985, speed=70.6 f/s, elapsed=0:02:35\n",
      "Episode 18: reward=-21, steps=920, speed=70.5 f/s, elapsed=0:02:49\n",
      "Episode 19: reward=-20, steps=894, speed=70.4 f/s, elapsed=0:03:03\n",
      "Episode 20: reward=-21, steps=938, speed=70.2 f/s, elapsed=0:03:18\n",
      "Episode 21: reward=-20, steps=1013, speed=70.1 f/s, elapsed=0:03:34\n",
      "Episode 22: reward=-21, steps=757, speed=69.9 f/s, elapsed=0:03:46\n",
      "Episode 23: reward=-21, steps=818, speed=69.8 f/s, elapsed=0:03:59\n",
      "Episode 24: reward=-21, steps=948, speed=69.8 f/s, elapsed=0:04:13\n",
      "Episode 25: reward=-20, steps=1016, speed=69.7 f/s, elapsed=0:04:29\n",
      "Episode 26: reward=-21, steps=923, speed=69.6 f/s, elapsed=0:04:43\n",
      "Episode 27: reward=-19, steps=913, speed=69.5 f/s, elapsed=0:04:56\n",
      "Episode 28: reward=-19, steps=1018, speed=69.5 f/s, elapsed=0:05:11\n",
      "Episode 29: reward=-21, steps=929, speed=69.3 f/s, elapsed=0:05:27\n",
      "Episode 30: reward=-18, steps=1065, speed=69.2 f/s, elapsed=0:05:44\n",
      "Episode 31: reward=-21, steps=848, speed=69.1 f/s, elapsed=0:05:57\n",
      "Episode 32: reward=-19, steps=1006, speed=69.1 f/s, elapsed=0:06:11\n",
      "Episode 33: reward=-19, steps=1142, speed=69.0 f/s, elapsed=0:06:29\n",
      "Episode 34: reward=-20, steps=917, speed=69.0 f/s, elapsed=0:06:43\n",
      "Episode 35: reward=-20, steps=940, speed=68.8 f/s, elapsed=0:06:58\n",
      "Episode 36: reward=-21, steps=1013, speed=68.7 f/s, elapsed=0:07:14\n",
      "Episode 37: reward=-19, steps=1077, speed=68.6 f/s, elapsed=0:07:31\n",
      "Episode 38: reward=-21, steps=1024, speed=68.5 f/s, elapsed=0:07:47\n",
      "Episode 39: reward=-20, steps=1137, speed=68.5 f/s, elapsed=0:08:04\n",
      "Episode 40: reward=-21, steps=894, speed=68.4 f/s, elapsed=0:08:18\n",
      "Episode 41: reward=-21, steps=986, speed=68.4 f/s, elapsed=0:08:33\n",
      "Episode 42: reward=-21, steps=943, speed=68.3 f/s, elapsed=0:08:47\n",
      "Episode 43: reward=-20, steps=1093, speed=68.3 f/s, elapsed=0:09:03\n",
      "Episode 44: reward=-21, steps=842, speed=68.2 f/s, elapsed=0:09:16\n",
      "Episode 45: reward=-19, steps=1196, speed=68.2 f/s, elapsed=0:09:34\n",
      "Episode 46: reward=-18, steps=1275, speed=68.1 f/s, elapsed=0:09:54\n",
      "Episode 47: reward=-20, steps=1159, speed=68.1 f/s, elapsed=0:10:11\n",
      "Episode 48: reward=-19, steps=1048, speed=68.0 f/s, elapsed=0:10:27\n",
      "Episode 49: reward=-20, steps=972, speed=68.0 f/s, elapsed=0:10:42\n",
      "Episode 50: reward=-20, steps=1112, speed=67.9 f/s, elapsed=0:10:59\n",
      "Episode 51: reward=-17, steps=1652, speed=67.9 f/s, elapsed=0:11:25\n",
      "Episode 52: reward=-17, steps=1358, speed=67.8 f/s, elapsed=0:11:46\n",
      "Episode 53: reward=-21, steps=1267, speed=67.7 f/s, elapsed=0:12:05\n",
      "Episode 54: reward=-21, steps=1430, speed=67.7 f/s, elapsed=0:12:27\n",
      "Episode 55: reward=-18, steps=1329, speed=67.7 f/s, elapsed=0:12:47\n",
      "Episode 56: reward=-18, steps=1350, speed=67.6 f/s, elapsed=0:13:08\n",
      "Episode 57: reward=-19, steps=1686, speed=67.6 f/s, elapsed=0:13:34\n",
      "Episode 58: reward=-18, steps=1276, speed=67.5 f/s, elapsed=0:13:53\n",
      "Episode 59: reward=-17, steps=1553, speed=67.5 f/s, elapsed=0:14:17\n",
      "Episode 60: reward=-20, steps=1276, speed=67.4 f/s, elapsed=0:14:37\n",
      "Episode 61: reward=-18, steps=1638, speed=67.4 f/s, elapsed=0:15:02\n",
      "Episode 62: reward=-18, steps=1637, speed=67.3 f/s, elapsed=0:15:28\n",
      "Episode 63: reward=-17, steps=1637, speed=67.2 f/s, elapsed=0:15:53\n",
      "Episode 64: reward=-17, steps=1734, speed=67.2 f/s, elapsed=0:16:20\n",
      "Episode 65: reward=-17, steps=1772, speed=67.1 f/s, elapsed=0:16:48\n",
      "Episode 66: reward=-17, steps=1536, speed=67.0 f/s, elapsed=0:17:12\n",
      "Episode 67: reward=-20, steps=1703, speed=67.0 f/s, elapsed=0:17:39\n",
      "Episode 68: reward=-18, steps=1831, speed=66.9 f/s, elapsed=0:18:08\n",
      "Episode 69: reward=-19, steps=1510, speed=66.8 f/s, elapsed=0:18:32\n",
      "Episode 70: reward=-16, steps=2121, speed=66.7 f/s, elapsed=0:19:06\n",
      "Episode 71: reward=-18, steps=1718, speed=66.6 f/s, elapsed=0:19:33\n",
      "Episode 72: reward=-16, steps=1886, speed=66.6 f/s, elapsed=0:20:04\n",
      "Episode 73: reward=-14, steps=2046, speed=66.5 f/s, elapsed=0:20:37\n",
      "Episode 74: reward=-15, steps=2328, speed=66.4 f/s, elapsed=0:21:14\n",
      "Episode 75: reward=-20, steps=2293, speed=66.3 f/s, elapsed=0:21:51\n",
      "Episode 76: reward=-14, steps=2164, speed=66.2 f/s, elapsed=0:22:27\n",
      "Episode 77: reward=-16, steps=1988, speed=66.1 f/s, elapsed=0:22:59\n",
      "Episode 78: reward=-15, steps=1966, speed=66.0 f/s, elapsed=0:23:31\n",
      "Episode 79: reward=-16, steps=1830, speed=65.9 f/s, elapsed=0:24:01\n",
      "Episode 80: reward=-18, steps=2069, speed=65.8 f/s, elapsed=0:24:35\n",
      "Episode 81: reward=-14, steps=2190, speed=65.7 f/s, elapsed=0:25:11\n",
      "Episode 82: reward=-17, steps=2094, speed=65.6 f/s, elapsed=0:25:46\n",
      "Episode 83: reward=-17, steps=2268, speed=65.5 f/s, elapsed=0:26:24\n",
      "Episode 84: reward=-12, steps=2424, speed=65.3 f/s, elapsed=0:27:06\n",
      "Episode 85: reward=-17, steps=1967, speed=65.2 f/s, elapsed=0:27:39\n",
      "Episode 86: reward=-14, steps=2356, speed=65.1 f/s, elapsed=0:28:18\n",
      "Episode 87: reward=-13, steps=2531, speed=65.0 f/s, elapsed=0:28:59\n",
      "Episode 88: reward=-10, steps=2625, speed=64.9 f/s, elapsed=0:29:42\n",
      "Episode 89: reward=-10, steps=2902, speed=64.9 f/s, elapsed=0:30:30\n",
      "Episode 90: reward=-13, steps=2436, speed=64.8 f/s, elapsed=0:31:11\n",
      "Episode 91: reward=-17, steps=2183, speed=64.7 f/s, elapsed=0:31:46\n",
      "Episode 92: reward=-13, steps=2306, speed=64.6 f/s, elapsed=0:32:25\n",
      "Episode 93: reward=-15, steps=2207, speed=64.5 f/s, elapsed=0:33:01\n",
      "Episode 94: reward=-16, steps=2173, speed=64.5 f/s, elapsed=0:33:37\n",
      "Episode 95: reward=-15, steps=2445, speed=64.4 f/s, elapsed=0:34:17\n",
      "Episode 96: reward=-18, steps=2069, speed=64.3 f/s, elapsed=0:34:51\n",
      "Episode 97: reward=-12, steps=2786, speed=64.2 f/s, elapsed=0:35:37\n",
      "Episode 98: reward=-16, steps=2214, speed=64.2 f/s, elapsed=0:36:13\n",
      "Episode 99: reward=-14, steps=2329, speed=64.1 f/s, elapsed=0:36:52\n",
      "Episode 100: reward=-15, steps=2578, speed=64.0 f/s, elapsed=0:37:34\n",
      "Episode 101: reward=-13, steps=2329, speed=64.0 f/s, elapsed=0:38:12\n",
      "Episode 102: reward=-12, steps=2472, speed=63.9 f/s, elapsed=0:38:53\n",
      "Episode 103: reward=-3, steps=3881, speed=63.8 f/s, elapsed=0:39:57\n",
      "Episode 104: reward=-12, steps=2524, speed=63.8 f/s, elapsed=0:40:39\n",
      "Episode 105: reward=-13, steps=2587, speed=63.7 f/s, elapsed=0:41:21\n",
      "Episode 106: reward=-12, steps=2678, speed=63.7 f/s, elapsed=0:42:05\n",
      "Episode 107: reward=-14, steps=2428, speed=63.6 f/s, elapsed=0:42:45\n",
      "Episode 108: reward=-4, steps=3349, speed=63.5 f/s, elapsed=0:43:41\n",
      "Episode 109: reward=-9, steps=3288, speed=63.5 f/s, elapsed=0:44:35\n",
      "Episode 110: reward=-3, steps=3773, speed=63.4 f/s, elapsed=0:45:38\n",
      "Episode 111: reward=-10, steps=3044, speed=63.3 f/s, elapsed=0:46:29\n",
      "Episode 112: reward=-12, steps=2719, speed=63.3 f/s, elapsed=0:47:14\n",
      "Episode 113: reward=-6, steps=3406, speed=63.2 f/s, elapsed=0:48:09\n",
      "Episode 114: reward=-5, steps=4011, speed=63.2 f/s, elapsed=0:49:15\n",
      "Episode 115: reward=2, steps=4333, speed=63.1 f/s, elapsed=0:50:27\n",
      "Episode 116: reward=-5, steps=3867, speed=63.1 f/s, elapsed=0:51:31\n",
      "Episode 117: reward=-5, steps=3473, speed=63.0 f/s, elapsed=0:52:29\n",
      "Episode 118: reward=-8, steps=2958, speed=63.0 f/s, elapsed=0:53:17\n",
      "Episode 119: reward=-6, steps=3300, speed=62.9 f/s, elapsed=0:54:12\n",
      "Episode 120: reward=-4, steps=3960, speed=62.9 f/s, elapsed=0:55:17\n",
      "Episode 121: reward=-1, steps=4929, speed=62.8 f/s, elapsed=0:56:38\n",
      "Episode 122: reward=-3, steps=3644, speed=62.8 f/s, elapsed=0:57:38\n",
      "Episode 123: reward=4, steps=4466, speed=62.7 f/s, elapsed=0:58:57\n",
      "Episode 124: reward=-3, steps=3786, speed=62.6 f/s, elapsed=1:00:01\n",
      "Episode 125: reward=3, steps=3524, speed=62.5 f/s, elapsed=1:01:04\n",
      "Episode 126: reward=-1, steps=4192, speed=62.4 f/s, elapsed=1:02:17\n",
      "Episode 127: reward=-4, steps=3679, speed=62.3 f/s, elapsed=1:03:20\n",
      "Episode 128: reward=-7, steps=3015, speed=62.2 f/s, elapsed=1:04:12\n",
      "Episode 129: reward=-2, steps=4072, speed=62.1 f/s, elapsed=1:05:23\n",
      "Episode 130: reward=-2, steps=4121, speed=62.0 f/s, elapsed=1:06:33\n",
      "Episode 131: reward=3, steps=4227, speed=61.9 f/s, elapsed=1:07:47\n",
      "Episode 132: reward=6, steps=4027, speed=61.8 f/s, elapsed=1:08:59\n",
      "Episode 133: reward=1, steps=4512, speed=61.7 f/s, elapsed=1:10:23\n",
      "Episode 134: reward=-14, steps=1746, speed=61.5 f/s, elapsed=1:10:54\n",
      "Episode 135: reward=3, steps=4021, speed=61.4 f/s, elapsed=1:12:06\n",
      "Episode 136: reward=4, steps=4296, speed=61.3 f/s, elapsed=1:13:22\n",
      "Episode 137: reward=7, steps=3771, speed=61.2 f/s, elapsed=1:14:33\n",
      "Episode 138: reward=6, steps=3716, speed=61.1 f/s, elapsed=1:15:40\n",
      "Episode 139: reward=-1, steps=3745, speed=60.9 f/s, elapsed=1:16:49\n",
      "Episode 140: reward=-11, steps=2143, speed=60.7 f/s, elapsed=1:17:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12976\\2476379557.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEngine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_ignite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_initial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Engine run is terminating due to exception: %s.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    695\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                 \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m                 \u001b[1;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    744\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AIProjects\\DeepRL\\Unit 8\\lib\\common.py\u001b[0m in \u001b[0;36mbatch_generator\u001b[1;34m(buffer, initial, batch_size)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AIProjects\\DeepRL\\Unit 8\\lib\\dqn_extra.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         indices = np.random.choice(len(self.buffer),\n\u001b[1;32m--> 171\u001b[1;33m                                    batch_size, p=probs)\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_batch(engine, batch_data):\n",
    "    batch, batch_indices, batch_weights = batch_data\n",
    "    optimizer.zero_grad()\n",
    "    loss_v, sample_prios = calc_loss(\n",
    "        batch, batch_weights, net, tgt_net.target_model,\n",
    "        gamma=params.gamma, device=device)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    buffer.update_priorities(batch_indices, sample_prios)\n",
    "    epsilon_tracker.frame(engine.state.iteration)\n",
    "    if engine.state.iteration % params.target_net_sync == 0:\n",
    "        tgt_net.sync()\n",
    "    return {\n",
    "        \"loss\": loss_v.item(),\n",
    "        \"epsilon\": selector.epsilon,\n",
    "        \"beta\": buffer.update_beta(engine.state.iteration),\n",
    "    }\n",
    "\n",
    "engine = Engine(process_batch)\n",
    "common.setup_ignite(engine, params, exp_source, NAME)\n",
    "engine.run(common.batch_generator(buffer, params.replay_initial, params.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e81780-9321-4395-87ee-ed03a934ada3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprl",
   "language": "python",
   "name": "deeprl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b974d19-b9cf-44fd-b63a-71206c73d3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import ptan\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from ignite.engine import Engine\n",
    "\n",
    "from lib import dqn_model, common\n",
    "\n",
    "NAME = \"02_n_steps\"\n",
    "DEFAULT_N_STEPS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc11e1a-8e75-4c33-a751-cbb0431f8574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[123, 151010689]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(common.SEED)\n",
    "torch.manual_seed(common.SEED)\n",
    "params = common.HYPERPARAMS['pong']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make(\"PongNoFrameskip-v4\")\n",
    "env = ptan.common.wrappers.wrap_dqn(env)\n",
    "env.seed(common.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096a3903-8314-45b1-b48e-43fdfea00b69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "\n",
    "tgt_net = ptan.agent.TargetNet(net)\n",
    "selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params.epsilon_start)\n",
    "epsilon_tracker = common.EpsilonTracker(selector, params)\n",
    "agent = ptan.agent.DQNAgent(net, selector, device = device)\n",
    "\n",
    "exp_source = ptan.experience.ExperienceSourceFirstLast(\n",
    "    env, agent, gamma=params.gamma, steps_count=4)\n",
    "buffer = ptan.experience.ExperienceReplayBuffer(\n",
    "    exp_source, buffer_size=params.replay_size)\n",
    "optimizer = optim.Adam(net.parameters(), lr=params.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c80aa128-bd01-452e-92a5-b646a3dd5d8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: reward=-21, steps=843, speed=0.0 f/s, elapsed=0:01:06\n",
      "Episode 2: reward=-20, steps=1054, speed=0.0 f/s, elapsed=0:01:06\n",
      "Episode 3: reward=-21, steps=880, speed=0.0 f/s, elapsed=0:01:06\n",
      "Episode 4: reward=-21, steps=822, speed=0.0 f/s, elapsed=0:01:06\n",
      "Episode 5: reward=-20, steps=914, speed=0.0 f/s, elapsed=0:01:06\n",
      "Episode 6: reward=-21, steps=911, speed=0.0 f/s, elapsed=0:01:06\n",
      "Episode 7: reward=-21, steps=820, speed=0.0 f/s, elapsed=0:01:06\n",
      "Episode 8: reward=-20, steps=865, speed=0.0 f/s, elapsed=0:01:06\n",
      "Episode 9: reward=-20, steps=840, speed=0.0 f/s, elapsed=0:01:06\n",
      "Episode 10: reward=-20, steps=1072, speed=0.0 f/s, elapsed=0:01:06\n",
      "Episode 11: reward=-21, steps=888, speed=0.0 f/s, elapsed=0:01:06\n",
      "Episode 12: reward=-20, steps=921, speed=62.6 f/s, elapsed=0:01:19\n",
      "Episode 13: reward=-20, steps=977, speed=62.7 f/s, elapsed=0:01:33\n",
      "Episode 14: reward=-20, steps=901, speed=62.7 f/s, elapsed=0:01:48\n",
      "Episode 15: reward=-20, steps=1047, speed=62.8 f/s, elapsed=0:02:03\n",
      "Episode 16: reward=-19, steps=1008, speed=62.9 f/s, elapsed=0:02:18\n",
      "Episode 17: reward=-20, steps=900, speed=63.1 f/s, elapsed=0:02:31\n",
      "Episode 18: reward=-20, steps=915, speed=63.2 f/s, elapsed=0:02:43\n",
      "Episode 19: reward=-21, steps=898, speed=63.4 f/s, elapsed=0:02:56\n",
      "Episode 20: reward=-21, steps=845, speed=63.5 f/s, elapsed=0:03:09\n",
      "Episode 21: reward=-19, steps=945, speed=63.5 f/s, elapsed=0:03:23\n",
      "Episode 22: reward=-21, steps=894, speed=63.5 f/s, elapsed=0:03:37\n",
      "Episode 23: reward=-20, steps=915, speed=63.7 f/s, elapsed=0:03:50\n",
      "Episode 24: reward=-20, steps=1082, speed=63.8 f/s, elapsed=0:04:05\n",
      "Episode 25: reward=-19, steps=976, speed=63.9 f/s, elapsed=0:04:19\n",
      "Episode 26: reward=-18, steps=1031, speed=64.0 f/s, elapsed=0:04:35\n",
      "Episode 27: reward=-21, steps=943, speed=64.1 f/s, elapsed=0:04:48\n",
      "Episode 28: reward=-21, steps=1025, speed=64.1 f/s, elapsed=0:05:04\n",
      "Episode 29: reward=-21, steps=785, speed=64.2 f/s, elapsed=0:05:16\n",
      "Episode 30: reward=-21, steps=796, speed=64.2 f/s, elapsed=0:05:27\n",
      "Episode 31: reward=-21, steps=787, speed=64.4 f/s, elapsed=0:05:38\n",
      "Episode 32: reward=-21, steps=816, speed=64.5 f/s, elapsed=0:05:50\n",
      "Episode 33: reward=-18, steps=1028, speed=64.6 f/s, elapsed=0:06:05\n",
      "Episode 34: reward=-20, steps=894, speed=64.7 f/s, elapsed=0:06:17\n",
      "Episode 35: reward=-21, steps=1024, speed=64.8 f/s, elapsed=0:06:32\n",
      "Episode 36: reward=-20, steps=949, speed=64.9 f/s, elapsed=0:06:46\n",
      "Episode 37: reward=-19, steps=935, speed=65.0 f/s, elapsed=0:07:00\n",
      "Episode 38: reward=-21, steps=821, speed=65.1 f/s, elapsed=0:07:11\n",
      "Episode 39: reward=-20, steps=832, speed=65.1 f/s, elapsed=0:07:24\n",
      "Episode 40: reward=-21, steps=817, speed=65.2 f/s, elapsed=0:07:36\n",
      "Episode 41: reward=-21, steps=817, speed=65.2 f/s, elapsed=0:07:48\n",
      "Episode 42: reward=-21, steps=780, speed=65.2 f/s, elapsed=0:08:00\n",
      "Episode 43: reward=-21, steps=776, speed=65.3 f/s, elapsed=0:08:11\n",
      "Episode 44: reward=-21, steps=820, speed=65.3 f/s, elapsed=0:08:23\n",
      "Episode 45: reward=-21, steps=933, speed=65.3 f/s, elapsed=0:08:37\n",
      "Episode 46: reward=-21, steps=822, speed=65.4 f/s, elapsed=0:08:50\n",
      "Episode 47: reward=-20, steps=916, speed=65.4 f/s, elapsed=0:09:03\n",
      "Episode 48: reward=-21, steps=785, speed=65.5 f/s, elapsed=0:09:15\n",
      "Episode 49: reward=-20, steps=834, speed=65.6 f/s, elapsed=0:09:27\n",
      "Episode 50: reward=-21, steps=824, speed=65.6 f/s, elapsed=0:09:39\n",
      "Episode 51: reward=-20, steps=833, speed=65.7 f/s, elapsed=0:09:51\n",
      "Episode 52: reward=-20, steps=836, speed=65.7 f/s, elapsed=0:10:03\n",
      "Episode 53: reward=-21, steps=777, speed=65.7 f/s, elapsed=0:10:15\n",
      "Episode 54: reward=-20, steps=838, speed=65.7 f/s, elapsed=0:10:28\n",
      "Episode 55: reward=-21, steps=879, speed=65.7 f/s, elapsed=0:10:41\n",
      "Episode 56: reward=-21, steps=821, speed=65.7 f/s, elapsed=0:10:54\n",
      "Episode 57: reward=-21, steps=879, speed=65.6 f/s, elapsed=0:11:08\n",
      "Episode 58: reward=-21, steps=822, speed=65.5 f/s, elapsed=0:11:23\n",
      "Episode 59: reward=-21, steps=846, speed=65.4 f/s, elapsed=0:11:37\n",
      "Episode 60: reward=-21, steps=819, speed=65.3 f/s, elapsed=0:11:50\n",
      "Episode 61: reward=-21, steps=819, speed=65.2 f/s, elapsed=0:12:03\n",
      "Episode 62: reward=-21, steps=778, speed=65.1 f/s, elapsed=0:12:16\n",
      "Episode 63: reward=-21, steps=819, speed=65.0 f/s, elapsed=0:12:29\n",
      "Episode 64: reward=-21, steps=815, speed=65.0 f/s, elapsed=0:12:42\n",
      "Episode 65: reward=-21, steps=822, speed=64.9 f/s, elapsed=0:12:56\n",
      "Episode 66: reward=-20, steps=833, speed=64.9 f/s, elapsed=0:13:09\n",
      "Episode 67: reward=-21, steps=789, speed=64.8 f/s, elapsed=0:13:22\n",
      "Episode 68: reward=-20, steps=896, speed=64.7 f/s, elapsed=0:13:37\n",
      "Episode 69: reward=-21, steps=818, speed=64.7 f/s, elapsed=0:13:50\n",
      "Episode 70: reward=-21, steps=789, speed=64.6 f/s, elapsed=0:14:02\n",
      "Episode 71: reward=-21, steps=817, speed=64.5 f/s, elapsed=0:14:16\n",
      "Episode 72: reward=-20, steps=890, speed=64.5 f/s, elapsed=0:14:30\n",
      "Episode 73: reward=-21, steps=838, speed=64.4 f/s, elapsed=0:14:44\n",
      "Episode 74: reward=-21, steps=820, speed=64.4 f/s, elapsed=0:14:57\n",
      "Episode 75: reward=-21, steps=816, speed=64.3 f/s, elapsed=0:15:10\n",
      "Episode 76: reward=-20, steps=834, speed=64.3 f/s, elapsed=0:15:24\n",
      "Episode 77: reward=-20, steps=837, speed=64.2 f/s, elapsed=0:15:37\n",
      "Episode 78: reward=-21, steps=778, speed=64.1 f/s, elapsed=0:15:50\n",
      "Episode 79: reward=-20, steps=958, speed=64.1 f/s, elapsed=0:16:06\n",
      "Episode 80: reward=-21, steps=846, speed=64.0 f/s, elapsed=0:16:20\n",
      "Episode 81: reward=-20, steps=898, speed=63.9 f/s, elapsed=0:16:35\n",
      "Episode 82: reward=-21, steps=818, speed=63.9 f/s, elapsed=0:16:49\n",
      "Episode 83: reward=-21, steps=778, speed=63.8 f/s, elapsed=0:17:01\n",
      "Episode 84: reward=-21, steps=816, speed=63.8 f/s, elapsed=0:17:14\n",
      "Episode 85: reward=-20, steps=829, speed=63.7 f/s, elapsed=0:17:28\n",
      "Episode 86: reward=-20, steps=833, speed=63.7 f/s, elapsed=0:17:41\n",
      "Episode 87: reward=-21, steps=776, speed=63.7 f/s, elapsed=0:17:54\n",
      "Episode 88: reward=-21, steps=757, speed=63.6 f/s, elapsed=0:18:06\n",
      "Episode 89: reward=-21, steps=818, speed=63.6 f/s, elapsed=0:18:19\n",
      "Episode 90: reward=-21, steps=879, speed=63.5 f/s, elapsed=0:18:34\n",
      "Episode 91: reward=-20, steps=834, speed=63.5 f/s, elapsed=0:18:47\n",
      "Episode 92: reward=-21, steps=822, speed=63.4 f/s, elapsed=0:19:01\n",
      "Episode 93: reward=-20, steps=835, speed=63.4 f/s, elapsed=0:19:14\n",
      "Episode 94: reward=-21, steps=817, speed=63.4 f/s, elapsed=0:19:28\n",
      "Episode 95: reward=-21, steps=818, speed=63.3 f/s, elapsed=0:19:41\n",
      "Episode 96: reward=-21, steps=817, speed=63.3 f/s, elapsed=0:19:54\n",
      "Episode 97: reward=-21, steps=775, speed=63.2 f/s, elapsed=0:20:07\n",
      "Episode 98: reward=-21, steps=821, speed=63.2 f/s, elapsed=0:20:20\n",
      "Episode 99: reward=-21, steps=905, speed=63.2 f/s, elapsed=0:20:35\n",
      "Episode 100: reward=-21, steps=817, speed=63.1 f/s, elapsed=0:20:48\n",
      "Episode 101: reward=-21, steps=821, speed=63.1 f/s, elapsed=0:21:02\n",
      "Episode 102: reward=-21, steps=819, speed=63.1 f/s, elapsed=0:21:15\n",
      "Episode 103: reward=-21, steps=883, speed=63.1 f/s, elapsed=0:21:29\n",
      "Episode 104: reward=-21, steps=820, speed=63.0 f/s, elapsed=0:21:42\n",
      "Episode 105: reward=-21, steps=815, speed=63.0 f/s, elapsed=0:21:56\n",
      "Episode 106: reward=-21, steps=817, speed=63.0 f/s, elapsed=0:22:09\n",
      "Episode 107: reward=-21, steps=819, speed=62.9 f/s, elapsed=0:22:22\n",
      "Episode 108: reward=-21, steps=820, speed=62.9 f/s, elapsed=0:22:35\n",
      "Episode 109: reward=-21, steps=901, speed=62.9 f/s, elapsed=0:22:50\n",
      "Episode 110: reward=-21, steps=817, speed=62.8 f/s, elapsed=0:23:04\n",
      "Episode 111: reward=-21, steps=822, speed=62.8 f/s, elapsed=0:23:17\n",
      "Episode 112: reward=-21, steps=760, speed=62.8 f/s, elapsed=0:23:30\n",
      "Episode 113: reward=-20, steps=841, speed=62.7 f/s, elapsed=0:23:43\n",
      "Episode 114: reward=-21, steps=790, speed=62.7 f/s, elapsed=0:23:56\n",
      "Episode 115: reward=-21, steps=759, speed=62.7 f/s, elapsed=0:24:09\n",
      "Episode 116: reward=-21, steps=821, speed=62.6 f/s, elapsed=0:24:23\n",
      "Episode 117: reward=-21, steps=758, speed=62.6 f/s, elapsed=0:24:35\n",
      "Episode 118: reward=-21, steps=943, speed=62.6 f/s, elapsed=0:24:50\n",
      "Episode 119: reward=-21, steps=816, speed=62.5 f/s, elapsed=0:25:04\n",
      "Episode 120: reward=-21, steps=760, speed=62.5 f/s, elapsed=0:25:16\n",
      "Episode 121: reward=-21, steps=757, speed=62.5 f/s, elapsed=0:25:28\n",
      "Episode 122: reward=-21, steps=761, speed=62.3 f/s, elapsed=0:25:42\n",
      "Episode 123: reward=-21, steps=817, speed=62.4 f/s, elapsed=0:25:55\n",
      "Episode 124: reward=-21, steps=762, speed=62.4 f/s, elapsed=0:26:07\n",
      "Episode 125: reward=-21, steps=756, speed=62.3 f/s, elapsed=0:26:21\n",
      "Episode 126: reward=-21, steps=817, speed=62.2 f/s, elapsed=0:26:35\n",
      "Episode 127: reward=-21, steps=761, speed=62.1 f/s, elapsed=0:26:48\n",
      "Episode 128: reward=-21, steps=757, speed=62.0 f/s, elapsed=0:27:01\n",
      "Episode 129: reward=-21, steps=761, speed=61.9 f/s, elapsed=0:27:14\n",
      "Episode 130: reward=-21, steps=819, speed=61.8 f/s, elapsed=0:27:28\n",
      "Episode 131: reward=-21, steps=757, speed=61.7 f/s, elapsed=0:27:42\n",
      "Episode 132: reward=-21, steps=758, speed=61.6 f/s, elapsed=0:27:55\n",
      "Episode 133: reward=-21, steps=758, speed=61.6 f/s, elapsed=0:28:08\n",
      "Episode 134: reward=-21, steps=758, speed=61.5 f/s, elapsed=0:28:21\n",
      "Episode 135: reward=-21, steps=821, speed=61.4 f/s, elapsed=0:28:36\n",
      "Episode 136: reward=-21, steps=758, speed=61.3 f/s, elapsed=0:28:49\n",
      "Episode 137: reward=-21, steps=757, speed=61.2 f/s, elapsed=0:29:02\n",
      "Episode 138: reward=-21, steps=761, speed=61.1 f/s, elapsed=0:29:15\n",
      "Episode 139: reward=-21, steps=760, speed=61.1 f/s, elapsed=0:29:29\n",
      "Episode 140: reward=-21, steps=759, speed=61.0 f/s, elapsed=0:29:42\n",
      "Episode 141: reward=-21, steps=762, speed=60.9 f/s, elapsed=0:29:55\n",
      "Episode 142: reward=-21, steps=759, speed=60.8 f/s, elapsed=0:30:09\n",
      "Episode 143: reward=-21, steps=758, speed=60.8 f/s, elapsed=0:30:22\n",
      "Episode 144: reward=-21, steps=758, speed=60.7 f/s, elapsed=0:30:35\n",
      "Episode 145: reward=-21, steps=761, speed=60.6 f/s, elapsed=0:30:48\n",
      "Episode 146: reward=-21, steps=760, speed=60.5 f/s, elapsed=0:31:02\n",
      "Episode 147: reward=-21, steps=816, speed=60.5 f/s, elapsed=0:31:16\n",
      "Episode 148: reward=-21, steps=756, speed=60.4 f/s, elapsed=0:31:29\n",
      "Episode 149: reward=-21, steps=760, speed=60.4 f/s, elapsed=0:31:42\n",
      "Episode 150: reward=-21, steps=822, speed=60.3 f/s, elapsed=0:31:57\n",
      "Episode 151: reward=-21, steps=760, speed=60.3 f/s, elapsed=0:32:10\n",
      "Episode 152: reward=-21, steps=815, speed=60.2 f/s, elapsed=0:32:24\n",
      "Episode 153: reward=-21, steps=759, speed=60.3 f/s, elapsed=0:32:36\n",
      "Episode 154: reward=-21, steps=824, speed=60.4 f/s, elapsed=0:32:49\n",
      "Episode 155: reward=-21, steps=758, speed=60.3 f/s, elapsed=0:33:02\n",
      "Episode 156: reward=-21, steps=756, speed=60.2 f/s, elapsed=0:33:16\n",
      "Episode 157: reward=-21, steps=758, speed=60.1 f/s, elapsed=0:33:29\n",
      "Episode 158: reward=-21, steps=762, speed=60.1 f/s, elapsed=0:33:42\n",
      "Episode 159: reward=-21, steps=755, speed=59.9 f/s, elapsed=0:33:57\n",
      "Episode 160: reward=-21, steps=758, speed=59.8 f/s, elapsed=0:34:10\n",
      "Episode 161: reward=-21, steps=756, speed=59.8 f/s, elapsed=0:34:23\n",
      "Episode 162: reward=-21, steps=759, speed=59.7 f/s, elapsed=0:34:37\n",
      "Episode 163: reward=-21, steps=758, speed=59.6 f/s, elapsed=0:34:50\n",
      "Episode 164: reward=-21, steps=822, speed=59.6 f/s, elapsed=0:35:05\n",
      "Episode 165: reward=-21, steps=761, speed=59.5 f/s, elapsed=0:35:18\n",
      "Episode 166: reward=-21, steps=759, speed=59.5 f/s, elapsed=0:35:32\n",
      "Episode 167: reward=-21, steps=757, speed=59.4 f/s, elapsed=0:35:45\n",
      "Episode 168: reward=-21, steps=756, speed=59.4 f/s, elapsed=0:35:58\n",
      "Episode 169: reward=-21, steps=755, speed=59.3 f/s, elapsed=0:36:12\n",
      "Episode 170: reward=-21, steps=756, speed=59.2 f/s, elapsed=0:36:25\n",
      "Episode 171: reward=-21, steps=755, speed=59.2 f/s, elapsed=0:36:39\n",
      "Episode 172: reward=-21, steps=759, speed=59.1 f/s, elapsed=0:36:52\n",
      "Episode 173: reward=-21, steps=755, speed=59.1 f/s, elapsed=0:37:05\n",
      "Episode 174: reward=-21, steps=761, speed=59.0 f/s, elapsed=0:37:19\n",
      "Episode 175: reward=-21, steps=760, speed=59.0 f/s, elapsed=0:37:32\n",
      "Episode 176: reward=-21, steps=762, speed=59.0 f/s, elapsed=0:37:45\n",
      "Episode 177: reward=-21, steps=820, speed=58.9 f/s, elapsed=0:38:00\n",
      "Episode 178: reward=-21, steps=756, speed=58.9 f/s, elapsed=0:38:13\n",
      "Episode 179: reward=-21, steps=760, speed=58.8 f/s, elapsed=0:38:26\n",
      "Episode 180: reward=-21, steps=757, speed=58.8 f/s, elapsed=0:38:40\n",
      "Episode 181: reward=-21, steps=756, speed=58.8 f/s, elapsed=0:38:53\n",
      "Episode 182: reward=-21, steps=758, speed=58.7 f/s, elapsed=0:39:06\n",
      "Episode 183: reward=-21, steps=760, speed=58.7 f/s, elapsed=0:39:19\n",
      "Episode 184: reward=-21, steps=762, speed=58.7 f/s, elapsed=0:39:33\n",
      "Episode 185: reward=-21, steps=759, speed=58.6 f/s, elapsed=0:39:46\n",
      "Episode 186: reward=-21, steps=762, speed=58.6 f/s, elapsed=0:40:00\n",
      "Episode 187: reward=-21, steps=758, speed=58.6 f/s, elapsed=0:40:13\n",
      "Episode 188: reward=-21, steps=756, speed=58.8 f/s, elapsed=0:40:24\n",
      "Episode 189: reward=-21, steps=757, speed=58.9 f/s, elapsed=0:40:35\n",
      "Episode 190: reward=-21, steps=759, speed=59.2 f/s, elapsed=0:40:46\n",
      "Episode 191: reward=-21, steps=756, speed=59.4 f/s, elapsed=0:40:57\n",
      "Episode 192: reward=-21, steps=757, speed=59.3 f/s, elapsed=0:41:10\n",
      "Episode 193: reward=-21, steps=762, speed=59.2 f/s, elapsed=0:41:25\n",
      "Episode 194: reward=-21, steps=761, speed=59.0 f/s, elapsed=0:41:40\n",
      "Episode 195: reward=-21, steps=756, speed=58.9 f/s, elapsed=0:41:54\n",
      "Episode 196: reward=-21, steps=759, speed=58.8 f/s, elapsed=0:42:09\n",
      "Episode 197: reward=-21, steps=761, speed=58.6 f/s, elapsed=0:42:23\n",
      "Episode 198: reward=-21, steps=760, speed=58.5 f/s, elapsed=0:42:38\n",
      "Episode 199: reward=-21, steps=759, speed=58.3 f/s, elapsed=0:42:53\n",
      "Episode 200: reward=-21, steps=760, speed=58.4 f/s, elapsed=0:43:05\n",
      "Episode 201: reward=-21, steps=761, speed=58.4 f/s, elapsed=0:43:19\n",
      "Episode 202: reward=-21, steps=818, speed=58.5 f/s, elapsed=0:43:31\n",
      "Episode 203: reward=-21, steps=757, speed=58.7 f/s, elapsed=0:43:42\n",
      "Episode 204: reward=-21, steps=756, speed=58.8 f/s, elapsed=0:43:54\n",
      "Episode 205: reward=-21, steps=757, speed=59.1 f/s, elapsed=0:44:04\n",
      "Episode 206: reward=-21, steps=756, speed=59.3 f/s, elapsed=0:44:15\n",
      "Episode 207: reward=-21, steps=760, speed=59.4 f/s, elapsed=0:44:27\n",
      "Episode 208: reward=-21, steps=762, speed=59.6 f/s, elapsed=0:44:38\n",
      "Episode 209: reward=-21, steps=761, speed=59.7 f/s, elapsed=0:44:50\n",
      "Episode 210: reward=-21, steps=760, speed=59.7 f/s, elapsed=0:45:03\n",
      "Episode 211: reward=-21, steps=757, speed=59.8 f/s, elapsed=0:45:14\n",
      "Episode 212: reward=-21, steps=761, speed=59.9 f/s, elapsed=0:45:26\n",
      "Episode 213: reward=-21, steps=759, speed=59.9 f/s, elapsed=0:45:39\n",
      "Episode 214: reward=-21, steps=762, speed=60.0 f/s, elapsed=0:45:50\n",
      "Episode 215: reward=-21, steps=755, speed=60.2 f/s, elapsed=0:46:01\n",
      "Episode 216: reward=-21, steps=818, speed=60.3 f/s, elapsed=0:46:14\n",
      "Episode 217: reward=-21, steps=760, speed=60.4 f/s, elapsed=0:46:25\n",
      "Episode 218: reward=-21, steps=758, speed=60.4 f/s, elapsed=0:46:38\n",
      "Episode 219: reward=-21, steps=760, speed=60.3 f/s, elapsed=0:46:51\n",
      "Episode 220: reward=-21, steps=762, speed=60.4 f/s, elapsed=0:47:03\n",
      "Episode 221: reward=-21, steps=759, speed=60.4 f/s, elapsed=0:47:15\n",
      "Episode 222: reward=-21, steps=756, speed=60.3 f/s, elapsed=0:47:29\n",
      "Episode 223: reward=-21, steps=760, speed=60.3 f/s, elapsed=0:47:42\n",
      "Episode 224: reward=-21, steps=819, speed=60.5 f/s, elapsed=0:47:53\n",
      "Episode 225: reward=-21, steps=757, speed=60.3 f/s, elapsed=0:48:09\n",
      "Episode 226: reward=-21, steps=756, speed=60.4 f/s, elapsed=0:48:20\n",
      "Episode 227: reward=-21, steps=820, speed=60.6 f/s, elapsed=0:48:32\n",
      "Episode 228: reward=-21, steps=759, speed=60.8 f/s, elapsed=0:48:42\n",
      "Episode 229: reward=-21, steps=758, speed=61.0 f/s, elapsed=0:48:53\n",
      "Episode 230: reward=-21, steps=759, speed=61.2 f/s, elapsed=0:49:04\n",
      "Episode 231: reward=-21, steps=757, speed=61.4 f/s, elapsed=0:49:15\n",
      "Episode 232: reward=-21, steps=762, speed=61.5 f/s, elapsed=0:49:26\n",
      "Episode 233: reward=-21, steps=757, speed=61.7 f/s, elapsed=0:49:36\n",
      "Episode 234: reward=-21, steps=756, speed=61.9 f/s, elapsed=0:49:47\n",
      "Episode 235: reward=-21, steps=757, speed=61.9 f/s, elapsed=0:49:59\n",
      "Episode 236: reward=-21, steps=755, speed=61.9 f/s, elapsed=0:50:11\n",
      "Episode 237: reward=-21, steps=757, speed=61.9 f/s, elapsed=0:50:24\n",
      "Episode 238: reward=-21, steps=823, speed=61.7 f/s, elapsed=0:50:39\n",
      "Episode 239: reward=-21, steps=820, speed=61.8 f/s, elapsed=0:50:52\n",
      "Episode 240: reward=-21, steps=760, speed=61.9 f/s, elapsed=0:51:03\n",
      "Episode 241: reward=-21, steps=761, speed=61.9 f/s, elapsed=0:51:15\n",
      "Episode 242: reward=-21, steps=819, speed=62.0 f/s, elapsed=0:51:28\n",
      "Episode 243: reward=-21, steps=760, speed=62.1 f/s, elapsed=0:51:39\n",
      "Episode 244: reward=-21, steps=755, speed=62.1 f/s, elapsed=0:51:51\n",
      "Episode 245: reward=-21, steps=755, speed=62.2 f/s, elapsed=0:52:02\n",
      "Episode 246: reward=-21, steps=758, speed=62.1 f/s, elapsed=0:52:15\n",
      "Episode 247: reward=-21, steps=761, speed=62.2 f/s, elapsed=0:52:27\n",
      "Episode 248: reward=-21, steps=757, speed=62.2 f/s, elapsed=0:52:39\n",
      "Episode 249: reward=-21, steps=821, speed=62.2 f/s, elapsed=0:52:52\n",
      "Episode 250: reward=-21, steps=761, speed=62.2 f/s, elapsed=0:53:04\n",
      "Episode 251: reward=-21, steps=761, speed=62.2 f/s, elapsed=0:53:17\n",
      "Episode 252: reward=-21, steps=755, speed=62.1 f/s, elapsed=0:53:30\n",
      "Episode 253: reward=-21, steps=822, speed=62.2 f/s, elapsed=0:53:42\n",
      "Episode 254: reward=-21, steps=756, speed=62.3 f/s, elapsed=0:53:54\n",
      "Episode 255: reward=-21, steps=757, speed=62.3 f/s, elapsed=0:54:05\n",
      "Episode 256: reward=-21, steps=758, speed=62.3 f/s, elapsed=0:54:18\n",
      "Episode 257: reward=-21, steps=823, speed=62.3 f/s, elapsed=0:54:31\n",
      "Episode 258: reward=-21, steps=820, speed=62.4 f/s, elapsed=0:54:43\n",
      "Episode 259: reward=-21, steps=759, speed=62.5 f/s, elapsed=0:54:54\n",
      "Episode 260: reward=-21, steps=757, speed=62.6 f/s, elapsed=0:55:05\n",
      "Episode 261: reward=-21, steps=756, speed=62.7 f/s, elapsed=0:55:16\n",
      "Episode 262: reward=-21, steps=760, speed=62.7 f/s, elapsed=0:55:29\n",
      "Episode 263: reward=-21, steps=758, speed=62.6 f/s, elapsed=0:55:42\n",
      "Episode 264: reward=-21, steps=756, speed=62.7 f/s, elapsed=0:55:53\n",
      "Episode 265: reward=-21, steps=759, speed=62.8 f/s, elapsed=0:56:04\n",
      "Episode 266: reward=-21, steps=760, speed=62.7 f/s, elapsed=0:56:17\n",
      "Episode 267: reward=-21, steps=762, speed=62.7 f/s, elapsed=0:56:29\n",
      "Episode 268: reward=-21, steps=758, speed=62.8 f/s, elapsed=0:56:40\n",
      "Episode 269: reward=-21, steps=761, speed=62.8 f/s, elapsed=0:56:52\n",
      "Episode 270: reward=-21, steps=760, speed=62.9 f/s, elapsed=0:57:04\n",
      "Episode 271: reward=-21, steps=761, speed=63.0 f/s, elapsed=0:57:15\n",
      "Episode 272: reward=-21, steps=758, speed=63.0 f/s, elapsed=0:57:27\n",
      "Episode 273: reward=-21, steps=756, speed=62.9 f/s, elapsed=0:57:40\n",
      "Episode 274: reward=-21, steps=824, speed=62.9 f/s, elapsed=0:57:53\n",
      "Episode 275: reward=-21, steps=761, speed=63.0 f/s, elapsed=0:58:05\n",
      "Episode 276: reward=-21, steps=762, speed=63.0 f/s, elapsed=0:58:17\n",
      "Episode 277: reward=-21, steps=756, speed=63.0 f/s, elapsed=0:58:28\n",
      "Episode 278: reward=-21, steps=756, speed=63.1 f/s, elapsed=0:58:40\n",
      "Episode 279: reward=-21, steps=820, speed=63.1 f/s, elapsed=0:58:53\n",
      "Episode 280: reward=-21, steps=759, speed=63.1 f/s, elapsed=0:59:04\n",
      "Episode 281: reward=-21, steps=822, speed=63.2 f/s, elapsed=0:59:17\n",
      "Episode 282: reward=-21, steps=762, speed=63.3 f/s, elapsed=0:59:28\n",
      "Episode 283: reward=-21, steps=755, speed=63.4 f/s, elapsed=0:59:39\n",
      "Episode 284: reward=-21, steps=758, speed=63.4 f/s, elapsed=0:59:51\n",
      "Episode 285: reward=-21, steps=757, speed=63.4 f/s, elapsed=1:00:03\n",
      "Episode 286: reward=-21, steps=762, speed=63.4 f/s, elapsed=1:00:15\n",
      "Episode 287: reward=-21, steps=759, speed=63.3 f/s, elapsed=1:00:27\n",
      "Episode 288: reward=-21, steps=819, speed=63.2 f/s, elapsed=1:00:41\n",
      "Episode 289: reward=-21, steps=758, speed=63.3 f/s, elapsed=1:00:53\n",
      "Episode 290: reward=-21, steps=760, speed=63.4 f/s, elapsed=1:01:04\n",
      "Episode 291: reward=-21, steps=761, speed=63.4 f/s, elapsed=1:01:16\n",
      "Episode 292: reward=-21, steps=761, speed=63.4 f/s, elapsed=1:01:28\n",
      "Episode 293: reward=-21, steps=822, speed=63.5 f/s, elapsed=1:01:40\n",
      "Episode 294: reward=-21, steps=760, speed=63.6 f/s, elapsed=1:01:51\n",
      "Episode 295: reward=-21, steps=760, speed=63.6 f/s, elapsed=1:02:03\n",
      "Episode 296: reward=-21, steps=761, speed=63.6 f/s, elapsed=1:02:15\n",
      "Episode 297: reward=-21, steps=756, speed=63.6 f/s, elapsed=1:02:27\n",
      "Episode 298: reward=-21, steps=759, speed=63.7 f/s, elapsed=1:02:38\n",
      "Episode 299: reward=-21, steps=755, speed=63.7 f/s, elapsed=1:02:50\n",
      "Episode 300: reward=-21, steps=756, speed=63.7 f/s, elapsed=1:03:01\n",
      "Episode 301: reward=-21, steps=755, speed=63.8 f/s, elapsed=1:03:13\n",
      "Episode 302: reward=-21, steps=762, speed=63.8 f/s, elapsed=1:03:24\n",
      "Episode 303: reward=-21, steps=756, speed=63.9 f/s, elapsed=1:03:36\n",
      "Episode 304: reward=-21, steps=761, speed=63.9 f/s, elapsed=1:03:47\n",
      "Episode 305: reward=-21, steps=761, speed=64.0 f/s, elapsed=1:03:58\n",
      "Episode 306: reward=-21, steps=756, speed=64.0 f/s, elapsed=1:04:10\n",
      "Episode 307: reward=-21, steps=760, speed=64.0 f/s, elapsed=1:04:22\n",
      "Episode 308: reward=-21, steps=757, speed=64.1 f/s, elapsed=1:04:33\n",
      "Episode 309: reward=-21, steps=756, speed=64.2 f/s, elapsed=1:04:44\n",
      "Episode 310: reward=-21, steps=759, speed=64.1 f/s, elapsed=1:04:57\n",
      "Episode 311: reward=-21, steps=755, speed=64.2 f/s, elapsed=1:05:08\n",
      "Episode 312: reward=-21, steps=759, speed=64.2 f/s, elapsed=1:05:20\n",
      "Episode 313: reward=-21, steps=762, speed=64.2 f/s, elapsed=1:05:32\n",
      "Episode 314: reward=-20, steps=835, speed=64.2 f/s, elapsed=1:05:44\n",
      "Episode 315: reward=-21, steps=822, speed=64.3 f/s, elapsed=1:05:56\n",
      "Episode 316: reward=-21, steps=761, speed=64.3 f/s, elapsed=1:06:08\n",
      "Episode 317: reward=-21, steps=761, speed=64.4 f/s, elapsed=1:06:19\n",
      "Episode 318: reward=-21, steps=759, speed=64.4 f/s, elapsed=1:06:30\n",
      "Episode 319: reward=-21, steps=756, speed=64.5 f/s, elapsed=1:06:42\n",
      "Episode 320: reward=-21, steps=760, speed=64.5 f/s, elapsed=1:06:53\n",
      "Episode 321: reward=-21, steps=757, speed=64.5 f/s, elapsed=1:07:05\n",
      "Episode 322: reward=-21, steps=757, speed=64.5 f/s, elapsed=1:07:17\n",
      "Episode 323: reward=-21, steps=757, speed=64.5 f/s, elapsed=1:07:28\n",
      "Episode 324: reward=-21, steps=761, speed=64.5 f/s, elapsed=1:07:40\n",
      "Episode 325: reward=-20, steps=835, speed=64.3 f/s, elapsed=1:07:55\n",
      "Episode 326: reward=-21, steps=819, speed=64.3 f/s, elapsed=1:08:08\n",
      "Episode 327: reward=-21, steps=818, speed=64.2 f/s, elapsed=1:08:22\n",
      "Episode 328: reward=-21, steps=760, speed=64.2 f/s, elapsed=1:08:34\n",
      "Episode 329: reward=-21, steps=879, speed=64.2 f/s, elapsed=1:08:48\n",
      "Episode 330: reward=-21, steps=756, speed=64.1 f/s, elapsed=1:09:00\n",
      "Episode 331: reward=-21, steps=758, speed=64.0 f/s, elapsed=1:09:13\n",
      "Episode 332: reward=-21, steps=760, speed=64.0 f/s, elapsed=1:09:25\n",
      "Episode 333: reward=-21, steps=757, speed=64.0 f/s, elapsed=1:09:37\n",
      "Episode 334: reward=-21, steps=823, speed=64.0 f/s, elapsed=1:09:50\n",
      "Episode 335: reward=-21, steps=755, speed=64.0 f/s, elapsed=1:10:02\n",
      "Episode 336: reward=-21, steps=755, speed=63.9 f/s, elapsed=1:10:14\n",
      "Episode 337: reward=-21, steps=759, speed=63.9 f/s, elapsed=1:10:26\n",
      "Episode 338: reward=-21, steps=758, speed=63.9 f/s, elapsed=1:10:38\n",
      "Episode 339: reward=-21, steps=756, speed=63.9 f/s, elapsed=1:10:50\n",
      "Episode 340: reward=-21, steps=755, speed=63.9 f/s, elapsed=1:11:01\n",
      "Episode 341: reward=-21, steps=815, speed=64.0 f/s, elapsed=1:11:14\n",
      "Episode 342: reward=-21, steps=755, speed=64.0 f/s, elapsed=1:11:25\n",
      "Episode 343: reward=-21, steps=760, speed=64.0 f/s, elapsed=1:11:37\n",
      "Episode 344: reward=-21, steps=756, speed=64.1 f/s, elapsed=1:11:48\n",
      "Episode 345: reward=-21, steps=761, speed=64.2 f/s, elapsed=1:11:59\n",
      "Episode 346: reward=-21, steps=762, speed=64.2 f/s, elapsed=1:12:11\n",
      "Episode 347: reward=-21, steps=761, speed=64.2 f/s, elapsed=1:12:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15828\\1205097118.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEngine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_ignite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"{NAME}={4}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_initial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Engine run is terminating due to exception: %s.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    695\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                 \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m                 \u001b[1;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    744\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AIProjects\\DeepRL\\Unit 8\\lib\\common.py\u001b[0m in \u001b[0;36mbatch_generator\u001b[1;34m(buffer, initial, batch_size)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\experience.py\u001b[0m in \u001b[0;36mpopulate\u001b[1;34m(self, samples)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \"\"\"\n\u001b[0;32m    367\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[0mentry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperience_source_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\experience.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mexp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mExperienceSourceFirstLast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[0mlast_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\experience.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m                     \u001b[0mnext_state_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_done_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_n\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                     \u001b[0mnext_state_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_done_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mis_done\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\common\\wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_ob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\common\\wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\common\\wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\common\\wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ptan\\common\\wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwas_real_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# check current lives, make loss of life terminal,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame_over\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"ale.lives\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36m_get_obs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_ram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'image'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36m_get_image\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetScreenRGB2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_ram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\atari_py\\ale_python_interface.py\u001b[0m in \u001b[0;36mgetScreenRGB2\u001b[1;34m(self, screen_data)\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[0mscreen_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mscreen_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m480\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m         \u001b[0male_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetScreenRGB2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ctypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscreen_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_batch(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    loss_v = common.calc_loss_dqn(\n",
    "        batch, net, tgt_net.target_model,\n",
    "        gamma=params.gamma*4, device=device)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    epsilon_tracker.frame(engine.state.iteration)\n",
    "    if engine.state.iteration % params.target_net_sync == 0:\n",
    "        tgt_net.sync()\n",
    "    return {\n",
    "        \"loss\": loss_v.item(),\n",
    "        \"epsilon\": selector.epsilon,\n",
    "    }\n",
    "\n",
    "engine = Engine(process_batch)\n",
    "common.setup_ignite(engine, params, exp_source, f\"{NAME}={4}\")\n",
    "engine.run(common.batch_generator(buffer, params.replay_initial, params.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39160eda-7a00-499c-8ba6-a606d2a48571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprl",
   "language": "python",
   "name": "deeprl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

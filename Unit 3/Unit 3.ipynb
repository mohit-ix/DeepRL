{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3b6c54-7c2c-4510-bb78-fe6432dcbf41",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f71048-5826-4d94-958a-cd1a01887cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc65233-18cc-481b-bae6-81db18221bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a class OurModule with wrapped functions\n",
    "class OurModule(nn.Module):\n",
    "    def __init__(self, num_inputs, num_classes, dropout_prob=0.3):\n",
    "        super(OurModule, self).__init__()\n",
    "        self.pipe = nn.Sequential(\n",
    "            nn.Linear(num_inputs, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, num_classes),\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff438ff-b7f5-4954-8a05-fdea48485d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OurModule(\n",
      "  (pipe): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "tensor([[0.3319, 0.3350, 0.3332]], grad_fn=<SoftmaxBackward>)\n",
      "Cuda's availability is True\n",
      "Data from cuda: tensor([[0.3319, 0.3350, 0.3332]], device='cuda:0', grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "net = OurModule(num_inputs = 2, num_classes = 3)\n",
    "print(net)\n",
    "v = torch.FloatTensor([[2, 3]])\n",
    "out = net(v)\n",
    "print(out)\n",
    "print(\"Cuda's availability is %s\" % torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Data from cuda: %s\" % out.to('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1d1e1-7aab-49af-9258-2830764f391e",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "Tensorboard is used for viewing the performace of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97534a12-71f3-4c60-8160-047ded495bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1701c4cf-6805-44bf-a063-c17f133eb706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "funcs = {\"sin\": math.sin, \"cos\": math.cos, \"tan\": math.tan}\n",
    "\n",
    "for angle in range(-360, 360):\n",
    "    # Converting angle from degree to radians\n",
    "    angle_rad = angle * math.pi/180\n",
    "    for name, fun in funcs.items():\n",
    "        val = fun(angle_rad)\n",
    "        # storing name of Fucntion, its value and the angle\n",
    "        writer.add_scalar(name, val, angle)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32713a5d-df2f-4669-be54-813d7282abec",
   "metadata": {},
   "source": [
    "A folder named 'runs' will be created in the folder. In command prompt cd to the folder where runs is present and write the tensorboard command:\n",
    "tensorboard --logdir PATH\n",
    "in my case the command came out to be:\n",
    "tensorboard --logdir runs\\Aug13_17-55-29_Mohit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afe8b74-34d7-49f8-a3ab-cd2b8f70f813",
   "metadata": {},
   "source": [
    "## Atari GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8f40c-dba7-4880-afed-1198cd5373d8",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4ab897-8aa5-47b3-b329-30f698a568d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For generating random values\n",
    "import random\n",
    "# for preprocessing images\n",
    "import cv2\n",
    "\n",
    "# for using pytorch\n",
    "import torch\n",
    "# for modules and sequence of neural network\n",
    "import torch.nn as nn\n",
    "# for using optim\n",
    "import torch.optim as optim\n",
    "# keeping the logs\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# transformation of images\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Initializing game environment and playing the game\n",
    "import gym\n",
    "import gym.spaces\n",
    "\n",
    "# for creating arrays and perfoming calculations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a925d92-b182-467c-8129-d86ef453344b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting logger and initializing Variables\n",
    "log = gym.logger\n",
    "log.set_level(gym.logger.INFO)\n",
    "\n",
    "LATENT_VECTOR_SIZE = 100\n",
    "DISCR_FILTERS = 64\n",
    "GENER_FILTERS = 64\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "REPORT_EVERY_ITER = 100\n",
    "SAVE_IMAGE_EVERY_ITER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab16853-95bf-4f15-88e7-61c4e503d217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InputWrapper(gym.ObservationWrapper):\n",
    "    '''\n",
    "    Preprocessing of input numpy array:\n",
    "    1. resizing image into predefined siize\n",
    "    2. move color channel axis to a first place\n",
    "    '''\n",
    "    def __init__(self, *args):\n",
    "        # Overriding the ObservationWrapper with InputWrapper\n",
    "        super(InputWrapper, self).__init__(*args)\n",
    "        # checking if type of observation space is same as that of gym space Box\n",
    "        assert isinstance(self.observation_space, gym.spaces.Box)\n",
    "        # saving previous observation space\n",
    "        old_space = self.observation_space\n",
    "        # Generating new observation space with same specs as old \n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            self.observation(old_space.low),\n",
    "            self.observation(old_space.high),\n",
    "            dtype=np.float32)\n",
    "        \n",
    "    def observation(self, observation):\n",
    "        # resizing image\n",
    "        new_obs = cv2.resize(\n",
    "            observation, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        # transforming (210, 160, 3) -> (3, 210, 160)\n",
    "        new_obs = np.moveaxis(new_obs, 2, 0)\n",
    "        return new_obs.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff24cfd-eaca-4781-a498-c1b3c6650772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    Discriminator checks whether the image generated by generator is according to the given requirement or not\n",
    "    '''\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # creating a model to converge images into a single number\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape[0], out_channels=DISCR_FILTERS,\n",
    "                      kernel_size=4, stride=2, padding=1), #(64, 32, 32)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS, out_channels=DISCR_FILTERS*2,\n",
    "                      kernel_size=4, stride=2, padding=1), #(128, 16, 16)\n",
    "            nn.BatchNorm2d(DISCR_FILTERS*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS*2, out_channels=DISCR_FILTERS*4,\n",
    "                      kernel_size=4, stride=2, padding=1), #(256, 8, 8)\n",
    "            nn.BatchNorm2d(DISCR_FILTERS*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS*4, out_channels=DISCR_FILTERS*8,\n",
    "                      kernel_size=4, stride=2, padding=1), #(512, 4, 4)\n",
    "            nn.BatchNorm2d(DISCR_FILTERS*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS*8, out_channels=1,\n",
    "                      kernel_size=4, stride=1, padding=0), #(1, 1, 1)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_out = self.model(x)\n",
    "        return conv_out.view(-1, 1).squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b805ee6f-85a1-404a-82b8-b7084f91d94b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, output_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        # model deconvolves input vector into (3, 64, 64) image\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=LATENT_VECTOR_SIZE, out_channels=GENER_FILTERS*8,\n",
    "                               kernel_size=4, stride=1, padding=0), #(512, 4, 4)\n",
    "            nn.BatchNorm2d(GENER_FILTERS*8),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS*8, out_channels=GENER_FILTERS*4,\n",
    "                               kernel_size=4, stride=2, padding=1), #(256, 8, 8)\n",
    "            nn.BatchNorm2d(GENER_FILTERS*4),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS*4, out_channels=GENER_FILTERS*2,\n",
    "                               kernel_size=4, stride=2, padding=1), #(128, 16, 16)\n",
    "            nn.BatchNorm2d(GENER_FILTERS*2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS*2, out_channels=GENER_FILTERS,\n",
    "                               kernel_size=4, stride=2, padding=1), #(64, 32, 32)\n",
    "            nn.BatchNorm2d(GENER_FILTERS),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS, out_channels=output_shape[0],\n",
    "                               kernel_size=4, stride=2, padding=1), #(3, 64, 64)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8bdcda-eb55-46fb-b0ee-4b4e5a597b45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iterate_batches(envs, batch_size=BATCH_SIZE):\n",
    "    '''\n",
    "    playing and geting observation for batch_size\n",
    "    '''\n",
    "    batch=[e.reset() for e in envs]\n",
    "    env_gen = iter(lambda: random.choice(envs), None)\n",
    "    \n",
    "    while True:\n",
    "        e = next(env_gen)\n",
    "        obs, reward, is_done, _ = e.step(e.action_space.sample())\n",
    "        if np.mean(obs) > 0.01:\n",
    "            batch.append(obs)\n",
    "        if len(batch) == batch_size:\n",
    "            # Normalizing input between -1 to 1\n",
    "            batch_np = np.array(batch, dtype=np.float32) * 2.0 / 255.0 - 1.0\n",
    "            yield torch.tensor(batch_np)\n",
    "            batch.clear()\n",
    "        if is_done:\n",
    "            e.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46bbea75-9bd5-4d7f-be12-5fa6ad128c23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Making new env: Breakout-v0\n",
      "INFO: Making new env: AirRaid-v0\n",
      "INFO: Making new env: Pong-v0\n",
      "(3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "envs = [\n",
    "    InputWrapper(gym.make(name))\n",
    "    for name in ('Breakout-v0', 'AirRaid-v0', 'Pong-v0')\n",
    "]\n",
    "input_shape = envs[0].observation_space.shape\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21916c81-a9ee-4edd-b659-4ead29a842d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_discr = Discriminator(input_shape=input_shape).to(device)\n",
    "net_gener = Generator(output_shape=input_shape).to(device)\n",
    "\n",
    "# Loss fucntion of Binary Cross Entropy\n",
    "objective = nn.BCELoss()\n",
    "# Optimizer for both generator and Discriminator\n",
    "gen_optimizer = optim.Adam(\n",
    "    params = net_gener.parameters(), lr=LEARNING_RATE,\n",
    "    betas=(0.5, 0.999))\n",
    "dis_optimizer = optim.Adam(\n",
    "    params = net_discr.parameters(), lr=LEARNING_RATE,\n",
    "    betas=(0.5, 0.999))\n",
    "\n",
    "# Tensorboard logs\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77bb7992-ad78-430d-a071-634a18ab9602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_losses = []\n",
    "dis_losses = []\n",
    "iter_no = 0\n",
    "\n",
    "true_labels_v = torch.ones(BATCH_SIZE, device=device)\n",
    "fake_labels_v = torch.zeros(BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb2b0412-9c16-425a-b3a5-1ebb0418b30d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Iter 100: gen_loss=5.561e+00, dis_loss=4.671e-02\n",
      "INFO: Iter 200: gen_loss=7.136e+00, dis_loss=4.518e-03\n",
      "INFO: Iter 300: gen_loss=7.748e+00, dis_loss=2.406e-03\n",
      "INFO: Iter 400: gen_loss=8.021e+00, dis_loss=2.322e-03\n",
      "INFO: Iter 500: gen_loss=8.110e+00, dis_loss=1.083e-03\n",
      "INFO: Iter 600: gen_loss=8.188e+00, dis_loss=1.546e-01\n",
      "INFO: Iter 700: gen_loss=7.006e+00, dis_loss=1.238e-02\n",
      "INFO: Iter 800: gen_loss=6.947e+00, dis_loss=6.379e-03\n",
      "INFO: Iter 900: gen_loss=6.979e+00, dis_loss=3.768e-03\n",
      "INFO: Iter 1000: gen_loss=8.033e+00, dis_loss=2.739e-03\n",
      "INFO: Iter 1100: gen_loss=8.535e+00, dis_loss=2.205e-03\n",
      "INFO: Iter 1200: gen_loss=7.516e+00, dis_loss=2.126e-03\n",
      "INFO: Iter 1300: gen_loss=7.801e+00, dis_loss=1.084e-03\n",
      "INFO: Iter 1400: gen_loss=8.568e+00, dis_loss=1.603e-02\n",
      "INFO: Iter 1500: gen_loss=1.154e+01, dis_loss=3.796e-02\n",
      "INFO: Iter 1600: gen_loss=7.052e+00, dis_loss=8.256e-02\n",
      "INFO: Iter 1700: gen_loss=6.813e+00, dis_loss=9.074e-03\n",
      "INFO: Iter 1800: gen_loss=6.462e+00, dis_loss=1.195e-01\n",
      "INFO: Iter 1900: gen_loss=5.689e+00, dis_loss=3.118e-02\n",
      "INFO: Iter 2000: gen_loss=5.964e+00, dis_loss=3.854e-01\n",
      "INFO: Iter 2100: gen_loss=4.659e+00, dis_loss=3.199e-01\n",
      "INFO: Iter 2200: gen_loss=4.746e+00, dis_loss=3.276e-01\n",
      "INFO: Iter 2300: gen_loss=5.226e+00, dis_loss=1.970e-01\n",
      "INFO: Iter 2400: gen_loss=5.179e+00, dis_loss=2.442e-01\n",
      "INFO: Iter 2500: gen_loss=4.995e+00, dis_loss=2.258e-01\n",
      "INFO: Iter 2600: gen_loss=5.083e+00, dis_loss=2.602e-01\n",
      "INFO: Iter 2700: gen_loss=5.430e+00, dis_loss=1.088e-01\n",
      "INFO: Iter 2800: gen_loss=5.802e+00, dis_loss=1.790e-01\n",
      "INFO: Iter 2900: gen_loss=5.046e+00, dis_loss=1.839e-01\n",
      "INFO: Iter 3000: gen_loss=4.979e+00, dis_loss=2.508e-01\n",
      "INFO: Iter 3100: gen_loss=6.024e+00, dis_loss=3.301e-02\n",
      "INFO: Iter 3200: gen_loss=7.177e+00, dis_loss=1.028e-01\n",
      "INFO: Iter 3300: gen_loss=7.142e+00, dis_loss=2.289e-02\n",
      "INFO: Iter 3400: gen_loss=7.675e+00, dis_loss=2.512e-02\n",
      "INFO: Iter 3500: gen_loss=4.990e+00, dis_loss=4.541e-01\n",
      "INFO: Iter 3600: gen_loss=6.152e+00, dis_loss=2.740e-02\n",
      "INFO: Iter 3700: gen_loss=7.017e+00, dis_loss=3.361e-02\n",
      "INFO: Iter 3800: gen_loss=8.054e+00, dis_loss=6.426e-03\n",
      "INFO: Iter 3900: gen_loss=8.203e+00, dis_loss=1.433e-02\n",
      "INFO: Iter 4000: gen_loss=9.150e+00, dis_loss=8.837e-03\n",
      "INFO: Iter 4100: gen_loss=6.750e+00, dis_loss=2.561e-01\n",
      "INFO: Iter 4200: gen_loss=7.139e+00, dis_loss=5.482e-02\n",
      "INFO: Iter 4300: gen_loss=6.734e+00, dis_loss=8.992e-02\n",
      "INFO: Iter 4400: gen_loss=8.137e+00, dis_loss=3.970e-02\n",
      "INFO: Iter 4500: gen_loss=8.792e+00, dis_loss=2.091e-02\n",
      "INFO: Iter 4600: gen_loss=9.598e+00, dis_loss=6.806e-03\n",
      "INFO: Iter 4700: gen_loss=8.093e+00, dis_loss=9.383e-02\n",
      "INFO: Iter 4800: gen_loss=8.078e+00, dis_loss=1.082e-02\n",
      "INFO: Iter 4900: gen_loss=8.024e+00, dis_loss=1.638e-01\n",
      "INFO: Iter 5000: gen_loss=7.494e+00, dis_loss=5.584e-02\n",
      "INFO: Iter 5100: gen_loss=8.375e+00, dis_loss=1.851e-02\n",
      "INFO: Iter 5200: gen_loss=9.558e+00, dis_loss=7.469e-03\n",
      "INFO: Iter 5300: gen_loss=1.002e+01, dis_loss=5.114e-03\n",
      "INFO: Iter 5400: gen_loss=1.025e+01, dis_loss=4.163e-03\n",
      "INFO: Iter 5500: gen_loss=7.806e+00, dis_loss=5.095e-01\n",
      "INFO: Iter 5600: gen_loss=4.077e+00, dis_loss=4.454e-01\n",
      "INFO: Iter 5700: gen_loss=5.011e+00, dis_loss=2.999e-01\n",
      "INFO: Iter 5800: gen_loss=5.023e+00, dis_loss=2.958e-01\n",
      "INFO: Iter 5900: gen_loss=4.943e+00, dis_loss=3.398e-01\n",
      "INFO: Iter 6000: gen_loss=4.442e+00, dis_loss=4.726e-01\n",
      "INFO: Iter 6100: gen_loss=5.324e+00, dis_loss=1.717e-01\n",
      "INFO: Iter 6200: gen_loss=6.230e+00, dis_loss=1.681e-01\n",
      "INFO: Iter 6300: gen_loss=5.035e+00, dis_loss=2.154e-01\n",
      "INFO: Iter 6400: gen_loss=4.737e+00, dis_loss=2.437e-01\n",
      "INFO: Iter 6500: gen_loss=5.891e+00, dis_loss=1.274e-01\n",
      "INFO: Iter 6600: gen_loss=5.821e+00, dis_loss=1.377e-01\n",
      "INFO: Iter 6700: gen_loss=6.480e+00, dis_loss=3.061e-02\n",
      "INFO: Iter 6800: gen_loss=7.870e+00, dis_loss=1.169e-01\n",
      "INFO: Iter 6900: gen_loss=5.281e+00, dis_loss=2.543e-01\n",
      "INFO: Iter 7000: gen_loss=6.736e+00, dis_loss=1.073e-01\n",
      "INFO: Iter 7100: gen_loss=5.880e+00, dis_loss=1.628e-01\n",
      "INFO: Iter 7200: gen_loss=5.580e+00, dis_loss=1.298e-01\n",
      "INFO: Iter 7300: gen_loss=6.670e+00, dis_loss=4.388e-02\n",
      "INFO: Iter 7400: gen_loss=7.736e+00, dis_loss=9.058e-03\n",
      "INFO: Iter 7500: gen_loss=6.407e+00, dis_loss=1.790e-01\n",
      "INFO: Iter 7600: gen_loss=5.207e+00, dis_loss=2.356e-01\n",
      "INFO: Iter 7700: gen_loss=7.629e+00, dis_loss=1.823e-02\n",
      "INFO: Iter 7800: gen_loss=5.730e+00, dis_loss=2.287e-01\n",
      "INFO: Iter 7900: gen_loss=6.889e+00, dis_loss=1.663e-02\n",
      "INFO: Iter 8000: gen_loss=7.673e+00, dis_loss=2.575e-02\n",
      "INFO: Iter 8100: gen_loss=6.193e+00, dis_loss=1.785e-01\n",
      "INFO: Iter 8200: gen_loss=7.326e+00, dis_loss=2.246e-02\n",
      "INFO: Iter 8300: gen_loss=8.152e+00, dis_loss=4.554e-03\n",
      "INFO: Iter 8400: gen_loss=7.812e+00, dis_loss=1.858e-01\n",
      "INFO: Iter 8500: gen_loss=6.127e+00, dis_loss=1.035e-01\n",
      "INFO: Iter 8600: gen_loss=7.262e+00, dis_loss=1.132e-02\n",
      "INFO: Iter 8700: gen_loss=5.997e+00, dis_loss=1.880e-01\n",
      "INFO: Iter 8800: gen_loss=5.913e+00, dis_loss=2.173e-01\n",
      "INFO: Iter 8900: gen_loss=5.500e+00, dis_loss=3.672e-01\n",
      "INFO: Iter 9000: gen_loss=5.511e+00, dis_loss=2.139e-01\n",
      "INFO: Iter 9100: gen_loss=5.657e+00, dis_loss=3.384e-02\n",
      "INFO: Iter 9200: gen_loss=6.553e+00, dis_loss=6.739e-02\n",
      "INFO: Iter 9300: gen_loss=5.703e+00, dis_loss=2.485e-01\n",
      "INFO: Iter 9400: gen_loss=5.687e+00, dis_loss=9.292e-02\n",
      "INFO: Iter 9500: gen_loss=6.506e+00, dis_loss=6.829e-02\n",
      "INFO: Iter 9600: gen_loss=5.988e+00, dis_loss=9.248e-02\n",
      "INFO: Iter 9700: gen_loss=6.599e+00, dis_loss=6.800e-03\n",
      "INFO: Iter 9800: gen_loss=7.130e+00, dis_loss=4.599e-03\n",
      "INFO: Iter 9900: gen_loss=7.840e+00, dis_loss=4.206e-03\n",
      "INFO: Iter 10000: gen_loss=8.799e+00, dis_loss=3.345e-03\n",
      "INFO: Iter 10100: gen_loss=8.544e+00, dis_loss=3.047e-03\n",
      "INFO: Iter 10200: gen_loss=9.324e+00, dis_loss=2.959e-03\n",
      "INFO: Iter 10300: gen_loss=6.069e+00, dis_loss=2.416e-01\n",
      "INFO: Iter 10400: gen_loss=6.280e+00, dis_loss=1.816e-01\n",
      "INFO: Iter 10500: gen_loss=4.786e+00, dis_loss=2.752e-01\n",
      "INFO: Iter 10600: gen_loss=5.567e+00, dis_loss=1.110e-01\n",
      "INFO: Iter 10700: gen_loss=6.650e+00, dis_loss=1.318e-02\n",
      "INFO: Iter 10800: gen_loss=7.089e+00, dis_loss=6.015e-03\n",
      "INFO: Iter 10900: gen_loss=7.914e+00, dis_loss=1.207e-02\n",
      "INFO: Iter 11000: gen_loss=6.012e+00, dis_loss=1.195e-01\n",
      "INFO: Iter 11100: gen_loss=7.107e+00, dis_loss=3.091e-03\n",
      "INFO: Iter 11200: gen_loss=7.191e+00, dis_loss=2.670e-03\n",
      "INFO: Iter 11300: gen_loss=7.244e+00, dis_loss=8.493e-02\n",
      "INFO: Iter 11400: gen_loss=6.917e+00, dis_loss=1.077e-01\n",
      "INFO: Iter 11500: gen_loss=6.049e+00, dis_loss=2.115e-01\n",
      "INFO: Iter 11600: gen_loss=5.202e+00, dis_loss=1.931e-01\n",
      "INFO: Iter 11700: gen_loss=6.834e+00, dis_loss=2.839e-02\n",
      "INFO: Iter 11800: gen_loss=6.205e+00, dis_loss=2.027e-01\n",
      "INFO: Iter 11900: gen_loss=6.747e+00, dis_loss=9.141e-02\n",
      "INFO: Iter 12000: gen_loss=6.685e+00, dis_loss=1.928e-01\n",
      "INFO: Iter 12100: gen_loss=6.219e+00, dis_loss=1.007e-01\n",
      "INFO: Iter 12200: gen_loss=5.503e+00, dis_loss=2.321e-01\n",
      "INFO: Iter 12300: gen_loss=7.058e+00, dis_loss=2.058e-02\n",
      "INFO: Iter 12400: gen_loss=6.026e+00, dis_loss=8.553e-02\n",
      "INFO: Iter 12500: gen_loss=6.833e+00, dis_loss=7.856e-03\n",
      "INFO: Iter 12600: gen_loss=6.683e+00, dis_loss=1.301e-01\n",
      "INFO: Iter 12700: gen_loss=6.876e+00, dis_loss=3.159e-02\n",
      "INFO: Iter 12800: gen_loss=7.368e+00, dis_loss=2.182e-02\n",
      "INFO: Iter 12900: gen_loss=5.993e+00, dis_loss=2.891e-01\n",
      "INFO: Iter 13000: gen_loss=5.723e+00, dis_loss=1.725e-02\n",
      "INFO: Iter 13100: gen_loss=7.119e+00, dis_loss=1.047e-02\n",
      "INFO: Iter 13200: gen_loss=8.847e+00, dis_loss=9.211e-02\n",
      "INFO: Iter 13300: gen_loss=7.678e+00, dis_loss=4.577e-02\n",
      "INFO: Iter 13400: gen_loss=6.361e+00, dis_loss=2.936e-01\n",
      "INFO: Iter 13500: gen_loss=5.477e+00, dis_loss=1.970e-01\n",
      "INFO: Iter 13600: gen_loss=5.220e+00, dis_loss=1.616e-01\n",
      "INFO: Iter 13700: gen_loss=6.568e+00, dis_loss=1.388e-01\n",
      "INFO: Iter 13800: gen_loss=5.962e+00, dis_loss=1.020e-01\n",
      "INFO: Iter 13900: gen_loss=6.068e+00, dis_loss=1.560e-01\n",
      "INFO: Iter 14000: gen_loss=6.849e+00, dis_loss=5.787e-02\n",
      "INFO: Iter 14100: gen_loss=7.011e+00, dis_loss=2.275e-02\n",
      "INFO: Iter 14200: gen_loss=7.215e+00, dis_loss=1.876e-02\n",
      "INFO: Iter 14300: gen_loss=6.207e+00, dis_loss=2.417e-01\n",
      "INFO: Iter 14400: gen_loss=6.027e+00, dis_loss=1.171e-02\n",
      "INFO: Iter 14500: gen_loss=5.609e+00, dis_loss=2.806e-01\n",
      "INFO: Iter 14600: gen_loss=6.033e+00, dis_loss=1.309e-01\n",
      "INFO: Iter 14700: gen_loss=6.803e+00, dis_loss=1.212e-01\n",
      "INFO: Iter 14800: gen_loss=6.545e+00, dis_loss=7.181e-02\n",
      "INFO: Iter 14900: gen_loss=6.967e+00, dis_loss=8.857e-03\n",
      "INFO: Iter 15000: gen_loss=7.808e+00, dis_loss=7.146e-03\n",
      "INFO: Iter 15100: gen_loss=7.377e+00, dis_loss=7.152e-03\n",
      "INFO: Iter 15200: gen_loss=7.350e+00, dis_loss=6.564e-03\n",
      "INFO: Iter 15300: gen_loss=6.371e+00, dis_loss=6.785e-03\n",
      "INFO: Iter 15400: gen_loss=6.679e+00, dis_loss=1.099e-02\n",
      "INFO: Iter 15500: gen_loss=5.663e+00, dis_loss=1.091e-01\n",
      "INFO: Iter 15600: gen_loss=6.689e+00, dis_loss=8.216e-03\n",
      "INFO: Iter 15700: gen_loss=6.669e+00, dis_loss=8.098e-02\n",
      "INFO: Iter 15800: gen_loss=6.771e+00, dis_loss=5.881e-03\n",
      "INFO: Iter 15900: gen_loss=6.800e+00, dis_loss=2.283e-02\n",
      "INFO: Iter 16000: gen_loss=6.581e+00, dis_loss=1.660e-02\n",
      "INFO: Iter 16100: gen_loss=7.712e+00, dis_loss=3.697e-03\n",
      "INFO: Iter 16200: gen_loss=8.335e+00, dis_loss=4.908e-03\n",
      "INFO: Iter 16300: gen_loss=7.967e+00, dis_loss=4.673e-02\n",
      "INFO: Iter 16400: gen_loss=8.124e+00, dis_loss=3.936e-03\n",
      "INFO: Iter 16500: gen_loss=7.975e+00, dis_loss=6.122e-02\n",
      "INFO: Iter 16600: gen_loss=8.748e+00, dis_loss=5.677e-03\n",
      "INFO: Iter 16700: gen_loss=8.838e+00, dis_loss=1.473e-02\n",
      "INFO: Iter 16800: gen_loss=9.906e+00, dis_loss=2.736e-03\n",
      "INFO: Iter 16900: gen_loss=9.993e+00, dis_loss=1.347e-03\n",
      "INFO: Iter 17000: gen_loss=9.414e+00, dis_loss=1.609e-03\n",
      "INFO: Iter 17100: gen_loss=9.387e+00, dis_loss=1.031e-03\n",
      "INFO: Iter 17200: gen_loss=9.402e+00, dis_loss=1.044e-03\n",
      "INFO: Iter 17300: gen_loss=1.006e+01, dis_loss=3.567e-03\n",
      "INFO: Iter 17400: gen_loss=6.066e+00, dis_loss=4.353e-01\n",
      "INFO: Iter 17500: gen_loss=7.438e+00, dis_loss=2.167e-02\n",
      "INFO: Iter 17600: gen_loss=7.801e+00, dis_loss=7.588e-03\n",
      "INFO: Iter 17700: gen_loss=8.725e+00, dis_loss=5.221e-03\n",
      "INFO: Iter 17800: gen_loss=7.125e+00, dis_loss=1.830e-01\n",
      "INFO: Iter 17900: gen_loss=6.950e+00, dis_loss=1.443e-01\n",
      "INFO: Iter 18000: gen_loss=7.822e+00, dis_loss=1.736e-01\n",
      "INFO: Iter 18100: gen_loss=6.680e+00, dis_loss=2.336e-01\n",
      "INFO: Iter 18200: gen_loss=6.190e+00, dis_loss=1.969e-01\n",
      "INFO: Iter 18300: gen_loss=6.235e+00, dis_loss=1.390e-02\n",
      "INFO: Iter 18400: gen_loss=6.426e+00, dis_loss=4.283e-03\n",
      "INFO: Iter 18500: gen_loss=6.802e+00, dis_loss=3.612e-03\n",
      "INFO: Iter 18600: gen_loss=6.984e+00, dis_loss=2.519e-03\n",
      "INFO: Iter 18700: gen_loss=7.122e+00, dis_loss=2.900e-03\n",
      "INFO: Iter 18800: gen_loss=7.243e+00, dis_loss=1.960e-03\n",
      "INFO: Iter 18900: gen_loss=7.003e+00, dis_loss=2.603e-03\n",
      "INFO: Iter 19000: gen_loss=7.390e+00, dis_loss=2.098e-03\n",
      "INFO: Iter 19100: gen_loss=7.607e+00, dis_loss=1.637e-03\n",
      "INFO: Iter 19200: gen_loss=7.521e+00, dis_loss=1.653e-03\n",
      "INFO: Iter 19300: gen_loss=7.861e+00, dis_loss=1.155e-03\n",
      "INFO: Iter 19400: gen_loss=7.948e+00, dis_loss=1.153e-03\n",
      "INFO: Iter 19500: gen_loss=8.401e+00, dis_loss=8.452e-04\n",
      "INFO: Iter 19600: gen_loss=8.648e+00, dis_loss=6.764e-04\n",
      "INFO: Iter 19700: gen_loss=8.744e+00, dis_loss=7.934e-04\n",
      "INFO: Iter 19800: gen_loss=9.108e+00, dis_loss=4.432e-04\n",
      "INFO: Iter 19900: gen_loss=9.018e+00, dis_loss=1.171e-03\n",
      "INFO: Iter 20000: gen_loss=9.482e+00, dis_loss=2.981e-04\n",
      "INFO: Iter 20100: gen_loss=9.486e+00, dis_loss=3.191e-04\n",
      "INFO: Iter 20200: gen_loss=9.555e+00, dis_loss=3.707e-04\n",
      "INFO: Iter 20300: gen_loss=9.523e+00, dis_loss=3.284e-04\n",
      "INFO: Iter 20400: gen_loss=9.956e+00, dis_loss=2.452e-04\n",
      "INFO: Iter 20500: gen_loss=9.816e+00, dis_loss=2.946e-04\n",
      "INFO: Iter 20600: gen_loss=9.919e+00, dis_loss=2.267e-04\n",
      "INFO: Iter 20700: gen_loss=9.794e+00, dis_loss=2.797e-04\n",
      "INFO: Iter 20800: gen_loss=1.023e+01, dis_loss=1.953e-04\n",
      "INFO: Iter 20900: gen_loss=9.536e+00, dis_loss=2.440e-01\n",
      "INFO: Iter 21000: gen_loss=6.272e+00, dis_loss=1.933e-01\n",
      "INFO: Iter 21100: gen_loss=6.011e+00, dis_loss=2.291e-01\n",
      "INFO: Iter 21200: gen_loss=4.637e+00, dis_loss=3.222e-01\n",
      "INFO: Iter 21300: gen_loss=6.598e+00, dis_loss=1.195e-02\n",
      "INFO: Iter 21400: gen_loss=6.091e+00, dis_loss=3.595e-01\n",
      "INFO: Iter 21500: gen_loss=5.526e+00, dis_loss=1.898e-01\n",
      "INFO: Iter 21600: gen_loss=4.907e+00, dis_loss=2.320e-01\n",
      "INFO: Iter 21700: gen_loss=6.189e+00, dis_loss=1.321e-01\n",
      "INFO: Iter 21800: gen_loss=6.158e+00, dis_loss=1.158e-02\n",
      "INFO: Iter 21900: gen_loss=6.274e+00, dis_loss=1.123e-01\n",
      "INFO: Iter 22000: gen_loss=6.768e+00, dis_loss=1.909e-02\n",
      "INFO: Iter 22100: gen_loss=7.968e+00, dis_loss=9.635e-02\n",
      "INFO: Iter 22200: gen_loss=7.076e+00, dis_loss=8.105e-02\n",
      "INFO: Iter 22300: gen_loss=6.776e+00, dis_loss=1.449e-01\n",
      "INFO: Iter 22400: gen_loss=7.875e+00, dis_loss=1.051e-02\n",
      "INFO: Iter 22500: gen_loss=7.177e+00, dis_loss=1.760e-01\n",
      "INFO: Iter 22600: gen_loss=6.438e+00, dis_loss=1.031e-02\n",
      "INFO: Iter 22700: gen_loss=7.554e+00, dis_loss=9.475e-03\n",
      "INFO: Iter 22800: gen_loss=7.641e+00, dis_loss=1.792e-01\n",
      "INFO: Iter 22900: gen_loss=7.728e+00, dis_loss=1.874e-02\n",
      "INFO: Iter 23000: gen_loss=7.149e+00, dis_loss=1.399e-01\n",
      "INFO: Iter 23100: gen_loss=5.760e+00, dis_loss=9.523e-02\n",
      "INFO: Iter 23200: gen_loss=7.110e+00, dis_loss=1.911e-01\n",
      "INFO: Iter 23300: gen_loss=4.404e+00, dis_loss=3.295e-01\n",
      "INFO: Iter 23400: gen_loss=6.143e+00, dis_loss=1.091e-01\n",
      "INFO: Iter 23500: gen_loss=7.217e+00, dis_loss=1.094e-02\n",
      "INFO: Iter 23600: gen_loss=7.336e+00, dis_loss=7.018e-03\n",
      "INFO: Iter 23700: gen_loss=6.724e+00, dis_loss=2.000e-01\n",
      "INFO: Iter 23800: gen_loss=6.114e+00, dis_loss=8.620e-03\n",
      "INFO: Iter 23900: gen_loss=7.922e+00, dis_loss=7.852e-03\n",
      "INFO: Iter 24000: gen_loss=6.958e+00, dis_loss=9.952e-02\n",
      "INFO: Iter 24100: gen_loss=6.319e+00, dis_loss=1.450e-01\n",
      "INFO: Iter 24200: gen_loss=6.310e+00, dis_loss=1.922e-01\n",
      "INFO: Iter 24300: gen_loss=6.291e+00, dis_loss=7.167e-02\n",
      "INFO: Iter 24400: gen_loss=6.082e+00, dis_loss=1.819e-01\n",
      "INFO: Iter 24500: gen_loss=5.863e+00, dis_loss=1.598e-02\n",
      "INFO: Iter 24600: gen_loss=7.582e+00, dis_loss=1.154e-01\n",
      "INFO: Iter 24700: gen_loss=7.334e+00, dis_loss=1.595e-01\n",
      "INFO: Iter 24800: gen_loss=7.295e+00, dis_loss=5.497e-02\n",
      "INFO: Iter 24900: gen_loss=7.125e+00, dis_loss=1.873e-01\n",
      "INFO: Iter 25000: gen_loss=5.849e+00, dis_loss=4.471e-02\n",
      "INFO: Iter 25100: gen_loss=6.409e+00, dis_loss=1.509e-01\n",
      "INFO: Iter 25200: gen_loss=7.219e+00, dis_loss=1.429e-01\n",
      "INFO: Iter 25300: gen_loss=5.956e+00, dis_loss=2.395e-01\n",
      "INFO: Iter 25400: gen_loss=6.001e+00, dis_loss=3.924e-02\n",
      "INFO: Iter 25500: gen_loss=6.323e+00, dis_loss=1.211e-01\n",
      "INFO: Iter 25600: gen_loss=7.338e+00, dis_loss=2.036e-02\n",
      "INFO: Iter 25700: gen_loss=6.080e+00, dis_loss=1.524e-01\n",
      "INFO: Iter 25800: gen_loss=6.550e+00, dis_loss=9.048e-03\n",
      "INFO: Iter 25900: gen_loss=7.177e+00, dis_loss=5.258e-02\n",
      "INFO: Iter 26000: gen_loss=5.899e+00, dis_loss=1.931e-01\n",
      "INFO: Iter 26100: gen_loss=7.228e+00, dis_loss=1.206e-01\n",
      "INFO: Iter 26200: gen_loss=7.720e+00, dis_loss=2.070e-01\n",
      "INFO: Iter 26300: gen_loss=5.957e+00, dis_loss=1.012e-02\n",
      "INFO: Iter 26400: gen_loss=7.680e+00, dis_loss=1.053e-02\n",
      "INFO: Iter 26500: gen_loss=8.274e+00, dis_loss=8.221e-02\n",
      "INFO: Iter 26600: gen_loss=6.517e+00, dis_loss=2.689e-01\n",
      "INFO: Iter 26700: gen_loss=6.150e+00, dis_loss=2.842e-02\n",
      "INFO: Iter 26800: gen_loss=6.420e+00, dis_loss=1.067e-01\n",
      "INFO: Iter 26900: gen_loss=5.630e+00, dis_loss=7.619e-02\n",
      "INFO: Iter 27000: gen_loss=6.515e+00, dis_loss=1.586e-01\n",
      "INFO: Iter 27100: gen_loss=6.527e+00, dis_loss=7.238e-03\n",
      "INFO: Iter 27200: gen_loss=7.530e+00, dis_loss=5.698e-02\n",
      "INFO: Iter 27300: gen_loss=7.394e+00, dis_loss=1.946e-01\n",
      "INFO: Iter 27400: gen_loss=6.684e+00, dis_loss=1.773e-02\n",
      "INFO: Iter 27500: gen_loss=7.622e+00, dis_loss=1.432e-01\n",
      "INFO: Iter 27600: gen_loss=6.809e+00, dis_loss=2.814e-02\n",
      "INFO: Iter 27700: gen_loss=7.716e+00, dis_loss=4.562e-03\n",
      "INFO: Iter 27800: gen_loss=7.042e+00, dis_loss=2.054e-01\n",
      "INFO: Iter 27900: gen_loss=6.439e+00, dis_loss=1.137e-01\n",
      "INFO: Iter 28000: gen_loss=7.681e+00, dis_loss=1.444e-01\n",
      "INFO: Iter 28100: gen_loss=5.844e+00, dis_loss=2.168e-01\n",
      "INFO: Iter 28200: gen_loss=6.738e+00, dis_loss=1.865e-01\n",
      "INFO: Iter 28300: gen_loss=5.990e+00, dis_loss=2.332e-01\n",
      "INFO: Iter 28400: gen_loss=6.557e+00, dis_loss=6.011e-02\n",
      "INFO: Iter 28500: gen_loss=5.826e+00, dis_loss=1.282e-01\n",
      "INFO: Iter 28600: gen_loss=7.035e+00, dis_loss=9.041e-02\n",
      "INFO: Iter 28700: gen_loss=7.978e+00, dis_loss=1.720e-01\n",
      "INFO: Iter 28800: gen_loss=5.583e+00, dis_loss=1.381e-02\n",
      "INFO: Iter 28900: gen_loss=6.536e+00, dis_loss=1.656e-02\n",
      "INFO: Iter 29000: gen_loss=7.587e+00, dis_loss=1.245e-01\n",
      "INFO: Iter 29100: gen_loss=6.026e+00, dis_loss=1.299e-01\n",
      "INFO: Iter 29200: gen_loss=6.349e+00, dis_loss=1.458e-01\n",
      "INFO: Iter 29300: gen_loss=6.117e+00, dis_loss=1.311e-01\n",
      "INFO: Iter 29400: gen_loss=7.593e+00, dis_loss=2.037e-01\n",
      "INFO: Iter 29500: gen_loss=7.023e+00, dis_loss=5.369e-02\n",
      "INFO: Iter 29600: gen_loss=6.777e+00, dis_loss=1.015e-01\n",
      "INFO: Iter 29700: gen_loss=6.747e+00, dis_loss=1.859e-01\n",
      "INFO: Iter 29800: gen_loss=4.855e+00, dis_loss=2.247e-01\n",
      "INFO: Iter 29900: gen_loss=6.530e+00, dis_loss=1.060e-02\n",
      "INFO: Iter 30000: gen_loss=7.931e+00, dis_loss=1.345e-01\n",
      "INFO: Iter 30100: gen_loss=6.968e+00, dis_loss=2.912e-02\n",
      "INFO: Iter 30200: gen_loss=7.390e+00, dis_loss=1.290e-01\n",
      "INFO: Iter 30300: gen_loss=7.780e+00, dis_loss=1.213e-01\n",
      "INFO: Iter 30400: gen_loss=7.876e+00, dis_loss=9.066e-02\n",
      "INFO: Iter 30500: gen_loss=7.849e+00, dis_loss=3.989e-02\n",
      "INFO: Iter 30600: gen_loss=6.864e+00, dis_loss=2.379e-02\n",
      "INFO: Iter 30700: gen_loss=6.615e+00, dis_loss=2.369e-01\n",
      "INFO: Iter 30800: gen_loss=6.707e+00, dis_loss=1.646e-01\n",
      "INFO: Iter 30900: gen_loss=6.682e+00, dis_loss=8.159e-02\n",
      "INFO: Iter 31000: gen_loss=6.433e+00, dis_loss=2.247e-01\n",
      "INFO: Iter 31100: gen_loss=5.968e+00, dis_loss=1.515e-02\n",
      "INFO: Iter 31200: gen_loss=6.296e+00, dis_loss=2.636e-01\n",
      "INFO: Iter 31300: gen_loss=5.839e+00, dis_loss=1.954e-02\n",
      "INFO: Iter 31400: gen_loss=7.374e+00, dis_loss=1.633e-01\n",
      "INFO: Iter 31500: gen_loss=5.894e+00, dis_loss=7.637e-02\n",
      "INFO: Iter 31600: gen_loss=6.647e+00, dis_loss=2.032e-01\n",
      "INFO: Iter 31700: gen_loss=7.086e+00, dis_loss=1.103e-01\n",
      "INFO: Iter 31800: gen_loss=7.574e+00, dis_loss=4.892e-02\n",
      "INFO: Iter 31900: gen_loss=8.391e+00, dis_loss=9.193e-02\n",
      "INFO: Iter 32000: gen_loss=6.889e+00, dis_loss=2.139e-01\n",
      "INFO: Iter 32100: gen_loss=5.964e+00, dis_loss=1.464e-01\n",
      "INFO: Iter 32200: gen_loss=6.786e+00, dis_loss=1.548e-01\n",
      "INFO: Iter 32300: gen_loss=7.398e+00, dis_loss=6.781e-02\n",
      "INFO: Iter 32400: gen_loss=8.364e+00, dis_loss=1.682e-01\n",
      "INFO: Iter 32500: gen_loss=7.507e+00, dis_loss=1.501e-01\n",
      "INFO: Iter 32600: gen_loss=6.776e+00, dis_loss=1.112e-01\n",
      "INFO: Iter 32700: gen_loss=6.907e+00, dis_loss=1.056e-01\n",
      "INFO: Iter 32800: gen_loss=6.943e+00, dis_loss=1.355e-01\n",
      "INFO: Iter 32900: gen_loss=6.283e+00, dis_loss=2.010e-01\n",
      "INFO: Iter 33000: gen_loss=4.836e+00, dis_loss=2.042e-01\n",
      "INFO: Iter 33100: gen_loss=5.088e+00, dis_loss=7.918e-02\n",
      "INFO: Iter 33200: gen_loss=5.594e+00, dis_loss=9.726e-03\n",
      "INFO: Iter 33300: gen_loss=5.985e+00, dis_loss=1.526e-02\n",
      "INFO: Iter 33400: gen_loss=6.760e+00, dis_loss=3.892e-01\n",
      "INFO: Iter 33500: gen_loss=6.664e+00, dis_loss=7.813e-02\n",
      "INFO: Iter 33600: gen_loss=7.597e+00, dis_loss=1.164e-01\n",
      "INFO: Iter 33700: gen_loss=6.592e+00, dis_loss=2.288e-01\n",
      "INFO: Iter 33800: gen_loss=6.386e+00, dis_loss=6.439e-02\n",
      "INFO: Iter 33900: gen_loss=6.604e+00, dis_loss=1.266e-01\n",
      "INFO: Iter 34000: gen_loss=6.354e+00, dis_loss=2.978e-02\n",
      "INFO: Iter 34100: gen_loss=6.683e+00, dis_loss=2.263e-02\n",
      "INFO: Iter 34200: gen_loss=7.970e+00, dis_loss=2.270e-01\n",
      "INFO: Iter 34300: gen_loss=5.927e+00, dis_loss=1.142e-01\n",
      "INFO: Iter 34400: gen_loss=5.937e+00, dis_loss=3.293e-01\n",
      "INFO: Iter 34500: gen_loss=4.103e+00, dis_loss=1.930e-01\n",
      "INFO: Iter 34600: gen_loss=5.679e+00, dis_loss=8.825e-02\n",
      "INFO: Iter 34700: gen_loss=6.630e+00, dis_loss=1.617e-01\n",
      "INFO: Iter 34800: gen_loss=7.845e+00, dis_loss=1.412e-01\n",
      "INFO: Iter 34900: gen_loss=6.534e+00, dis_loss=6.103e-02\n",
      "INFO: Iter 35000: gen_loss=4.815e+00, dis_loss=3.196e-01\n",
      "INFO: Iter 35100: gen_loss=5.096e+00, dis_loss=8.265e-02\n",
      "INFO: Iter 35200: gen_loss=7.455e+00, dis_loss=6.810e-02\n",
      "INFO: Iter 35300: gen_loss=7.619e+00, dis_loss=1.866e-01\n",
      "INFO: Iter 35400: gen_loss=7.079e+00, dis_loss=1.234e-01\n",
      "INFO: Iter 35500: gen_loss=6.574e+00, dis_loss=1.791e-01\n",
      "INFO: Iter 35600: gen_loss=7.066e+00, dis_loss=1.304e-01\n",
      "INFO: Iter 35700: gen_loss=6.556e+00, dis_loss=2.807e-02\n",
      "INFO: Iter 35800: gen_loss=6.682e+00, dis_loss=5.789e-02\n",
      "INFO: Iter 35900: gen_loss=7.090e+00, dis_loss=1.361e-01\n",
      "INFO: Iter 36000: gen_loss=7.134e+00, dis_loss=5.676e-02\n",
      "INFO: Iter 36100: gen_loss=7.758e+00, dis_loss=1.753e-01\n",
      "INFO: Iter 36200: gen_loss=6.642e+00, dis_loss=2.305e-01\n",
      "INFO: Iter 36300: gen_loss=6.676e+00, dis_loss=2.703e-01\n",
      "INFO: Iter 36400: gen_loss=5.223e+00, dis_loss=1.332e-01\n",
      "INFO: Iter 36500: gen_loss=6.606e+00, dis_loss=1.077e-01\n",
      "INFO: Iter 36600: gen_loss=6.688e+00, dis_loss=1.359e-01\n",
      "INFO: Iter 36700: gen_loss=6.919e+00, dis_loss=1.438e-01\n",
      "INFO: Iter 36800: gen_loss=6.934e+00, dis_loss=8.851e-02\n",
      "INFO: Iter 36900: gen_loss=6.552e+00, dis_loss=1.082e-01\n",
      "INFO: Iter 37000: gen_loss=7.610e+00, dis_loss=9.799e-02\n",
      "INFO: Iter 37100: gen_loss=7.845e+00, dis_loss=9.923e-02\n",
      "INFO: Iter 37200: gen_loss=7.644e+00, dis_loss=1.124e-01\n",
      "INFO: Iter 37300: gen_loss=6.984e+00, dis_loss=1.408e-01\n",
      "INFO: Iter 37400: gen_loss=7.047e+00, dis_loss=1.300e-01\n",
      "INFO: Iter 37500: gen_loss=7.633e+00, dis_loss=1.198e-01\n",
      "INFO: Iter 37600: gen_loss=7.187e+00, dis_loss=8.194e-02\n",
      "INFO: Iter 37700: gen_loss=7.053e+00, dis_loss=2.681e-01\n",
      "INFO: Iter 37800: gen_loss=6.763e+00, dis_loss=5.792e-02\n",
      "INFO: Iter 37900: gen_loss=6.295e+00, dis_loss=2.038e-01\n",
      "INFO: Iter 38000: gen_loss=6.605e+00, dis_loss=1.947e-01\n",
      "INFO: Iter 38100: gen_loss=6.594e+00, dis_loss=6.815e-02\n",
      "INFO: Iter 38200: gen_loss=7.326e+00, dis_loss=1.211e-01\n",
      "INFO: Iter 38300: gen_loss=7.199e+00, dis_loss=2.173e-01\n",
      "INFO: Iter 38400: gen_loss=7.175e+00, dis_loss=8.846e-02\n",
      "INFO: Iter 38500: gen_loss=6.617e+00, dis_loss=1.397e-01\n",
      "INFO: Iter 38600: gen_loss=7.622e+00, dis_loss=2.112e-01\n",
      "INFO: Iter 38700: gen_loss=7.251e+00, dis_loss=5.948e-02\n",
      "INFO: Iter 38800: gen_loss=7.763e+00, dis_loss=9.727e-02\n",
      "INFO: Iter 38900: gen_loss=7.413e+00, dis_loss=1.286e-01\n",
      "INFO: Iter 39000: gen_loss=6.422e+00, dis_loss=1.491e-01\n",
      "INFO: Iter 39100: gen_loss=6.035e+00, dis_loss=1.842e-02\n",
      "INFO: Iter 39200: gen_loss=6.974e+00, dis_loss=9.453e-02\n",
      "INFO: Iter 39300: gen_loss=6.935e+00, dis_loss=7.997e-02\n",
      "INFO: Iter 39400: gen_loss=6.749e+00, dis_loss=2.199e-01\n",
      "INFO: Iter 39500: gen_loss=7.233e+00, dis_loss=1.196e-01\n",
      "INFO: Iter 39600: gen_loss=7.072e+00, dis_loss=1.549e-02\n",
      "INFO: Iter 39700: gen_loss=7.766e+00, dis_loss=1.203e-01\n",
      "INFO: Iter 39800: gen_loss=6.475e+00, dis_loss=1.665e-01\n",
      "INFO: Iter 39900: gen_loss=7.623e+00, dis_loss=4.899e-02\n",
      "INFO: Iter 40000: gen_loss=6.114e+00, dis_loss=2.177e-01\n",
      "INFO: Iter 40100: gen_loss=6.777e+00, dis_loss=1.405e-01\n",
      "INFO: Iter 40200: gen_loss=6.872e+00, dis_loss=1.081e-01\n",
      "INFO: Iter 40300: gen_loss=7.333e+00, dis_loss=2.121e-01\n",
      "INFO: Iter 40400: gen_loss=6.606e+00, dis_loss=1.257e-01\n",
      "INFO: Iter 40500: gen_loss=7.367e+00, dis_loss=9.913e-02\n",
      "INFO: Iter 40600: gen_loss=7.612e+00, dis_loss=1.406e-01\n",
      "INFO: Iter 40700: gen_loss=8.258e+00, dis_loss=8.042e-02\n",
      "INFO: Iter 40800: gen_loss=8.432e+00, dis_loss=1.078e-01\n",
      "INFO: Iter 40900: gen_loss=7.418e+00, dis_loss=1.994e-01\n",
      "INFO: Iter 41000: gen_loss=6.967e+00, dis_loss=5.845e-02\n",
      "INFO: Iter 41100: gen_loss=7.958e+00, dis_loss=1.088e-01\n",
      "INFO: Iter 41200: gen_loss=9.165e+00, dis_loss=6.798e-02\n",
      "INFO: Iter 41300: gen_loss=7.923e+00, dis_loss=9.066e-02\n",
      "INFO: Iter 41400: gen_loss=6.739e+00, dis_loss=9.361e-02\n",
      "INFO: Iter 41500: gen_loss=7.194e+00, dis_loss=9.845e-02\n",
      "INFO: Iter 41600: gen_loss=6.683e+00, dis_loss=9.258e-02\n",
      "INFO: Iter 41700: gen_loss=6.744e+00, dis_loss=1.861e-01\n",
      "INFO: Iter 41800: gen_loss=6.864e+00, dis_loss=2.135e-01\n",
      "INFO: Iter 41900: gen_loss=7.105e+00, dis_loss=1.356e-01\n",
      "INFO: Iter 42000: gen_loss=7.299e+00, dis_loss=1.754e-01\n",
      "INFO: Iter 42100: gen_loss=7.062e+00, dis_loss=6.132e-02\n",
      "INFO: Iter 42200: gen_loss=7.710e+00, dis_loss=1.156e-01\n",
      "INFO: Iter 42300: gen_loss=7.770e+00, dis_loss=1.116e-01\n",
      "INFO: Iter 42400: gen_loss=7.855e+00, dis_loss=7.301e-02\n",
      "INFO: Iter 42500: gen_loss=7.718e+00, dis_loss=1.643e-01\n",
      "INFO: Iter 42600: gen_loss=7.332e+00, dis_loss=1.349e-01\n",
      "INFO: Iter 42700: gen_loss=8.044e+00, dis_loss=1.555e-01\n",
      "INFO: Iter 42800: gen_loss=8.584e+00, dis_loss=5.807e-02\n",
      "INFO: Iter 42900: gen_loss=7.771e+00, dis_loss=3.071e-02\n",
      "INFO: Iter 43000: gen_loss=8.186e+00, dis_loss=1.577e-01\n",
      "INFO: Iter 43100: gen_loss=7.239e+00, dis_loss=8.819e-02\n",
      "INFO: Iter 43200: gen_loss=9.140e+00, dis_loss=4.308e-02\n",
      "INFO: Iter 43300: gen_loss=7.868e+00, dis_loss=1.641e-01\n",
      "INFO: Iter 43400: gen_loss=7.988e+00, dis_loss=5.065e-02\n",
      "INFO: Iter 43500: gen_loss=7.986e+00, dis_loss=2.989e-02\n",
      "INFO: Iter 43600: gen_loss=7.886e+00, dis_loss=1.434e-01\n",
      "INFO: Iter 43700: gen_loss=7.659e+00, dis_loss=1.099e-01\n",
      "INFO: Iter 43800: gen_loss=6.363e+00, dis_loss=2.078e-02\n",
      "INFO: Iter 43900: gen_loss=6.933e+00, dis_loss=2.722e-01\n",
      "INFO: Iter 44000: gen_loss=6.945e+00, dis_loss=5.702e-02\n",
      "INFO: Iter 44100: gen_loss=7.420e+00, dis_loss=1.125e-01\n",
      "INFO: Iter 44200: gen_loss=7.642e+00, dis_loss=6.815e-02\n",
      "INFO: Iter 44300: gen_loss=6.862e+00, dis_loss=2.047e-01\n",
      "INFO: Iter 44400: gen_loss=6.355e+00, dis_loss=1.793e-02\n",
      "INFO: Iter 44500: gen_loss=7.415e+00, dis_loss=2.685e-01\n",
      "INFO: Iter 44600: gen_loss=6.496e+00, dis_loss=2.136e-02\n",
      "INFO: Iter 44700: gen_loss=7.137e+00, dis_loss=1.049e-01\n",
      "INFO: Iter 44800: gen_loss=7.007e+00, dis_loss=5.300e-02\n",
      "INFO: Iter 44900: gen_loss=7.132e+00, dis_loss=2.787e-01\n",
      "INFO: Iter 45000: gen_loss=7.483e+00, dis_loss=1.918e-01\n",
      "INFO: Iter 45100: gen_loss=7.742e+00, dis_loss=7.154e-02\n",
      "INFO: Iter 45200: gen_loss=7.101e+00, dis_loss=1.903e-01\n",
      "INFO: Iter 45300: gen_loss=6.730e+00, dis_loss=1.111e-01\n",
      "INFO: Iter 45400: gen_loss=7.624e+00, dis_loss=8.205e-02\n",
      "INFO: Iter 45500: gen_loss=7.605e+00, dis_loss=6.306e-02\n",
      "INFO: Iter 45600: gen_loss=7.159e+00, dis_loss=2.224e-01\n",
      "INFO: Iter 45700: gen_loss=6.786e+00, dis_loss=6.656e-02\n",
      "INFO: Iter 45800: gen_loss=8.091e+00, dis_loss=4.849e-02\n",
      "INFO: Iter 45900: gen_loss=7.007e+00, dis_loss=1.954e-01\n",
      "INFO: Iter 46000: gen_loss=6.281e+00, dis_loss=1.322e-01\n",
      "INFO: Iter 46100: gen_loss=7.611e+00, dis_loss=1.379e-02\n",
      "INFO: Iter 46200: gen_loss=7.462e+00, dis_loss=1.386e-02\n",
      "INFO: Iter 46300: gen_loss=6.680e+00, dis_loss=8.897e-03\n",
      "INFO: Iter 46400: gen_loss=7.104e+00, dis_loss=4.920e-03\n",
      "INFO: Iter 46500: gen_loss=7.595e+00, dis_loss=3.431e-03\n",
      "INFO: Iter 46600: gen_loss=7.265e+00, dis_loss=1.649e-01\n",
      "INFO: Iter 46700: gen_loss=8.138e+00, dis_loss=1.459e-01\n",
      "INFO: Iter 46800: gen_loss=6.978e+00, dis_loss=7.246e-02\n",
      "INFO: Iter 46900: gen_loss=7.138e+00, dis_loss=1.431e-01\n",
      "INFO: Iter 47000: gen_loss=7.874e+00, dis_loss=1.940e-01\n",
      "INFO: Iter 47100: gen_loss=7.164e+00, dis_loss=1.004e-01\n",
      "INFO: Iter 47200: gen_loss=7.461e+00, dis_loss=1.996e-01\n",
      "INFO: Iter 47300: gen_loss=7.704e+00, dis_loss=1.359e-01\n",
      "INFO: Iter 47400: gen_loss=7.771e+00, dis_loss=1.927e-01\n",
      "INFO: Iter 47500: gen_loss=7.162e+00, dis_loss=2.833e-02\n",
      "INFO: Iter 47600: gen_loss=8.389e+00, dis_loss=1.022e-01\n",
      "INFO: Iter 47700: gen_loss=8.112e+00, dis_loss=7.659e-02\n",
      "INFO: Iter 47800: gen_loss=7.421e+00, dis_loss=9.375e-02\n",
      "INFO: Iter 47900: gen_loss=8.162e+00, dis_loss=7.925e-02\n",
      "INFO: Iter 48000: gen_loss=7.000e+00, dis_loss=2.445e-01\n",
      "INFO: Iter 48100: gen_loss=6.869e+00, dis_loss=1.504e-01\n",
      "INFO: Iter 48200: gen_loss=6.877e+00, dis_loss=9.819e-02\n",
      "INFO: Iter 48300: gen_loss=7.628e+00, dis_loss=2.052e-01\n",
      "INFO: Iter 48400: gen_loss=7.262e+00, dis_loss=1.730e-01\n",
      "INFO: Iter 48500: gen_loss=7.034e+00, dis_loss=8.075e-02\n",
      "INFO: Iter 48600: gen_loss=6.894e+00, dis_loss=1.778e-01\n",
      "INFO: Iter 48700: gen_loss=7.152e+00, dis_loss=7.342e-02\n",
      "INFO: Iter 48800: gen_loss=6.723e+00, dis_loss=8.509e-02\n",
      "INFO: Iter 48900: gen_loss=7.762e+00, dis_loss=1.360e-01\n",
      "INFO: Iter 49000: gen_loss=7.437e+00, dis_loss=5.979e-02\n",
      "INFO: Iter 49100: gen_loss=7.299e+00, dis_loss=9.472e-02\n",
      "INFO: Iter 49200: gen_loss=7.828e+00, dis_loss=1.544e-01\n",
      "INFO: Iter 49300: gen_loss=8.548e+00, dis_loss=7.712e-02\n",
      "INFO: Iter 49400: gen_loss=8.880e+00, dis_loss=5.388e-02\n",
      "INFO: Iter 49500: gen_loss=7.851e+00, dis_loss=1.074e-01\n",
      "INFO: Iter 49600: gen_loss=9.037e+00, dis_loss=3.320e-02\n",
      "INFO: Iter 49700: gen_loss=9.306e+00, dis_loss=8.085e-03\n",
      "INFO: Iter 49800: gen_loss=8.251e+00, dis_loss=1.107e-01\n",
      "INFO: Iter 49900: gen_loss=7.993e+00, dis_loss=9.486e-02\n",
      "INFO: Iter 50000: gen_loss=9.226e+00, dis_loss=6.864e-02\n",
      "INFO: Iter 50100: gen_loss=9.778e+00, dis_loss=2.051e-02\n",
      "INFO: Iter 50200: gen_loss=6.414e+00, dis_loss=2.460e-01\n",
      "INFO: Iter 50300: gen_loss=6.783e+00, dis_loss=2.548e-01\n",
      "INFO: Iter 50400: gen_loss=7.436e+00, dis_loss=6.610e-02\n",
      "INFO: Iter 50500: gen_loss=8.079e+00, dis_loss=1.867e-02\n",
      "INFO: Iter 50600: gen_loss=6.737e+00, dis_loss=7.228e-02\n",
      "INFO: Iter 50700: gen_loss=6.332e+00, dis_loss=8.009e-03\n",
      "INFO: Iter 50800: gen_loss=6.331e+00, dis_loss=5.065e-03\n",
      "INFO: Iter 50900: gen_loss=6.342e+00, dis_loss=1.169e-02\n",
      "INFO: Iter 51000: gen_loss=9.139e+00, dis_loss=5.066e-02\n",
      "INFO: Iter 51100: gen_loss=8.834e+00, dis_loss=8.129e-02\n",
      "INFO: Iter 51200: gen_loss=7.820e+00, dis_loss=2.082e-01\n",
      "INFO: Iter 51300: gen_loss=9.068e+00, dis_loss=1.263e-01\n",
      "INFO: Iter 51400: gen_loss=5.812e+00, dis_loss=1.733e-01\n",
      "INFO: Iter 51500: gen_loss=6.099e+00, dis_loss=2.260e-02\n",
      "INFO: Iter 51600: gen_loss=7.104e+00, dis_loss=1.241e-01\n",
      "INFO: Iter 51700: gen_loss=7.226e+00, dis_loss=1.827e-01\n",
      "INFO: Iter 51800: gen_loss=7.881e+00, dis_loss=7.926e-02\n",
      "INFO: Iter 51900: gen_loss=7.677e+00, dis_loss=7.096e-02\n",
      "INFO: Iter 52000: gen_loss=8.252e+00, dis_loss=2.470e-01\n",
      "INFO: Iter 52100: gen_loss=6.266e+00, dis_loss=8.366e-02\n",
      "INFO: Iter 52200: gen_loss=6.258e+00, dis_loss=7.270e-02\n",
      "INFO: Iter 52300: gen_loss=6.813e+00, dis_loss=1.115e-01\n",
      "INFO: Iter 52400: gen_loss=7.566e+00, dis_loss=2.302e-01\n",
      "INFO: Iter 52500: gen_loss=6.605e+00, dis_loss=2.309e-02\n",
      "INFO: Iter 52600: gen_loss=8.247e+00, dis_loss=1.327e-01\n",
      "INFO: Iter 52700: gen_loss=8.388e+00, dis_loss=8.395e-02\n",
      "INFO: Iter 52800: gen_loss=8.053e+00, dis_loss=2.025e-01\n",
      "INFO: Iter 52900: gen_loss=7.257e+00, dis_loss=1.019e-01\n",
      "INFO: Iter 53000: gen_loss=7.620e+00, dis_loss=5.527e-02\n",
      "INFO: Iter 53100: gen_loss=8.135e+00, dis_loss=7.322e-02\n",
      "INFO: Iter 53200: gen_loss=8.189e+00, dis_loss=3.348e-02\n",
      "INFO: Iter 53300: gen_loss=8.267e+00, dis_loss=1.200e-01\n",
      "INFO: Iter 53400: gen_loss=7.569e+00, dis_loss=1.631e-01\n",
      "INFO: Iter 53500: gen_loss=7.468e+00, dis_loss=1.267e-01\n",
      "INFO: Iter 53600: gen_loss=7.172e+00, dis_loss=4.502e-02\n",
      "INFO: Iter 53700: gen_loss=7.716e+00, dis_loss=1.187e-01\n",
      "INFO: Iter 53800: gen_loss=8.203e+00, dis_loss=4.964e-02\n",
      "INFO: Iter 53900: gen_loss=8.091e+00, dis_loss=5.894e-02\n",
      "INFO: Iter 54000: gen_loss=7.207e+00, dis_loss=1.251e-01\n",
      "INFO: Iter 54100: gen_loss=8.566e+00, dis_loss=6.904e-02\n",
      "INFO: Iter 54200: gen_loss=8.300e+00, dis_loss=1.564e-01\n",
      "INFO: Iter 54300: gen_loss=8.740e+00, dis_loss=3.940e-02\n",
      "INFO: Iter 54400: gen_loss=8.124e+00, dis_loss=1.349e-01\n",
      "INFO: Iter 54500: gen_loss=6.908e+00, dis_loss=1.232e-02\n",
      "INFO: Iter 54600: gen_loss=8.415e+00, dis_loss=1.024e-01\n",
      "INFO: Iter 54700: gen_loss=7.617e+00, dis_loss=1.705e-01\n",
      "INFO: Iter 54800: gen_loss=6.988e+00, dis_loss=1.109e-01\n",
      "INFO: Iter 54900: gen_loss=9.112e+00, dis_loss=4.198e-02\n",
      "INFO: Iter 55000: gen_loss=9.045e+00, dis_loss=2.006e-01\n",
      "INFO: Iter 55100: gen_loss=6.228e+00, dis_loss=1.591e-01\n",
      "INFO: Iter 55200: gen_loss=7.082e+00, dis_loss=1.166e-01\n",
      "INFO: Iter 55300: gen_loss=7.424e+00, dis_loss=1.412e-01\n",
      "INFO: Iter 55400: gen_loss=8.376e+00, dis_loss=1.901e-02\n",
      "INFO: Iter 55500: gen_loss=6.640e+00, dis_loss=8.356e-02\n",
      "INFO: Iter 55600: gen_loss=7.607e+00, dis_loss=7.154e-02\n",
      "INFO: Iter 55700: gen_loss=7.754e+00, dis_loss=9.552e-03\n",
      "INFO: Iter 55800: gen_loss=6.848e+00, dis_loss=1.722e-02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19516\\476078021.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_v\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;31m# fake samples, input is 4D: batch, filters, x, y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     gen_input_v = torch.FloatTensor(\n\u001b[0;32m      4\u001b[0m         BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1)\n\u001b[0;32m      5\u001b[0m     \u001b[0mgen_input_v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19516\\2366149702.py\u001b[0m in \u001b[0;36miterate_batches\u001b[1;34m(envs, batch_size)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame_over\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"ale.lives\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36m_get_obs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_ram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'image'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36m_get_image\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetScreenRGB2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_ram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\atari_py\\ale_python_interface.py\u001b[0m in \u001b[0;36mgetScreenRGB2\u001b[1;34m(self, screen_data)\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[0mscreen_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mscreen_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m480\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m         \u001b[0male_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetScreenRGB2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ctypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscreen_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch_v in iterate_batches(envs):\n",
    "    # fake samples, input is 4D: batch, filters, x, y\n",
    "    gen_input_v = torch.FloatTensor(\n",
    "        BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1)\n",
    "    gen_input_v.normal_(0, 1)\n",
    "    gen_input_v = gen_input_v.to(device)\n",
    "    batch_v = batch_v.to(device)\n",
    "    gen_output_v = net_gener(gen_input_v)\n",
    "    \n",
    "    # train discriminator\n",
    "    dis_optimizer.zero_grad()\n",
    "    dis_output_true_v = net_discr(batch_v)\n",
    "    dis_output_fake_v = net_discr(gen_output_v.detach())\n",
    "    dis_loss = objective(dis_output_true_v, true_labels_v) + \\\n",
    "               objective(dis_output_fake_v, fake_labels_v)\n",
    "    dis_loss.backward()\n",
    "    dis_optimizer.step()\n",
    "    dis_losses.append(dis_loss.item())\n",
    "    \n",
    "    #train generator\n",
    "    gen_optimizer.zero_grad()\n",
    "    dis_output_v = net_discr(gen_output_v)\n",
    "    gen_loss_v = objective(dis_output_v, true_labels_v)\n",
    "    gen_loss_v.backward()\n",
    "    gen_optimizer.step()\n",
    "    gen_losses.append(gen_loss_v.item())\n",
    "    \n",
    "    iter_no += 1\n",
    "    if iter_no % REPORT_EVERY_ITER == 0:\n",
    "        log.info(\"Iter %d: gen_loss=%.3e, dis_loss=%.3e\",\n",
    "                 iter_no, np.mean(gen_losses),\n",
    "                 np.mean(dis_losses))\n",
    "        writer.add_scalar(\n",
    "            \"gen_loss\", np.mean(gen_losses), iter_no)\n",
    "        writer.add_scalar(\n",
    "            \"dis_loss\", np.mean(dis_losses), iter_no)\n",
    "        gen_losses = []\n",
    "        dis_losses = []\n",
    "    if iter_no % SAVE_IMAGE_EVERY_ITER == 0:\n",
    "        writer.add_image(\"fake\", vutils.make_grid(\n",
    "            gen_output_v.data[:64], normalize=True), iter_no)\n",
    "        writer.add_image(\"true\", vutils.make_grid(\n",
    "            batch_v.data[:64], normalize=True), iter_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2624587-a525-44cf-8b24-be21ed5a4018",
   "metadata": {},
   "source": [
    "The GAN is trained for 55,000 steps and generates pretty good results. It can be checked using tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c9280-34c0-4e65-a57b-09306992398f",
   "metadata": {},
   "source": [
    "## Atari Gan Ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82910892-67b9-495f-8ace-431d98fca6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#import ignite\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.contrib.handlers import tensorboard_logger as tb_logger\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import gym\n",
    "import gym.spaces\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62bb5ce-d219-4c0e-91c8-a8f283700ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tHIS PART IS SAME AS ABOVE\n",
    "log = gym.logger\n",
    "log.set_level(gym.logger.INFO)\n",
    "\n",
    "LATENT_VECTOR_SIZE = 100\n",
    "DISCR_FILTERS = 64\n",
    "GENER_FILTERS = 64\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "REPORT_EVERY_ITER = 100\n",
    "SAVE_IMAGE_EVERY_ITER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813cc8ab-55fc-46c1-aced-85beb2cb8825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SAME AS BEFORE\n",
    "class InputWrapper(gym.ObservationWrapper):\n",
    "    '''\n",
    "    Preprocessing of input numpy array:\n",
    "    1. resizing image into predefined siize\n",
    "    2. move color channel axis to a first place\n",
    "    '''\n",
    "    def __init__(self, *args):\n",
    "        # Overriding the ObservationWrapper with InputWrapper\n",
    "        super(InputWrapper, self).__init__(*args)\n",
    "        # checking if type of observation space is same as that of gym space Box\n",
    "        assert isinstance(self.observation_space, gym.spaces.Box)\n",
    "        # saving previous observation space\n",
    "        old_space = self.observation_space\n",
    "        # Generating new observation space with same specs as old \n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            self.observation(old_space.low),\n",
    "            self.observation(old_space.high),\n",
    "            dtype=np.float32)\n",
    "        \n",
    "    def observation(self, observation):\n",
    "        # resizing image\n",
    "        new_obs = cv2.resize(\n",
    "            observation, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        # transforming (210, 160, 3) -> (3, 210, 160)\n",
    "        new_obs = np.moveaxis(new_obs, 2, 0)\n",
    "        return new_obs.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3af7961-e388-4858-b6e8-eb9977604463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SAME AS BEFORE\n",
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    Discriminator checks whether the image generated by generator is according to the given requirement or not\n",
    "    '''\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # creating a model to converge images into a single number\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape[0], out_channels=DISCR_FILTERS,\n",
    "                      kernel_size=4, stride=2, padding=1), #(64, 32, 32)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS, out_channels=DISCR_FILTERS*2,\n",
    "                      kernel_size=4, stride=2, padding=1), #(128, 16, 16)\n",
    "            nn.BatchNorm2d(DISCR_FILTERS*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS*2, out_channels=DISCR_FILTERS*4,\n",
    "                      kernel_size=4, stride=2, padding=1), #(256, 8, 8)\n",
    "            nn.BatchNorm2d(DISCR_FILTERS*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS*4, out_channels=DISCR_FILTERS*8,\n",
    "                      kernel_size=4, stride=2, padding=1), #(512, 4, 4)\n",
    "            nn.BatchNorm2d(DISCR_FILTERS*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS*8, out_channels=1,\n",
    "                      kernel_size=4, stride=1, padding=0), #(1, 1, 1)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_out = self.model(x)\n",
    "        return conv_out.view(-1, 1).squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09310cf9-81c8-4b72-8e5d-ec21fee11a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SAME AS BEFORE\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, output_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        # model deconvolves input vector into (3, 64, 64) image\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=LATENT_VECTOR_SIZE, out_channels=GENER_FILTERS*8,\n",
    "                               kernel_size=4, stride=1, padding=0), #(512, 4, 4)\n",
    "            nn.BatchNorm2d(GENER_FILTERS*8),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS*8, out_channels=GENER_FILTERS*4,\n",
    "                               kernel_size=4, stride=2, padding=1), #(256, 8, 8)\n",
    "            nn.BatchNorm2d(GENER_FILTERS*4),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS*4, out_channels=GENER_FILTERS*2,\n",
    "                               kernel_size=4, stride=2, padding=1), #(128, 16, 16)\n",
    "            nn.BatchNorm2d(GENER_FILTERS*2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS*2, out_channels=GENER_FILTERS,\n",
    "                               kernel_size=4, stride=2, padding=1), #(64, 32, 32)\n",
    "            nn.BatchNorm2d(GENER_FILTERS),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS, out_channels=output_shape[0],\n",
    "                               kernel_size=4, stride=2, padding=1), #(3, 64, 64)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98300f35-d9ac-45f6-90da-686918b84ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SAME AS BEFORE\n",
    "def iterate_batches(envs, batch_size=BATCH_SIZE):\n",
    "    '''\n",
    "    playing and geting observation for batch_size\n",
    "    '''\n",
    "    batch=[e.reset() for e in envs]\n",
    "    env_gen = iter(lambda: random.choice(envs), None)\n",
    "    \n",
    "    while True:\n",
    "        e = next(env_gen)\n",
    "        obs, reward, is_done, _ = e.step(e.action_space.sample())\n",
    "        if np.mean(obs) > 0.01:\n",
    "            batch.append(obs)\n",
    "        if len(batch) == batch_size:\n",
    "            # Normalizing input between -1 to 1\n",
    "            batch_np = np.array(batch, dtype=np.float32) * 2.0 / 255.0 - 1.0\n",
    "            yield torch.tensor(batch_np)\n",
    "            batch.clear()\n",
    "        if is_done:\n",
    "            e.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c164f59f-12af-420a-8743-08ca330ebc98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Making new env: Breakout-v0\n",
      "INFO: Making new env: AirRaid-v0\n",
      "INFO: Making new env: Pong-v0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "envs = [\n",
    "    InputWrapper(gym.make(name))\n",
    "    for name in ('Breakout-v0', 'AirRaid-v0', 'Pong-v0')\n",
    "]\n",
    "input_shape = envs[0].observation_space.shape\n",
    "\n",
    "net_discr = Discriminator(input_shape=input_shape).to(device)\n",
    "net_gener = Generator(output_shape=input_shape).to(device)\n",
    "\n",
    "# Loss fucntion of Binary Cross Entropy\n",
    "objective = nn.BCELoss()\n",
    "# Optimizer for both generator and Discriminator\n",
    "gen_optimizer = optim.Adam(\n",
    "    params = net_gener.parameters(), lr=LEARNING_RATE,\n",
    "    betas=(0.5, 0.999))\n",
    "dis_optimizer = optim.Adam(\n",
    "    params = net_discr.parameters(), lr=LEARNING_RATE,\n",
    "    betas=(0.5, 0.999))\n",
    "\n",
    "true_labels_v = torch.ones(BATCH_SIZE, device=device)\n",
    "fake_labels_v = torch.zeros(BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fd37036-d654-4a4b-975e-c11d18b4d3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_batch(trainer, batch):\n",
    "    # fake samples, input is 4D: batch, filters, x, y\n",
    "    gen_input_v = torch.FloatTensor(\n",
    "        BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1)\n",
    "    gen_input_v.normal_(0, 1)\n",
    "    gen_input_v = gen_input_v.to(device)\n",
    "    batch_v = batch.to(device)\n",
    "    gen_output_v = net_gener(gen_input_v)\n",
    "    \n",
    "    # train discriminator\n",
    "    dis_optimizer.zero_grad()\n",
    "    dis_output_true_v = net_discr(batch_v)\n",
    "    dis_output_fake_v = net_discr(gen_output_v.detach())\n",
    "    dis_loss = objective(dis_output_true_v, true_labels_v) + \\\n",
    "               objective(dis_output_fake_v, fake_labels_v)\n",
    "    dis_loss.backward()\n",
    "    dis_optimizer.step()\n",
    "    \n",
    "    #train generator\n",
    "    gen_optimizer.zero_grad()\n",
    "    dis_output_v = net_discr(gen_output_v)\n",
    "    gen_loss = objective(dis_output_v, true_labels_v)\n",
    "    gen_loss.backward()\n",
    "    gen_optimizer.step()\n",
    "    \n",
    "    if trainer.state.iteration % SAVE_IMAGE_EVERY_ITER == 0:\n",
    "        fake_img = vutils.make_grid(\n",
    "            gen_output_v.data[:64], normalize=True)\n",
    "        trainer.tb.writer.add_image(\n",
    "            \"fake\", fake_img, trainer.state.iteration)\n",
    "        real_img = vutils.make_grid(\n",
    "            batch_v.data[:64], normalize=True)\n",
    "        trainer.tb.writer.add_image(\n",
    "            \"real\", real_img, trainer.state.iteration)\n",
    "        trainer.tb.writer.flush()\n",
    "    return dis_loss.item(), gen_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2f28793-f280-4078-9e97-2b625a27343e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine = Engine(process_batch)\n",
    "tb = tb_logger.TensorboardLogger(log_dir=None)\n",
    "engine.tb = tb\n",
    "RunningAverage(output_transform=lambda out: out[1]).\\\n",
    "    attach(engine, \"avg_loss_gen\")\n",
    "RunningAverage(output_transform=lambda out: out[0]).\\\n",
    "    attach(engine, \"avg_loss_dis\")\n",
    "\n",
    "handler = tb_logger.OutputHandler(tag=\"train\",\n",
    "                                  metric_names=['avg_loss_gen', 'avg_loss_dis'])\n",
    "tb.attach(engine, log_handler=handler,\n",
    "          event_name=Events.ITERATION_COMPLETED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dc84192-51da-4671-8b57-6cdb0c0c563e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 100: gen_loss=4.975398, dis_loss=0.387582\n",
      "INFO: 200: gen_loss=4.352178, dis_loss=0.353541\n",
      "INFO: 300: gen_loss=4.789439, dis_loss=0.107345\n",
      "INFO: 400: gen_loss=4.876387, dis_loss=0.127333\n",
      "INFO: 500: gen_loss=5.258148, dis_loss=0.228796\n",
      "INFO: 600: gen_loss=5.414878, dis_loss=0.272098\n",
      "INFO: 700: gen_loss=5.240187, dis_loss=0.235681\n",
      "INFO: 800: gen_loss=4.576335, dis_loss=0.255500\n",
      "INFO: 900: gen_loss=5.885434, dis_loss=0.147684\n",
      "INFO: 1000: gen_loss=5.916265, dis_loss=0.089216\n",
      "INFO: 1100: gen_loss=5.243893, dis_loss=0.175737\n",
      "INFO: 1200: gen_loss=6.136098, dis_loss=0.044893\n",
      "INFO: 1300: gen_loss=6.990434, dis_loss=0.022466\n",
      "INFO: 1400: gen_loss=5.745535, dis_loss=0.074429\n",
      "INFO: 1500: gen_loss=5.623897, dis_loss=0.043017\n",
      "INFO: 1600: gen_loss=6.508416, dis_loss=0.036814\n",
      "INFO: 1700: gen_loss=5.394989, dis_loss=0.224614\n",
      "INFO: 1800: gen_loss=6.523425, dis_loss=0.049758\n",
      "INFO: 1900: gen_loss=7.108238, dis_loss=0.012480\n",
      "INFO: 2000: gen_loss=7.346043, dis_loss=0.028708\n",
      "INFO: 2100: gen_loss=7.930427, dis_loss=0.023057\n",
      "INFO: 2200: gen_loss=6.592956, dis_loss=0.292871\n",
      "INFO: 2300: gen_loss=6.226735, dis_loss=0.083220\n",
      "INFO: 2400: gen_loss=7.457927, dis_loss=0.020146\n",
      "INFO: 2500: gen_loss=8.050007, dis_loss=0.007782\n",
      "INFO: 2600: gen_loss=8.492841, dis_loss=0.007781\n",
      "INFO: 2700: gen_loss=6.654717, dis_loss=0.145954\n",
      "INFO: 2800: gen_loss=8.057374, dis_loss=0.028782\n",
      "INFO: 2900: gen_loss=6.106334, dis_loss=0.149620\n",
      "INFO: 3000: gen_loss=6.714346, dis_loss=0.025210\n",
      "INFO: 3100: gen_loss=6.757651, dis_loss=0.034315\n",
      "INFO: 3200: gen_loss=6.325180, dis_loss=0.169777\n",
      "INFO: 3300: gen_loss=7.552858, dis_loss=0.039071\n",
      "INFO: 3400: gen_loss=8.467086, dis_loss=0.009279\n",
      "INFO: 3500: gen_loss=8.942162, dis_loss=0.004590\n",
      "INFO: 3600: gen_loss=8.619767, dis_loss=0.006742\n",
      "INFO: 3700: gen_loss=8.614672, dis_loss=0.003175\n",
      "INFO: 3800: gen_loss=8.724014, dis_loss=0.001770\n",
      "INFO: 3900: gen_loss=6.257284, dis_loss=0.443236\n",
      "INFO: 4000: gen_loss=6.438236, dis_loss=0.067031\n",
      "INFO: 4100: gen_loss=6.459032, dis_loss=0.071481\n",
      "INFO: 4200: gen_loss=6.092245, dis_loss=0.123694\n",
      "INFO: 4300: gen_loss=6.831693, dis_loss=0.023135\n",
      "INFO: 4400: gen_loss=6.564772, dis_loss=0.114460\n",
      "INFO: 4500: gen_loss=6.670535, dis_loss=0.022288\n",
      "INFO: 4600: gen_loss=6.744524, dis_loss=0.289566\n",
      "INFO: 4700: gen_loss=5.502622, dis_loss=0.142452\n",
      "INFO: 4800: gen_loss=6.495096, dis_loss=0.027239\n",
      "INFO: 4900: gen_loss=7.091862, dis_loss=0.007833\n",
      "INFO: 5000: gen_loss=7.237682, dis_loss=0.004380\n",
      "INFO: 5100: gen_loss=8.040570, dis_loss=0.004827\n",
      "INFO: 5200: gen_loss=7.106844, dis_loss=0.116484\n",
      "INFO: 5300: gen_loss=5.640164, dis_loss=0.226220\n",
      "INFO: 5400: gen_loss=6.668839, dis_loss=0.044917\n",
      "INFO: 5500: gen_loss=6.983199, dis_loss=0.080612\n",
      "INFO: 5600: gen_loss=7.399349, dis_loss=0.022017\n",
      "INFO: 5700: gen_loss=6.431021, dis_loss=0.086489\n",
      "INFO: 5800: gen_loss=7.904517, dis_loss=0.019124\n",
      "INFO: 5900: gen_loss=6.988455, dis_loss=0.131782\n",
      "INFO: 6000: gen_loss=7.230472, dis_loss=0.149022\n",
      "INFO: 6100: gen_loss=7.458761, dis_loss=0.039731\n",
      "INFO: 6200: gen_loss=7.673960, dis_loss=0.076699\n",
      "INFO: 6300: gen_loss=6.874172, dis_loss=0.080817\n",
      "INFO: 6400: gen_loss=7.587179, dis_loss=0.023501\n",
      "INFO: 6500: gen_loss=8.411720, dis_loss=0.006838\n",
      "INFO: 6600: gen_loss=8.666459, dis_loss=0.004354\n",
      "INFO: 6700: gen_loss=7.278126, dis_loss=0.070446\n",
      "INFO: 6800: gen_loss=8.345902, dis_loss=0.018986\n",
      "INFO: 6900: gen_loss=7.967500, dis_loss=0.004794\n",
      "INFO: 7000: gen_loss=7.761778, dis_loss=0.003098\n",
      "INFO: 7100: gen_loss=8.007084, dis_loss=0.003161\n",
      "INFO: 7200: gen_loss=8.350372, dis_loss=0.002625\n",
      "INFO: 7300: gen_loss=8.827996, dis_loss=0.004899\n",
      "INFO: 7400: gen_loss=9.147596, dis_loss=0.002369\n",
      "INFO: 7500: gen_loss=8.764595, dis_loss=0.001958\n",
      "INFO: 7600: gen_loss=8.165801, dis_loss=0.001660\n",
      "INFO: 7700: gen_loss=8.233472, dis_loss=0.001165\n",
      "INFO: 7800: gen_loss=8.821515, dis_loss=0.003946\n",
      "INFO: 7900: gen_loss=9.996972, dis_loss=0.001665\n",
      "INFO: 8000: gen_loss=8.154816, dis_loss=0.079962\n",
      "INFO: 8100: gen_loss=6.826686, dis_loss=0.039851\n",
      "INFO: 8200: gen_loss=6.849817, dis_loss=0.009109\n",
      "INFO: 8300: gen_loss=8.894287, dis_loss=0.069556\n",
      "INFO: 8400: gen_loss=7.461024, dis_loss=0.031140\n",
      "INFO: 8500: gen_loss=8.553709, dis_loss=0.005451\n",
      "INFO: 8600: gen_loss=8.843285, dis_loss=0.002487\n",
      "INFO: 8700: gen_loss=7.556106, dis_loss=0.063875\n",
      "INFO: 8800: gen_loss=7.704649, dis_loss=0.014074\n",
      "INFO: 8900: gen_loss=10.814342, dis_loss=0.024555\n",
      "INFO: 9000: gen_loss=10.790878, dis_loss=0.003940\n",
      "INFO: 9100: gen_loss=9.296891, dis_loss=0.001147\n",
      "INFO: 9200: gen_loss=9.222227, dis_loss=0.000453\n",
      "INFO: 9300: gen_loss=9.504202, dis_loss=0.012390\n",
      "INFO: 9400: gen_loss=7.395970, dis_loss=0.005240\n",
      "INFO: 9500: gen_loss=6.744600, dis_loss=0.011920\n",
      "INFO: 9600: gen_loss=7.581571, dis_loss=0.004190\n",
      "INFO: 9700: gen_loss=8.476420, dis_loss=0.017180\n",
      "INFO: 9800: gen_loss=7.443280, dis_loss=0.116107\n",
      "INFO: 9900: gen_loss=7.694995, dis_loss=0.030436\n",
      "INFO: 10000: gen_loss=8.564247, dis_loss=0.008188\n",
      "INFO: 10100: gen_loss=8.210047, dis_loss=0.007414\n",
      "INFO: 10200: gen_loss=9.286882, dis_loss=0.004164\n",
      "INFO: 10300: gen_loss=9.984781, dis_loss=0.002619\n",
      "INFO: 10400: gen_loss=6.387010, dis_loss=0.535071\n",
      "INFO: 10500: gen_loss=6.169863, dis_loss=0.187360\n",
      "INFO: 10600: gen_loss=6.201782, dis_loss=0.090722\n",
      "INFO: 10700: gen_loss=7.042472, dis_loss=0.018805\n",
      "INFO: 10800: gen_loss=7.954416, dis_loss=0.008237\n",
      "INFO: 10900: gen_loss=6.144603, dis_loss=0.804836\n",
      "INFO: 11000: gen_loss=5.386594, dis_loss=0.176035\n",
      "INFO: 11100: gen_loss=6.616507, dis_loss=0.031659\n",
      "INFO: 11200: gen_loss=7.738057, dis_loss=0.044534\n",
      "INFO: 11300: gen_loss=7.151167, dis_loss=0.167667\n",
      "INFO: 11400: gen_loss=6.160101, dis_loss=0.105282\n",
      "INFO: 11500: gen_loss=6.465694, dis_loss=0.065114\n",
      "INFO: 11600: gen_loss=6.183878, dis_loss=0.060300\n",
      "INFO: 11700: gen_loss=6.735002, dis_loss=0.017769\n",
      "INFO: 11800: gen_loss=7.863336, dis_loss=0.012203\n",
      "INFO: 11900: gen_loss=8.811558, dis_loss=0.007452\n",
      "INFO: 12000: gen_loss=8.767007, dis_loss=0.002588\n",
      "INFO: 12100: gen_loss=9.196021, dis_loss=0.006011\n",
      "INFO: 12200: gen_loss=8.992460, dis_loss=0.002181\n",
      "INFO: 12300: gen_loss=9.793679, dis_loss=0.002721\n",
      "INFO: 12400: gen_loss=9.456208, dis_loss=0.001339\n",
      "INFO: 12500: gen_loss=7.470425, dis_loss=0.298887\n",
      "INFO: 12600: gen_loss=6.733155, dis_loss=0.194134\n",
      "INFO: 12700: gen_loss=7.418509, dis_loss=0.057413\n",
      "INFO: 12800: gen_loss=7.890357, dis_loss=0.078844\n",
      "INFO: 12900: gen_loss=7.973740, dis_loss=0.016033\n",
      "INFO: 13000: gen_loss=6.379422, dis_loss=0.116962\n",
      "INFO: 13100: gen_loss=7.858460, dis_loss=0.028720\n",
      "INFO: 13200: gen_loss=8.808936, dis_loss=0.007669\n",
      "INFO: 13300: gen_loss=9.148229, dis_loss=0.003762\n",
      "INFO: 13400: gen_loss=9.057248, dis_loss=0.002728\n",
      "INFO: 13500: gen_loss=7.575372, dis_loss=0.087241\n",
      "INFO: 13600: gen_loss=7.945324, dis_loss=0.020847\n",
      "INFO: 13700: gen_loss=7.125496, dis_loss=0.214905\n",
      "INFO: 13800: gen_loss=7.422806, dis_loss=0.084666\n",
      "INFO: 13900: gen_loss=6.901419, dis_loss=0.058429\n",
      "INFO: 14000: gen_loss=8.200831, dis_loss=0.013788\n",
      "INFO: 14100: gen_loss=8.460707, dis_loss=0.019631\n",
      "INFO: 14200: gen_loss=8.889468, dis_loss=0.005199\n",
      "INFO: 14300: gen_loss=8.798130, dis_loss=0.023803\n",
      "INFO: 14400: gen_loss=6.480528, dis_loss=0.185816\n",
      "INFO: 14500: gen_loss=7.081525, dis_loss=0.105622\n",
      "INFO: 14600: gen_loss=6.470191, dis_loss=0.391830\n",
      "INFO: 14700: gen_loss=6.525809, dis_loss=0.156791\n",
      "INFO: 14800: gen_loss=7.254901, dis_loss=0.065840\n",
      "INFO: 14900: gen_loss=7.969361, dis_loss=0.066722\n",
      "INFO: 15000: gen_loss=7.096983, dis_loss=0.160204\n",
      "INFO: 15100: gen_loss=7.242544, dis_loss=0.302019\n",
      "INFO: 15200: gen_loss=7.017838, dis_loss=0.051763\n",
      "INFO: 15300: gen_loss=6.412526, dis_loss=0.219100\n",
      "INFO: 15400: gen_loss=5.650975, dis_loss=0.173690\n",
      "INFO: 15500: gen_loss=6.043761, dis_loss=0.030983\n",
      "INFO: 15600: gen_loss=6.694099, dis_loss=0.019130\n",
      "INFO: 15700: gen_loss=6.310212, dis_loss=0.267949\n",
      "INFO: 15800: gen_loss=5.991703, dis_loss=0.257620\n",
      "INFO: 15900: gen_loss=5.758633, dis_loss=0.207823\n",
      "INFO: 16000: gen_loss=5.427507, dis_loss=0.122729\n",
      "INFO: 16100: gen_loss=7.003331, dis_loss=0.032376\n",
      "INFO: 16200: gen_loss=7.627645, dis_loss=0.169216\n",
      "INFO: 16300: gen_loss=6.047246, dis_loss=0.084704\n",
      "INFO: 16400: gen_loss=6.575509, dis_loss=0.014845\n",
      "INFO: 16500: gen_loss=7.112524, dis_loss=0.014543\n",
      "INFO: 16600: gen_loss=6.169915, dis_loss=0.067701\n",
      "INFO: 16700: gen_loss=7.073149, dis_loss=0.015521\n",
      "INFO: 16800: gen_loss=7.537530, dis_loss=0.172742\n",
      "INFO: 16900: gen_loss=5.934281, dis_loss=0.150612\n",
      "INFO: 17000: gen_loss=6.335080, dis_loss=0.369148\n",
      "INFO: 17100: gen_loss=5.954561, dis_loss=0.058475\n",
      "INFO: 17200: gen_loss=6.508867, dis_loss=0.013510\n",
      "INFO: 17300: gen_loss=7.556265, dis_loss=0.007983\n",
      "INFO: 17400: gen_loss=7.836942, dis_loss=0.188312\n",
      "INFO: 17500: gen_loss=6.145798, dis_loss=0.146053\n",
      "INFO: 17600: gen_loss=5.666364, dis_loss=0.311105\n",
      "INFO: 17700: gen_loss=6.147377, dis_loss=0.052311\n",
      "INFO: 17800: gen_loss=5.688555, dis_loss=0.197962\n",
      "INFO: 17900: gen_loss=6.373742, dis_loss=0.039760\n",
      "INFO: 18000: gen_loss=6.784235, dis_loss=0.010645\n",
      "INFO: 18100: gen_loss=6.723773, dis_loss=0.072242\n",
      "INFO: 18200: gen_loss=7.086807, dis_loss=0.020780\n",
      "INFO: 18300: gen_loss=8.619591, dis_loss=0.018444\n",
      "INFO: 18400: gen_loss=6.797083, dis_loss=0.116396\n",
      "INFO: 18500: gen_loss=6.224379, dis_loss=0.158502\n",
      "INFO: 18600: gen_loss=6.749746, dis_loss=0.069863\n",
      "INFO: 18700: gen_loss=5.342887, dis_loss=0.189489\n",
      "INFO: 18800: gen_loss=6.058318, dis_loss=0.145439\n",
      "INFO: 18900: gen_loss=5.534229, dis_loss=0.055687\n",
      "INFO: 19000: gen_loss=5.920588, dis_loss=0.019014\n",
      "INFO: 19100: gen_loss=7.904028, dis_loss=0.068757\n",
      "INFO: 19200: gen_loss=6.104063, dis_loss=0.101494\n",
      "INFO: 19300: gen_loss=6.900717, dis_loss=0.170618\n",
      "INFO: 19400: gen_loss=6.736174, dis_loss=0.056201\n",
      "INFO: 19500: gen_loss=6.379217, dis_loss=0.324492\n",
      "INFO: 19600: gen_loss=5.863377, dis_loss=0.058052\n",
      "INFO: 19700: gen_loss=6.597272, dis_loss=0.021746\n",
      "INFO: 19800: gen_loss=5.620130, dis_loss=0.054057\n",
      "INFO: 19900: gen_loss=6.201082, dis_loss=0.034534\n",
      "INFO: 20000: gen_loss=5.342615, dis_loss=0.187285\n",
      "INFO: 20100: gen_loss=5.748175, dis_loss=0.036539\n",
      "INFO: 20200: gen_loss=6.644302, dis_loss=0.109810\n",
      "INFO: 20300: gen_loss=5.894992, dis_loss=0.179740\n",
      "INFO: 20400: gen_loss=6.127734, dis_loss=0.061591\n",
      "INFO: 20500: gen_loss=6.112896, dis_loss=0.119777\n",
      "INFO: 20600: gen_loss=5.486123, dis_loss=0.134434\n",
      "INFO: 20700: gen_loss=6.809049, dis_loss=0.028524\n",
      "INFO: 20800: gen_loss=7.331154, dis_loss=0.012792\n",
      "INFO: 20900: gen_loss=7.321652, dis_loss=0.006169\n",
      "INFO: 21000: gen_loss=7.488630, dis_loss=0.012086\n",
      "INFO: 21100: gen_loss=6.607138, dis_loss=0.227047\n",
      "INFO: 21200: gen_loss=6.060961, dis_loss=0.040167\n",
      "INFO: 21300: gen_loss=6.538553, dis_loss=0.010848\n",
      "INFO: 21400: gen_loss=7.409870, dis_loss=0.009635\n",
      "INFO: 21500: gen_loss=8.435063, dis_loss=0.003437\n",
      "INFO: 21600: gen_loss=8.573151, dis_loss=0.003920\n",
      "INFO: 21700: gen_loss=5.669687, dis_loss=0.200513\n",
      "INFO: 21800: gen_loss=6.274614, dis_loss=0.095861\n",
      "INFO: 21900: gen_loss=5.057523, dis_loss=0.186099\n",
      "INFO: 22000: gen_loss=5.763172, dis_loss=0.092082\n",
      "INFO: 22100: gen_loss=5.168689, dis_loss=0.216049\n",
      "INFO: 22200: gen_loss=6.094546, dis_loss=0.107713\n",
      "INFO: 22300: gen_loss=6.274787, dis_loss=0.092466\n",
      "INFO: 22400: gen_loss=7.206615, dis_loss=0.019009\n",
      "INFO: 22500: gen_loss=5.807340, dis_loss=0.174485\n",
      "INFO: 22600: gen_loss=5.607275, dis_loss=0.035177\n",
      "INFO: 22700: gen_loss=7.346767, dis_loss=0.011004\n",
      "INFO: 22800: gen_loss=6.412280, dis_loss=0.118631\n",
      "INFO: 22900: gen_loss=6.436055, dis_loss=0.203244\n",
      "INFO: 23000: gen_loss=6.301548, dis_loss=0.048552\n",
      "INFO: 23100: gen_loss=6.335607, dis_loss=0.062300\n",
      "INFO: 23200: gen_loss=6.061346, dis_loss=0.053418\n",
      "INFO: 23300: gen_loss=6.965079, dis_loss=0.014614\n",
      "INFO: 23400: gen_loss=6.170494, dis_loss=0.169345\n",
      "INFO: 23500: gen_loss=5.607166, dis_loss=0.112779\n",
      "INFO: 23600: gen_loss=5.586267, dis_loss=0.362795\n",
      "INFO: 23700: gen_loss=5.899069, dis_loss=0.060026\n",
      "INFO: 23800: gen_loss=6.704072, dis_loss=0.014770\n",
      "INFO: 23900: gen_loss=7.069890, dis_loss=0.098738\n",
      "INFO: 24000: gen_loss=5.706393, dis_loss=0.020956\n",
      "INFO: 24100: gen_loss=6.592828, dis_loss=0.042755\n",
      "INFO: 24200: gen_loss=7.834902, dis_loss=0.021395\n",
      "INFO: 24300: gen_loss=9.163897, dis_loss=0.028582\n",
      "INFO: 24400: gen_loss=7.057790, dis_loss=0.020671\n",
      "INFO: 24500: gen_loss=7.490421, dis_loss=0.010417\n",
      "INFO: 24600: gen_loss=8.112059, dis_loss=0.003561\n",
      "INFO: 24700: gen_loss=8.028118, dis_loss=0.001407\n",
      "INFO: 24800: gen_loss=9.645317, dis_loss=0.019710\n",
      "INFO: 24900: gen_loss=8.391888, dis_loss=0.003846\n",
      "INFO: 25000: gen_loss=8.261891, dis_loss=0.001526\n",
      "INFO: 25100: gen_loss=8.192476, dis_loss=0.001226\n",
      "INFO: 25200: gen_loss=8.144357, dis_loss=0.001028\n",
      "INFO: 25300: gen_loss=7.931460, dis_loss=0.000807\n",
      "INFO: 25400: gen_loss=7.230354, dis_loss=0.001691\n",
      "INFO: 25500: gen_loss=7.371563, dis_loss=0.001311\n",
      "INFO: 25600: gen_loss=7.334368, dis_loss=0.002357\n",
      "INFO: 25700: gen_loss=9.307272, dis_loss=0.017846\n",
      "INFO: 25800: gen_loss=7.807627, dis_loss=0.004218\n",
      "INFO: 25900: gen_loss=7.994924, dis_loss=0.001657\n",
      "INFO: 26000: gen_loss=8.225263, dis_loss=0.001235\n",
      "INFO: 26100: gen_loss=8.573350, dis_loss=0.000832\n",
      "INFO: 26200: gen_loss=8.600790, dis_loss=0.000663\n",
      "INFO: 26300: gen_loss=12.620739, dis_loss=0.005856\n",
      "INFO: 26400: gen_loss=10.921832, dis_loss=0.000914\n",
      "INFO: 26500: gen_loss=9.938309, dis_loss=0.000249\n",
      "INFO: 26600: gen_loss=9.421488, dis_loss=0.000228\n",
      "INFO: 26700: gen_loss=9.177360, dis_loss=0.000312\n",
      "INFO: 26800: gen_loss=9.021432, dis_loss=0.000492\n",
      "INFO: 26900: gen_loss=8.972240, dis_loss=0.000637\n",
      "INFO: 27000: gen_loss=9.325173, dis_loss=0.000363\n",
      "INFO: 27100: gen_loss=9.454180, dis_loss=0.000312\n",
      "INFO: 27200: gen_loss=9.391465, dis_loss=0.000582\n",
      "INFO: 27300: gen_loss=9.749527, dis_loss=0.001185\n",
      "INFO: 27400: gen_loss=8.705678, dis_loss=0.198195\n",
      "INFO: 27500: gen_loss=8.113863, dis_loss=0.028588\n",
      "INFO: 27600: gen_loss=8.114886, dis_loss=0.004981\n",
      "INFO: 27700: gen_loss=8.234736, dis_loss=0.001939\n",
      "INFO: 27800: gen_loss=10.305047, dis_loss=0.028990\n",
      "INFO: 27900: gen_loss=13.999275, dis_loss=0.036965\n",
      "INFO: 28000: gen_loss=8.435919, dis_loss=0.007008\n",
      "INFO: 28100: gen_loss=7.922676, dis_loss=0.001454\n",
      "INFO: 28200: gen_loss=7.633046, dis_loss=0.001077\n",
      "INFO: 28300: gen_loss=8.159460, dis_loss=0.000651\n",
      "INFO: 28400: gen_loss=8.359526, dis_loss=0.000686\n",
      "INFO: 28500: gen_loss=8.758319, dis_loss=0.001022\n",
      "INFO: 28600: gen_loss=8.055964, dis_loss=0.043838\n",
      "INFO: 28700: gen_loss=6.949810, dis_loss=0.091618\n",
      "INFO: 28800: gen_loss=8.772428, dis_loss=0.039130\n",
      "INFO: 28900: gen_loss=7.186884, dis_loss=0.130898\n",
      "INFO: 29000: gen_loss=7.317594, dis_loss=0.025239\n",
      "INFO: 29100: gen_loss=6.363745, dis_loss=0.021350\n",
      "INFO: 29200: gen_loss=6.890254, dis_loss=0.004852\n",
      "INFO: 29300: gen_loss=6.924340, dis_loss=0.021191\n",
      "INFO: 29400: gen_loss=6.805323, dis_loss=0.023273\n",
      "INFO: 29500: gen_loss=7.032774, dis_loss=0.047378\n",
      "INFO: 29600: gen_loss=8.190170, dis_loss=0.170769\n",
      "INFO: 29700: gen_loss=8.370004, dis_loss=0.067356\n",
      "INFO: 29800: gen_loss=8.365675, dis_loss=0.015005\n",
      "INFO: 29900: gen_loss=8.683995, dis_loss=0.084887\n",
      "INFO: 30000: gen_loss=9.017100, dis_loss=0.042132\n",
      "INFO: 30100: gen_loss=8.838631, dis_loss=0.008034\n",
      "INFO: 30200: gen_loss=8.878772, dis_loss=0.305283\n",
      "INFO: 30300: gen_loss=9.260644, dis_loss=0.059466\n",
      "INFO: 30400: gen_loss=9.831620, dis_loss=0.010412\n",
      "INFO: 30500: gen_loss=9.537881, dis_loss=0.008298\n",
      "INFO: 30600: gen_loss=8.438031, dis_loss=0.190154\n",
      "INFO: 30700: gen_loss=8.504241, dis_loss=0.035046\n",
      "INFO: 30800: gen_loss=7.150751, dis_loss=0.225094\n",
      "INFO: 30900: gen_loss=7.393636, dis_loss=0.050260\n",
      "INFO: 31000: gen_loss=9.175704, dis_loss=0.020294\n",
      "INFO: 31100: gen_loss=7.763105, dis_loss=0.112247\n",
      "INFO: 31200: gen_loss=6.720818, dis_loss=0.082082\n",
      "INFO: 31300: gen_loss=7.247221, dis_loss=0.030066\n",
      "INFO: 31400: gen_loss=8.336473, dis_loss=0.008067\n",
      "INFO: 31500: gen_loss=8.396601, dis_loss=0.020021\n",
      "INFO: 31600: gen_loss=9.405519, dis_loss=0.006891\n",
      "INFO: 31700: gen_loss=7.229392, dis_loss=0.234666\n",
      "INFO: 31800: gen_loss=6.461292, dis_loss=0.044322\n",
      "INFO: 31900: gen_loss=6.838513, dis_loss=0.110485\n",
      "INFO: 32000: gen_loss=7.947390, dis_loss=0.037660\n",
      "INFO: 32100: gen_loss=8.713716, dis_loss=0.053039\n",
      "INFO: 32200: gen_loss=8.167250, dis_loss=0.048474\n",
      "INFO: 32300: gen_loss=7.290982, dis_loss=0.055451\n",
      "INFO: 32400: gen_loss=7.206495, dis_loss=0.013634\n",
      "INFO: 32500: gen_loss=7.791873, dis_loss=0.013488\n",
      "INFO: 32600: gen_loss=9.441188, dis_loss=0.010110\n",
      "INFO: 32700: gen_loss=7.676510, dis_loss=0.042335\n",
      "INFO: 32800: gen_loss=7.698389, dis_loss=0.008129\n",
      "INFO: 32900: gen_loss=8.074076, dis_loss=0.004408\n",
      "INFO: 33000: gen_loss=9.192871, dis_loss=0.009046\n",
      "INFO: 33100: gen_loss=7.574357, dis_loss=0.179020\n",
      "INFO: 33200: gen_loss=7.515046, dis_loss=0.033084\n",
      "INFO: 33300: gen_loss=7.884510, dis_loss=0.007539\n",
      "INFO: 33400: gen_loss=7.650221, dis_loss=0.011635\n",
      "INFO: 33500: gen_loss=7.936940, dis_loss=0.091371\n",
      "INFO: 33600: gen_loss=7.845709, dis_loss=0.060724\n",
      "INFO: 33700: gen_loss=8.219014, dis_loss=0.156104\n",
      "INFO: 33800: gen_loss=8.373259, dis_loss=0.039848\n",
      "INFO: 33900: gen_loss=8.943140, dis_loss=0.076516\n",
      "INFO: 34000: gen_loss=8.435871, dis_loss=0.014100\n",
      "INFO: 34100: gen_loss=7.789588, dis_loss=0.067071\n",
      "INFO: 34200: gen_loss=9.319121, dis_loss=0.017104\n",
      "INFO: 34300: gen_loss=10.015444, dis_loss=0.010903\n",
      "INFO: 34400: gen_loss=10.730356, dis_loss=0.014588\n",
      "INFO: 34500: gen_loss=9.024516, dis_loss=0.031658\n",
      "INFO: 34600: gen_loss=9.484154, dis_loss=0.008378\n",
      "INFO: 34700: gen_loss=10.091304, dis_loss=0.004610\n",
      "INFO: 34800: gen_loss=8.396333, dis_loss=0.055661\n",
      "INFO: 34900: gen_loss=8.194862, dis_loss=0.019724\n",
      "INFO: 35000: gen_loss=8.981193, dis_loss=0.070823\n",
      "INFO: 35100: gen_loss=9.454020, dis_loss=0.036935\n",
      "INFO: 35200: gen_loss=7.588070, dis_loss=0.089113\n",
      "INFO: 35300: gen_loss=7.399784, dis_loss=0.019864\n",
      "INFO: 35400: gen_loss=7.762582, dis_loss=0.022307\n",
      "INFO: 35500: gen_loss=8.917505, dis_loss=0.007978\n",
      "INFO: 35600: gen_loss=8.612651, dis_loss=0.008933\n",
      "INFO: 35700: gen_loss=9.076560, dis_loss=0.005156\n",
      "INFO: 35800: gen_loss=7.497306, dis_loss=0.179152\n",
      "INFO: 35900: gen_loss=8.318590, dis_loss=0.029744\n",
      "INFO: 36000: gen_loss=7.844489, dis_loss=0.019641\n",
      "INFO: 36100: gen_loss=7.350895, dis_loss=0.060342\n",
      "INFO: 36200: gen_loss=7.819957, dis_loss=0.014139\n",
      "INFO: 36300: gen_loss=8.319416, dis_loss=0.015848\n",
      "INFO: 36400: gen_loss=8.864469, dis_loss=0.004010\n",
      "INFO: 36500: gen_loss=7.195172, dis_loss=0.041984\n",
      "INFO: 36600: gen_loss=8.913847, dis_loss=0.016533\n",
      "INFO: 36700: gen_loss=8.949632, dis_loss=0.004123\n",
      "INFO: 36800: gen_loss=9.238263, dis_loss=0.018432\n",
      "INFO: 36900: gen_loss=7.996769, dis_loss=0.113557\n",
      "INFO: 37000: gen_loss=7.925137, dis_loss=0.031861\n",
      "INFO: 37100: gen_loss=8.900921, dis_loss=0.012467\n",
      "INFO: 37200: gen_loss=6.996727, dis_loss=0.065353\n",
      "INFO: 37300: gen_loss=7.188687, dis_loss=0.011916\n",
      "INFO: 37400: gen_loss=7.947671, dis_loss=0.005786\n",
      "INFO: 37500: gen_loss=8.571607, dis_loss=0.056655\n",
      "INFO: 37600: gen_loss=7.746916, dis_loss=0.056576\n",
      "INFO: 37700: gen_loss=8.368092, dis_loss=0.036112\n",
      "INFO: 37800: gen_loss=8.743833, dis_loss=0.091589\n",
      "INFO: 37900: gen_loss=9.487956, dis_loss=0.036789\n",
      "INFO: 38000: gen_loss=9.904492, dis_loss=0.050738\n",
      "INFO: 38100: gen_loss=10.260325, dis_loss=0.028945\n",
      "INFO: 38200: gen_loss=10.310060, dis_loss=0.081998\n",
      "INFO: 38300: gen_loss=10.142902, dis_loss=0.021650\n",
      "INFO: 38400: gen_loss=9.040311, dis_loss=0.168615\n",
      "INFO: 38500: gen_loss=8.047372, dis_loss=0.046155\n",
      "INFO: 38600: gen_loss=9.146298, dis_loss=0.130100\n",
      "INFO: 38700: gen_loss=7.420504, dis_loss=0.034303\n",
      "INFO: 38800: gen_loss=7.919434, dis_loss=0.016162\n",
      "INFO: 38900: gen_loss=7.743324, dis_loss=0.140081\n",
      "INFO: 39000: gen_loss=7.865674, dis_loss=0.145999\n",
      "INFO: 39100: gen_loss=8.166538, dis_loss=0.044821\n",
      "INFO: 39200: gen_loss=7.993584, dis_loss=0.079293\n",
      "INFO: 39300: gen_loss=7.991554, dis_loss=0.016379\n",
      "INFO: 39400: gen_loss=8.162893, dis_loss=0.008904\n",
      "INFO: 39500: gen_loss=9.008193, dis_loss=0.004382\n",
      "INFO: 39600: gen_loss=10.277942, dis_loss=0.007699\n",
      "INFO: 39700: gen_loss=9.310930, dis_loss=0.079290\n",
      "INFO: 39800: gen_loss=8.545948, dis_loss=0.116041\n",
      "INFO: 39900: gen_loss=8.567564, dis_loss=0.067027\n",
      "INFO: 40000: gen_loss=9.055071, dis_loss=0.014495\n",
      "INFO: 40100: gen_loss=10.115466, dis_loss=0.011017\n",
      "INFO: 40200: gen_loss=7.705096, dis_loss=0.152780\n",
      "INFO: 40300: gen_loss=7.521427, dis_loss=0.024496\n",
      "INFO: 40400: gen_loss=8.013111, dis_loss=0.123298\n",
      "INFO: 40500: gen_loss=8.423410, dis_loss=0.040804\n",
      "INFO: 40600: gen_loss=9.880099, dis_loss=0.018345\n",
      "INFO: 40700: gen_loss=9.810300, dis_loss=0.075341\n",
      "INFO: 40800: gen_loss=7.587198, dis_loss=0.106216\n",
      "INFO: 40900: gen_loss=8.284597, dis_loss=0.019426\n",
      "INFO: 41000: gen_loss=8.794546, dis_loss=0.006992\n",
      "INFO: 41100: gen_loss=8.010955, dis_loss=0.076181\n",
      "INFO: 41200: gen_loss=8.360601, dis_loss=0.023494\n",
      "INFO: 41300: gen_loss=8.505788, dis_loss=0.081757\n",
      "INFO: 41400: gen_loss=8.551571, dis_loss=0.019544\n",
      "INFO: 41500: gen_loss=8.375509, dis_loss=0.013017\n",
      "INFO: 41600: gen_loss=9.173737, dis_loss=0.012131\n",
      "INFO: 41700: gen_loss=9.469345, dis_loss=0.107190\n",
      "INFO: 41800: gen_loss=9.419070, dis_loss=0.023689\n",
      "INFO: 41900: gen_loss=8.935702, dis_loss=0.044120\n",
      "INFO: 42000: gen_loss=10.040537, dis_loss=0.033145\n",
      "INFO: 42100: gen_loss=8.749950, dis_loss=0.036157\n",
      "INFO: 42200: gen_loss=9.084428, dis_loss=0.099297\n",
      "INFO: 42300: gen_loss=7.132692, dis_loss=0.124464\n",
      "INFO: 42400: gen_loss=7.224428, dis_loss=0.023385\n",
      "INFO: 42500: gen_loss=7.973122, dis_loss=0.008427\n",
      "INFO: 42600: gen_loss=7.807217, dis_loss=0.312524\n",
      "INFO: 42700: gen_loss=6.472109, dis_loss=0.055249\n",
      "INFO: 42800: gen_loss=6.935879, dis_loss=0.015032\n",
      "INFO: 42900: gen_loss=9.113355, dis_loss=0.032821\n",
      "INFO: 43000: gen_loss=9.174284, dis_loss=0.134215\n",
      "INFO: 43100: gen_loss=9.464374, dis_loss=0.132825\n",
      "INFO: 43200: gen_loss=9.183347, dis_loss=0.032761\n",
      "INFO: 43300: gen_loss=7.809551, dis_loss=0.040411\n",
      "INFO: 43400: gen_loss=8.826630, dis_loss=0.354451\n",
      "INFO: 43500: gen_loss=7.455657, dis_loss=0.117753\n",
      "INFO: 43600: gen_loss=8.342827, dis_loss=0.095951\n",
      "INFO: 43700: gen_loss=8.629814, dis_loss=0.032656\n",
      "INFO: 43800: gen_loss=8.109514, dis_loss=0.029349\n",
      "INFO: 43900: gen_loss=7.870799, dis_loss=0.091150\n",
      "INFO: 44000: gen_loss=9.024181, dis_loss=0.175298\n",
      "INFO: 44100: gen_loss=8.620735, dis_loss=0.129427\n",
      "INFO: 44200: gen_loss=7.059661, dis_loss=0.062835\n",
      "INFO: 44300: gen_loss=8.021951, dis_loss=0.017792\n",
      "INFO: 44400: gen_loss=7.720313, dis_loss=0.022000\n",
      "INFO: 44500: gen_loss=9.489283, dis_loss=0.056755\n",
      "INFO: 44600: gen_loss=8.979276, dis_loss=0.015126\n",
      "INFO: 44700: gen_loss=8.909724, dis_loss=0.078676\n",
      "INFO: 44800: gen_loss=9.723466, dis_loss=0.049829\n",
      "INFO: 44900: gen_loss=7.043441, dis_loss=0.334275\n",
      "INFO: 45000: gen_loss=6.057086, dis_loss=0.057967\n",
      "INFO: 45100: gen_loss=7.669192, dis_loss=0.017145\n",
      "INFO: 45200: gen_loss=6.403924, dis_loss=0.090748\n",
      "INFO: 45300: gen_loss=6.843902, dis_loss=0.051230\n",
      "INFO: 45400: gen_loss=8.782588, dis_loss=0.080112\n",
      "INFO: 45500: gen_loss=7.888103, dis_loss=0.014924\n",
      "INFO: 45600: gen_loss=8.168665, dis_loss=0.011108\n",
      "INFO: 45700: gen_loss=9.015060, dis_loss=0.006485\n",
      "INFO: 45800: gen_loss=9.952800, dis_loss=0.010788\n",
      "INFO: 45900: gen_loss=9.455073, dis_loss=0.002829\n",
      "INFO: 46000: gen_loss=9.000050, dis_loss=0.212909\n",
      "INFO: 46100: gen_loss=8.014254, dis_loss=0.066546\n",
      "INFO: 46200: gen_loss=8.539346, dis_loss=0.061380\n",
      "INFO: 46300: gen_loss=8.069428, dis_loss=0.171492\n",
      "INFO: 46400: gen_loss=8.844928, dis_loss=0.079202\n",
      "INFO: 46500: gen_loss=9.549846, dis_loss=0.065036\n",
      "INFO: 46600: gen_loss=8.031848, dis_loss=0.151064\n",
      "INFO: 46700: gen_loss=8.978939, dis_loss=0.025641\n",
      "INFO: 46800: gen_loss=9.455937, dis_loss=0.020225\n",
      "INFO: 46900: gen_loss=9.132621, dis_loss=0.056524\n",
      "INFO: 47000: gen_loss=9.494734, dis_loss=0.011083\n",
      "INFO: 47100: gen_loss=9.721774, dis_loss=0.008468\n",
      "INFO: 47200: gen_loss=8.686430, dis_loss=0.002858\n",
      "INFO: 47300: gen_loss=8.670417, dis_loss=0.002953\n",
      "INFO: 47400: gen_loss=8.222219, dis_loss=0.004785\n",
      "INFO: 47500: gen_loss=9.492411, dis_loss=0.004073\n",
      "INFO: 47600: gen_loss=9.890671, dis_loss=0.002394\n",
      "INFO: 47700: gen_loss=11.027726, dis_loss=0.006085\n",
      "INFO: 47800: gen_loss=9.405965, dis_loss=0.137344\n",
      "INFO: 47900: gen_loss=7.893548, dis_loss=0.120733\n",
      "INFO: 48000: gen_loss=6.804253, dis_loss=0.021110\n",
      "INFO: 48100: gen_loss=7.292489, dis_loss=0.212698\n",
      "INFO: 48200: gen_loss=7.011935, dis_loss=0.044001\n",
      "INFO: 48300: gen_loss=8.422383, dis_loss=0.064825\n",
      "INFO: 48400: gen_loss=7.707139, dis_loss=0.075245\n",
      "INFO: 48500: gen_loss=8.313762, dis_loss=0.170969\n",
      "INFO: 48600: gen_loss=8.312462, dis_loss=0.125175\n",
      "INFO: 48700: gen_loss=9.358388, dis_loss=0.051476\n",
      "INFO: 48800: gen_loss=9.028585, dis_loss=0.119578\n",
      "INFO: 48900: gen_loss=8.083156, dis_loss=0.094525\n",
      "INFO: 49000: gen_loss=7.862379, dis_loss=0.036401\n",
      "INFO: 49100: gen_loss=8.204325, dis_loss=0.018008\n",
      "INFO: 49200: gen_loss=8.715061, dis_loss=0.227914\n",
      "INFO: 49300: gen_loss=8.329947, dis_loss=0.119315\n",
      "INFO: 49400: gen_loss=8.544647, dis_loss=0.023481\n",
      "INFO: 49500: gen_loss=8.968493, dis_loss=0.035890\n",
      "INFO: 49600: gen_loss=9.394515, dis_loss=0.013480\n",
      "INFO: 49700: gen_loss=9.690293, dis_loss=0.036402\n",
      "INFO: 49800: gen_loss=9.570624, dis_loss=0.029075\n",
      "INFO: 49900: gen_loss=9.415029, dis_loss=0.111215\n",
      "INFO: 50000: gen_loss=9.664097, dis_loss=0.067780\n",
      "INFO: 50100: gen_loss=9.538037, dis_loss=0.089401\n",
      "INFO: 50200: gen_loss=7.450725, dis_loss=0.031201\n",
      "INFO: 50300: gen_loss=8.244779, dis_loss=0.032887\n",
      "INFO: 50400: gen_loss=7.217638, dis_loss=0.035548\n",
      "INFO: 50500: gen_loss=7.575834, dis_loss=0.040327\n",
      "INFO: 50600: gen_loss=8.375817, dis_loss=0.008942\n",
      "INFO: 50700: gen_loss=8.329282, dis_loss=0.017080\n",
      "INFO: 50800: gen_loss=9.465431, dis_loss=0.050544\n",
      "INFO: 50900: gen_loss=8.195439, dis_loss=0.103633\n",
      "INFO: 51000: gen_loss=8.056323, dis_loss=0.282540\n",
      "INFO: 51100: gen_loss=7.608345, dis_loss=0.046720\n",
      "INFO: 51200: gen_loss=9.355526, dis_loss=0.168140\n",
      "INFO: 51300: gen_loss=9.151203, dis_loss=0.096459\n",
      "INFO: 51400: gen_loss=8.271993, dis_loss=0.019285\n",
      "INFO: 51500: gen_loss=8.778831, dis_loss=0.062357\n",
      "INFO: 51600: gen_loss=9.586794, dis_loss=0.059373\n",
      "INFO: 51700: gen_loss=8.730073, dis_loss=0.013770\n",
      "INFO: 51800: gen_loss=9.380084, dis_loss=0.005264\n",
      "INFO: 51900: gen_loss=10.106643, dis_loss=0.025771\n",
      "INFO: 52000: gen_loss=8.614721, dis_loss=0.060589\n",
      "INFO: 52100: gen_loss=9.351082, dis_loss=0.049027\n",
      "INFO: 52200: gen_loss=9.273947, dis_loss=0.122125\n",
      "INFO: 52300: gen_loss=7.983222, dis_loss=0.030863\n",
      "INFO: 52400: gen_loss=7.916336, dis_loss=0.207478\n",
      "INFO: 52500: gen_loss=8.177957, dis_loss=0.067058\n",
      "INFO: 52600: gen_loss=7.695824, dis_loss=0.025180\n",
      "INFO: 52700: gen_loss=8.400114, dis_loss=0.125681\n",
      "INFO: 52800: gen_loss=7.933487, dis_loss=0.171693\n",
      "INFO: 52900: gen_loss=8.344559, dis_loss=0.067403\n",
      "INFO: 53000: gen_loss=8.686809, dis_loss=0.091410\n",
      "INFO: 53100: gen_loss=8.048129, dis_loss=0.064792\n",
      "INFO: 53200: gen_loss=7.753437, dis_loss=0.126035\n",
      "INFO: 53300: gen_loss=8.789402, dis_loss=0.032616\n",
      "INFO: 53400: gen_loss=9.518583, dis_loss=0.026660\n",
      "INFO: 53500: gen_loss=9.737810, dis_loss=0.014403\n",
      "INFO: 53600: gen_loss=9.805226, dis_loss=0.041915\n",
      "INFO: 53700: gen_loss=10.115133, dis_loss=0.115908\n",
      "INFO: 53800: gen_loss=9.194734, dis_loss=0.032098\n",
      "INFO: 53900: gen_loss=9.755622, dis_loss=0.152394\n",
      "INFO: 54000: gen_loss=8.816708, dis_loss=0.058529\n",
      "INFO: 54100: gen_loss=9.770651, dis_loss=0.041819\n",
      "INFO: 54200: gen_loss=10.039995, dis_loss=0.021698\n",
      "INFO: 54300: gen_loss=9.288014, dis_loss=0.005897\n",
      "INFO: 54400: gen_loss=8.304778, dis_loss=0.007216\n",
      "INFO: 54500: gen_loss=8.162899, dis_loss=0.145786\n",
      "INFO: 54600: gen_loss=7.613262, dis_loss=0.105800\n",
      "INFO: 54700: gen_loss=8.318422, dis_loss=0.059029\n",
      "INFO: 54800: gen_loss=8.567101, dis_loss=0.023308\n",
      "INFO: 54900: gen_loss=9.718515, dis_loss=0.041871\n",
      "INFO: 55000: gen_loss=9.409924, dis_loss=0.017743\n",
      "INFO: 55100: gen_loss=9.683155, dis_loss=0.010371\n",
      "INFO: 55200: gen_loss=10.185871, dis_loss=0.128373\n",
      "INFO: 55300: gen_loss=9.739650, dis_loss=0.021806\n",
      "INFO: 55400: gen_loss=9.216691, dis_loss=0.058867\n",
      "INFO: 55500: gen_loss=8.667656, dis_loss=0.092085\n",
      "INFO: 55600: gen_loss=9.545562, dis_loss=0.036310\n",
      "INFO: 55700: gen_loss=9.542893, dis_loss=0.020951\n",
      "INFO: 55800: gen_loss=8.794271, dis_loss=0.038210\n",
      "INFO: 55900: gen_loss=7.915797, dis_loss=0.136989\n",
      "INFO: 56000: gen_loss=7.912933, dis_loss=0.022514\n",
      "INFO: 56100: gen_loss=7.953286, dis_loss=0.009271\n",
      "INFO: 56200: gen_loss=9.614233, dis_loss=0.035458\n",
      "INFO: 56300: gen_loss=9.892657, dis_loss=0.039472\n",
      "INFO: 56400: gen_loss=10.561487, dis_loss=0.096382\n",
      "INFO: 56500: gen_loss=9.506848, dis_loss=0.046434\n",
      "INFO: 56600: gen_loss=9.136430, dis_loss=0.083293\n",
      "INFO: 56700: gen_loss=9.487362, dis_loss=0.064493\n",
      "INFO: 56800: gen_loss=9.369948, dis_loss=0.045048\n",
      "INFO: 56900: gen_loss=9.813336, dis_loss=0.068592\n",
      "INFO: 57000: gen_loss=9.477416, dis_loss=0.073924\n",
      "INFO: 57100: gen_loss=9.644520, dis_loss=0.078514\n",
      "INFO: 57200: gen_loss=8.221219, dis_loss=0.024043\n",
      "INFO: 57300: gen_loss=8.777174, dis_loss=0.071898\n",
      "INFO: 57400: gen_loss=9.700183, dis_loss=0.178047\n",
      "INFO: 57500: gen_loss=10.002761, dis_loss=0.048527\n",
      "INFO: 57600: gen_loss=9.872326, dis_loss=0.047336\n",
      "INFO: 57700: gen_loss=9.855305, dis_loss=0.049772\n",
      "INFO: 57800: gen_loss=9.496956, dis_loss=0.072070\n",
      "INFO: 57900: gen_loss=8.113242, dis_loss=0.078327\n",
      "INFO: 58000: gen_loss=8.949674, dis_loss=0.062924\n",
      "INFO: 58100: gen_loss=9.610365, dis_loss=0.102112\n",
      "INFO: 58200: gen_loss=10.746369, dis_loss=0.043496\n",
      "INFO: 58300: gen_loss=10.619760, dis_loss=0.048275\n",
      "INFO: 58400: gen_loss=9.688564, dis_loss=0.028262\n",
      "INFO: 58500: gen_loss=10.988580, dis_loss=0.027055\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4744\\449241815.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                  trainer.state.metrics['avg_loss_dis'])\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterate_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Engine run is terminating due to exception: %s.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch[%s] Complete. Time taken: %02d:%02d:%02d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Current run is terminating due to exception: %s.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4744\\3679636322.py\u001b[0m in \u001b[0;36miterate_batches\u001b[1;34m(envs, batch_size)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame_over\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"ale.lives\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36m_get_obs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_ram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'image'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36m_get_image\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetScreenRGB2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_ram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\aiprojects\\deeprl\\deeprl\\lib\\site-packages\\atari_py\\ale_python_interface.py\u001b[0m in \u001b[0;36mgetScreenRGB2\u001b[1;34m(self, screen_data)\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[0mscreen_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mscreen_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m480\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m         \u001b[0male_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetScreenRGB2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ctypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscreen_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@engine.on(Events.ITERATION_COMPLETED)\n",
    "def log_losses(trainer):\n",
    "    if trainer.state.iteration % REPORT_EVERY_ITER == 0:\n",
    "        log.info(\"%d: gen_loss=%f, dis_loss=%f\",\n",
    "                 trainer.state.iteration,\n",
    "                 trainer.state.metrics['avg_loss_gen'],\n",
    "                 trainer.state.metrics['avg_loss_dis'])\n",
    "\n",
    "engine.run(data=iterate_batches(envs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32f8dcc-8ba2-4f13-9727-96175a393ee1",
   "metadata": {},
   "source": [
    "Trained the Neural Network for 58K steps ans the result "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprl",
   "language": "python",
   "name": "deeprl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

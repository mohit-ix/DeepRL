{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239473f1-ed34-4a19-8bfb-dd88346351c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import ptan\n",
    "\n",
    "import ptan.ignite as ptan_ignite\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from ignite.engine import Engine\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.contrib.handlers import tensorboard_logger as tb_logger\n",
    "\n",
    "from lib import dqn_model, common\n",
    "\n",
    "\n",
    "NAME = \"02_n_envs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d624ece8-375a-4941-9e5b-217eacd79765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_generator(buffer: ptan.experience.ExperienceReplayBuffer,\n",
    "                    initial: int, batch_size: int, steps: int):\n",
    "    buffer.populate(initial)\n",
    "    while True:\n",
    "        buffer.populate(steps)\n",
    "        yield buffer.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5094ff5-3f0a-47c8-a346-d245b55b7a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#getting rid of missing metrics warning\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "random.seed(common.SEED)\n",
    "torch.manual_seed(common.SEED)\n",
    "params = common.HYPERPARAMS['pong']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "envs = []\n",
    "n_envs = 3\n",
    "for _ in range(n_envs):\n",
    "    env = gym.make(params.env_name)\n",
    "    env = ptan.common.wrappers.wrap_dqn(env)\n",
    "    env.seed(common.SEED)\n",
    "    envs.append(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df76f16-8780-4e4e-8b08-a9b65cdcfca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params.batch_size *= n_envs\n",
    "net = dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "\n",
    "tgt_net = ptan.agent.TargetNet(net)\n",
    "selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params.epsilon_start)\n",
    "epsilon_tracker = common.EpsilonTracker(selector, params)\n",
    "agent = ptan.agent.DQNAgent(net, selector, device=device)\n",
    "\n",
    "exp_source = ptan.experience.ExperienceSourceFirstLast(\n",
    "    env, agent, gamma=params.gamma)\n",
    "buffer = ptan.experience.ExperienceReplayBuffer(\n",
    "    exp_source, buffer_size=params.replay_size)\n",
    "optimizer = optim.Adam(net.parameters(), lr = params.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16abe98c-a87e-444a-8f75-ee67702eb5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_batch(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    loss_v = common.calc_loss_dqn(batch, net, tgt_net.target_model,\n",
    "                                  gamma=params.gamma, device=device)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    epsilon_tracker.frame(engine.state.iteration)\n",
    "    if engine.state.iteration % params.target_net_sync == 0:\n",
    "        tgt_net.sync()\n",
    "    return {\n",
    "        \"loss\": loss_v.item(),\n",
    "        \"epsilon\": selector.epsilon,\n",
    "    }\n",
    "\n",
    "engine=Engine(process_batch)\n",
    "ptan_ignite.EndOfEpisodeHandler(exp_source, bound_avg_reward=15.0).attach(engine)\n",
    "ptan_ignite.EpisodeFPSHandler(fps_mul=n_envs).attach(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b3d4c6-6ebf-4749-8adf-11eb20a23045",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: reward=-21.0, steps=848, speed=0.000 frames/s, elapsed=0:02:19.094739\n",
      "Episode 2: reward=-20.0, steps=1048, speed=0.000 frames/s, elapsed=0:02:19.095739\n",
      "Episode 3: reward=-21.0, steps=788, speed=0.000 frames/s, elapsed=0:02:19.095739\n",
      "Episode 4: reward=-19.0, steps=992, speed=0.000 frames/s, elapsed=0:02:19.095739\n",
      "Episode 5: reward=-21.0, steps=834, speed=0.000 frames/s, elapsed=0:02:19.096739\n",
      "Episode 6: reward=-20.0, steps=922, speed=0.000 frames/s, elapsed=0:02:19.096739\n",
      "Episode 7: reward=-21.0, steps=994, speed=0.000 frames/s, elapsed=0:02:19.096739\n",
      "Episode 8: reward=-21.0, steps=940, speed=0.000 frames/s, elapsed=0:02:19.097782\n",
      "Episode 9: reward=-20.0, steps=864, speed=0.000 frames/s, elapsed=0:02:19.097782\n",
      "Episode 10: reward=-21.0, steps=937, speed=0.000 frames/s, elapsed=0:02:19.097782\n",
      "Episode 11: reward=-21.0, steps=879, speed=64.433 frames/s, elapsed=0:02:19.796381\n",
      "Episode 12: reward=-20.0, steps=973, speed=65.010 frames/s, elapsed=0:02:30.212696\n",
      "Episode 13: reward=-21.0, steps=794, speed=65.462 frames/s, elapsed=0:02:39.289950\n",
      "Episode 14: reward=-20.0, steps=999, speed=65.908 frames/s, elapsed=0:02:50.670387\n",
      "Episode 15: reward=-21.0, steps=879, speed=66.331 frames/s, elapsed=0:03:00.769875\n",
      "Episode 16: reward=-21.0, steps=834, speed=66.766 frames/s, elapsed=0:03:10.234381\n",
      "Episode 17: reward=-21.0, steps=876, speed=67.192 frames/s, elapsed=0:03:20.186270\n",
      "Episode 18: reward=-20.0, steps=925, speed=67.605 frames/s, elapsed=0:03:30.701096\n",
      "Episode 19: reward=-21.0, steps=865, speed=67.989 frames/s, elapsed=0:03:40.692552\n",
      "Episode 20: reward=-21.0, steps=775, speed=68.381 frames/s, elapsed=0:03:49.527109\n",
      "Episode 21: reward=-21.0, steps=886, speed=68.769 frames/s, elapsed=0:03:59.608144\n",
      "Episode 22: reward=-21.0, steps=756, speed=69.154 frames/s, elapsed=0:04:08.195524\n",
      "Episode 23: reward=-21.0, steps=789, speed=69.527 frames/s, elapsed=0:04:17.182729\n",
      "Episode 24: reward=-21.0, steps=969, speed=69.887 frames/s, elapsed=0:04:28.253737\n",
      "Episode 25: reward=-20.0, steps=835, speed=70.268 frames/s, elapsed=0:04:37.667074\n",
      "Episode 26: reward=-21.0, steps=965, speed=70.593 frames/s, elapsed=0:04:48.797100\n",
      "Episode 27: reward=-20.0, steps=896, speed=70.925 frames/s, elapsed=0:04:59.085725\n",
      "Episode 28: reward=-21.0, steps=850, speed=71.278 frames/s, elapsed=0:05:08.668271\n",
      "Episode 29: reward=-21.0, steps=942, speed=71.593 frames/s, elapsed=0:05:19.493501\n",
      "Episode 30: reward=-20.0, steps=1054, speed=72.002 frames/s, elapsed=0:05:30.969458\n",
      "Episode 31: reward=-21.0, steps=815, speed=72.295 frames/s, elapsed=0:05:40.351222\n",
      "Episode 32: reward=-19.0, steps=1048, speed=72.419 frames/s, elapsed=0:05:53.724867\n",
      "Episode 33: reward=-19.0, steps=916, speed=72.414 frames/s, elapsed=0:06:06.405873\n",
      "Episode 34: reward=-19.0, steps=979, speed=72.464 frames/s, elapsed=0:06:19.454918\n",
      "Episode 35: reward=-20.0, steps=891, speed=72.628 frames/s, elapsed=0:06:30.502250\n",
      "Episode 36: reward=-19.0, steps=940, speed=72.754 frames/s, elapsed=0:06:42.439976\n",
      "Episode 37: reward=-21.0, steps=1030, speed=72.914 frames/s, elapsed=0:06:55.181720\n",
      "Episode 38: reward=-20.0, steps=893, speed=73.143 frames/s, elapsed=0:07:05.780440\n",
      "Episode 39: reward=-21.0, steps=818, speed=73.333 frames/s, elapsed=0:07:15.651012\n",
      "Episode 40: reward=-20.0, steps=838, speed=73.557 frames/s, elapsed=0:07:25.587619\n",
      "Episode 41: reward=-19.0, steps=1135, speed=73.810 frames/s, elapsed=0:07:38.743452\n",
      "Episode 42: reward=-21.0, steps=820, speed=74.052 frames/s, elapsed=0:07:48.276756\n",
      "Episode 43: reward=-19.0, steps=1070, speed=74.293 frames/s, elapsed=0:08:00.714232\n",
      "Episode 44: reward=-21.0, steps=882, speed=74.525 frames/s, elapsed=0:08:10.984225\n",
      "Episode 45: reward=-20.0, steps=931, speed=74.743 frames/s, elapsed=0:08:21.867856\n",
      "Episode 46: reward=-20.0, steps=1005, speed=75.022 frames/s, elapsed=0:08:33.202338\n",
      "Episode 47: reward=-18.0, steps=1043, speed=75.321 frames/s, elapsed=0:08:44.807723\n",
      "Episode 48: reward=-20.0, steps=1053, speed=75.587 frames/s, elapsed=0:08:56.685967\n",
      "Episode 49: reward=-21.0, steps=973, speed=75.851 frames/s, elapsed=0:09:07.632602\n",
      "Episode 50: reward=-20.0, steps=1017, speed=76.099 frames/s, elapsed=0:09:19.160305\n",
      "Episode 51: reward=-21.0, steps=1087, speed=76.358 frames/s, elapsed=0:09:31.384087\n",
      "Episode 52: reward=-19.0, steps=1218, speed=76.604 frames/s, elapsed=0:09:45.125668\n",
      "Episode 53: reward=-20.0, steps=1077, speed=76.836 frames/s, elapsed=0:09:57.339997\n",
      "Episode 54: reward=-19.0, steps=1059, speed=77.062 frames/s, elapsed=0:10:09.351279\n",
      "Episode 55: reward=-21.0, steps=881, speed=77.267 frames/s, elapsed=0:10:19.420915\n",
      "Episode 56: reward=-21.0, steps=828, speed=77.516 frames/s, elapsed=0:10:28.649403\n",
      "Episode 57: reward=-20.0, steps=934, speed=77.752 frames/s, elapsed=0:10:39.131406\n",
      "Episode 58: reward=-20.0, steps=917, speed=77.956 frames/s, elapsed=0:10:49.529693\n",
      "Episode 59: reward=-17.0, steps=1355, speed=78.161 frames/s, elapsed=0:11:04.904526\n",
      "Episode 60: reward=-20.0, steps=1053, speed=78.385 frames/s, elapsed=0:11:16.687918\n",
      "Episode 61: reward=-21.0, steps=905, speed=78.566 frames/s, elapsed=0:11:27.049659\n",
      "Episode 62: reward=-21.0, steps=882, speed=78.760 frames/s, elapsed=0:11:37.045456\n",
      "Episode 63: reward=-21.0, steps=900, speed=78.940 frames/s, elapsed=0:11:47.296560\n",
      "Episode 64: reward=-19.0, steps=1146, speed=79.133 frames/s, elapsed=0:12:00.233557\n",
      "Episode 65: reward=-20.0, steps=1205, speed=79.328 frames/s, elapsed=0:12:13.766270\n",
      "Episode 66: reward=-21.0, steps=1076, speed=79.481 frames/s, elapsed=0:12:26.150173\n",
      "Episode 67: reward=-20.0, steps=906, speed=79.656 frames/s, elapsed=0:12:36.421017\n",
      "Episode 68: reward=-21.0, steps=1025, speed=79.830 frames/s, elapsed=0:12:48.030520\n",
      "Episode 69: reward=-20.0, steps=973, speed=80.006 frames/s, elapsed=0:12:58.997292\n",
      "Episode 70: reward=-20.0, steps=885, speed=80.174 frames/s, elapsed=0:13:09.011367\n",
      "Episode 71: reward=-19.0, steps=1028, speed=80.355 frames/s, elapsed=0:13:20.543600\n",
      "Episode 72: reward=-21.0, steps=928, speed=80.484 frames/s, elapsed=0:13:31.218848\n",
      "Episode 73: reward=-20.0, steps=1004, speed=80.641 frames/s, elapsed=0:13:42.600261\n",
      "Episode 74: reward=-21.0, steps=935, speed=80.811 frames/s, elapsed=0:13:53.063860\n",
      "Episode 75: reward=-20.0, steps=1032, speed=80.964 frames/s, elapsed=0:14:04.730077\n",
      "Episode 76: reward=-21.0, steps=785, speed=81.115 frames/s, elapsed=0:14:13.611914\n",
      "Episode 77: reward=-18.0, steps=1118, speed=81.264 frames/s, elapsed=0:14:26.247109\n",
      "Episode 78: reward=-20.0, steps=1073, speed=81.380 frames/s, elapsed=0:14:38.543723\n",
      "Episode 79: reward=-21.0, steps=848, speed=81.491 frames/s, elapsed=0:14:48.313205\n",
      "Episode 80: reward=-20.0, steps=895, speed=81.594 frames/s, elapsed=0:14:58.629605\n",
      "Episode 81: reward=-21.0, steps=878, speed=81.692 frames/s, elapsed=0:15:08.790767\n",
      "Episode 82: reward=-18.0, steps=1053, speed=81.838 frames/s, elapsed=0:15:20.625664\n",
      "Episode 83: reward=-20.0, steps=1127, speed=82.051 frames/s, elapsed=0:15:32.820842\n",
      "Episode 84: reward=-20.0, steps=995, speed=82.112 frames/s, elapsed=0:15:44.490813\n",
      "Episode 85: reward=-21.0, steps=967, speed=82.204 frames/s, elapsed=0:15:55.668612\n",
      "Episode 86: reward=-18.0, steps=1164, speed=82.289 frames/s, elapsed=0:16:09.131130\n",
      "Episode 87: reward=-20.0, steps=1181, speed=82.371 frames/s, elapsed=0:16:22.778431\n",
      "Episode 88: reward=-20.0, steps=943, speed=82.461 frames/s, elapsed=0:16:33.652132\n",
      "Episode 89: reward=-20.0, steps=1196, speed=82.541 frames/s, elapsed=0:16:47.466182\n",
      "Episode 90: reward=-21.0, steps=867, speed=82.612 frames/s, elapsed=0:16:57.535482\n",
      "Episode 91: reward=-20.0, steps=1127, speed=82.695 frames/s, elapsed=0:17:10.540036\n",
      "Episode 92: reward=-17.0, steps=1214, speed=82.777 frames/s, elapsed=0:17:24.538254\n",
      "Episode 93: reward=-20.0, steps=871, speed=82.850 frames/s, elapsed=0:17:34.601198\n",
      "Episode 94: reward=-20.0, steps=1091, speed=82.933 frames/s, elapsed=0:17:47.153090\n",
      "Episode 95: reward=-20.0, steps=1281, speed=82.985 frames/s, elapsed=0:18:02.128885\n",
      "Episode 96: reward=-19.0, steps=1272, speed=83.065 frames/s, elapsed=0:18:16.755235\n",
      "Episode 97: reward=-18.0, steps=1382, speed=83.140 frames/s, elapsed=0:18:32.649430\n",
      "Episode 98: reward=-20.0, steps=972, speed=83.214 frames/s, elapsed=0:18:43.843621\n",
      "Episode 99: reward=-21.0, steps=897, speed=83.280 frames/s, elapsed=0:18:54.214834\n",
      "Episode 100: reward=-21.0, steps=1024, speed=83.303 frames/s, elapsed=0:19:06.363334\n",
      "Episode 101: reward=-19.0, steps=1110, speed=83.365 frames/s, elapsed=0:19:19.211646\n",
      "Episode 102: reward=-20.0, steps=981, speed=83.426 frames/s, elapsed=0:19:30.560032\n",
      "Episode 103: reward=-21.0, steps=975, speed=83.494 frames/s, elapsed=0:19:41.791883\n",
      "Episode 104: reward=-18.0, steps=1409, speed=83.575 frames/s, elapsed=0:19:57.861573\n",
      "Episode 105: reward=-19.0, steps=1305, speed=83.623 frames/s, elapsed=0:20:13.045814\n",
      "Episode 106: reward=-18.0, steps=1062, speed=83.675 frames/s, elapsed=0:20:25.363126\n",
      "Episode 107: reward=-19.0, steps=1140, speed=83.761 frames/s, elapsed=0:20:38.321159\n",
      "Episode 108: reward=-16.0, steps=1614, speed=83.866 frames/s, elapsed=0:20:56.447705\n",
      "Episode 109: reward=-20.0, steps=1285, speed=83.936 frames/s, elapsed=0:21:11.181485\n",
      "Episode 110: reward=-19.0, steps=1481, speed=84.035 frames/s, elapsed=0:21:27.816368\n",
      "Episode 111: reward=-19.0, steps=1262, speed=84.113 frames/s, elapsed=0:21:42.180458\n",
      "Episode 112: reward=-20.0, steps=1204, speed=84.200 frames/s, elapsed=0:21:55.782919\n",
      "Episode 113: reward=-18.0, steps=1659, speed=84.261 frames/s, elapsed=0:22:14.791264\n",
      "Episode 114: reward=-20.0, steps=1135, speed=84.323 frames/s, elapsed=0:22:27.810886\n",
      "Episode 115: reward=-19.0, steps=1522, speed=84.403 frames/s, elapsed=0:22:45.032611\n",
      "Episode 116: reward=-20.0, steps=1328, speed=84.473 frames/s, elapsed=0:23:00.149245\n",
      "Episode 117: reward=-19.0, steps=1315, speed=84.550 frames/s, elapsed=0:23:15.027765\n",
      "Episode 118: reward=-21.0, steps=1374, speed=84.597 frames/s, elapsed=0:23:30.834160\n",
      "Episode 119: reward=-20.0, steps=1124, speed=84.658 frames/s, elapsed=0:23:43.674016\n",
      "Episode 120: reward=-18.0, steps=1260, speed=84.729 frames/s, elapsed=0:23:57.956490\n",
      "Episode 121: reward=-20.0, steps=1574, speed=84.810 frames/s, elapsed=0:24:15.662254\n",
      "Episode 122: reward=-18.0, steps=1352, speed=84.851 frames/s, elapsed=0:24:31.238551\n",
      "Episode 123: reward=-19.0, steps=1364, speed=84.917 frames/s, elapsed=0:24:46.721911\n",
      "Episode 124: reward=-21.0, steps=1202, speed=84.976 frames/s, elapsed=0:25:00.380232\n",
      "Episode 125: reward=-19.0, steps=1650, speed=85.034 frames/s, elapsed=0:25:19.154739\n",
      "Episode 126: reward=-19.0, steps=1342, speed=85.076 frames/s, elapsed=0:25:34.583045\n",
      "Episode 127: reward=-20.0, steps=1230, speed=85.125 frames/s, elapsed=0:25:48.631705\n",
      "Episode 128: reward=-18.0, steps=1662, speed=85.199 frames/s, elapsed=0:26:07.349392\n",
      "Episode 129: reward=-18.0, steps=1802, speed=85.250 frames/s, elapsed=0:26:27.863433\n",
      "Episode 130: reward=-16.0, steps=1776, speed=85.294 frames/s, elapsed=0:26:48.165443\n",
      "Episode 131: reward=-16.0, steps=1420, speed=85.305 frames/s, elapsed=0:27:04.735995\n",
      "Episode 132: reward=-21.0, steps=1431, speed=85.365 frames/s, elapsed=0:27:20.936901\n",
      "Episode 133: reward=-18.0, steps=1593, speed=85.437 frames/s, elapsed=0:27:38.847394\n",
      "Episode 134: reward=-13.0, steps=2180, speed=85.472 frames/s, elapsed=0:28:03.819022\n",
      "Episode 135: reward=-16.0, steps=1805, speed=85.374 frames/s, elapsed=0:28:26.236489\n",
      "Episode 136: reward=-20.0, steps=1423, speed=85.292 frames/s, elapsed=0:28:43.733432\n",
      "Episode 137: reward=-13.0, steps=1968, speed=85.275 frames/s, elapsed=0:29:07.037572\n",
      "Episode 138: reward=-20.0, steps=1313, speed=85.249 frames/s, elapsed=0:29:22.691685\n",
      "Episode 139: reward=-18.0, steps=1843, speed=85.311 frames/s, elapsed=0:29:43.533076\n",
      "Episode 140: reward=-14.0, steps=1950, speed=85.374 frames/s, elapsed=0:30:05.576089\n",
      "Episode 141: reward=-18.0, steps=1407, speed=85.442 frames/s, elapsed=0:30:21.425096\n",
      "Episode 142: reward=-19.0, steps=1395, speed=85.515 frames/s, elapsed=0:30:37.084906\n",
      "Episode 143: reward=-17.0, steps=1355, speed=85.586 frames/s, elapsed=0:30:52.309217\n",
      "Episode 144: reward=-16.0, steps=1965, speed=85.565 frames/s, elapsed=0:31:15.556957\n",
      "Episode 145: reward=-17.0, steps=1681, speed=85.647 frames/s, elapsed=0:31:34.296193\n",
      "Episode 146: reward=-14.0, steps=1901, speed=85.710 frames/s, elapsed=0:31:55.716915\n",
      "Episode 147: reward=-16.0, steps=2063, speed=85.756 frames/s, elapsed=0:32:19.158963\n",
      "Episode 148: reward=-19.0, steps=1257, speed=85.824 frames/s, elapsed=0:32:33.260934\n",
      "Episode 149: reward=-14.0, steps=2118, speed=85.878 frames/s, elapsed=0:32:57.181374\n",
      "Episode 150: reward=-18.0, steps=1667, speed=85.947 frames/s, elapsed=0:33:15.823663\n",
      "Episode 151: reward=-19.0, steps=1928, speed=85.977 frames/s, elapsed=0:33:37.882866\n",
      "Episode 152: reward=-20.0, steps=1457, speed=86.042 frames/s, elapsed=0:33:54.226915\n",
      "Episode 153: reward=-19.0, steps=2193, speed=86.077 frames/s, elapsed=0:34:19.198968\n",
      "Episode 154: reward=-19.0, steps=1888, speed=86.119 frames/s, elapsed=0:34:40.599367\n",
      "Episode 155: reward=-18.0, steps=1888, speed=86.176 frames/s, elapsed=0:35:01.812388\n",
      "Episode 156: reward=-18.0, steps=1701, speed=86.092 frames/s, elapsed=0:35:22.560605\n",
      "Episode 157: reward=-15.0, steps=1974, speed=85.881 frames/s, elapsed=0:35:48.694876\n",
      "Episode 158: reward=-19.0, steps=1567, speed=85.738 frames/s, elapsed=0:36:08.617593\n",
      "Episode 159: reward=-16.0, steps=1770, speed=85.603 frames/s, elapsed=0:36:31.025065\n",
      "Episode 160: reward=-12.0, steps=2498, speed=85.618 frames/s, elapsed=0:36:59.934665\n",
      "Episode 161: reward=-17.0, steps=1839, speed=85.682 frames/s, elapsed=0:37:20.640320\n",
      "Episode 162: reward=-16.0, steps=1604, speed=85.745 frames/s, elapsed=0:37:38.703522\n",
      "Episode 163: reward=-19.0, steps=1828, speed=85.777 frames/s, elapsed=0:37:59.626905\n",
      "Episode 164: reward=-14.0, steps=1793, speed=85.841 frames/s, elapsed=0:38:19.789872\n",
      "Episode 165: reward=-19.0, steps=1764, speed=85.888 frames/s, elapsed=0:38:39.793596\n",
      "Episode 166: reward=-13.0, steps=2239, speed=85.928 frames/s, elapsed=0:39:05.255125\n",
      "Episode 167: reward=-16.0, steps=2415, speed=85.992 frames/s, elapsed=0:39:32.344327\n",
      "Episode 168: reward=-16.0, steps=1929, speed=86.049 frames/s, elapsed=0:39:54.063798\n",
      "Episode 169: reward=-16.0, steps=1813, speed=86.090 frames/s, elapsed=0:40:14.657495\n",
      "Episode 170: reward=-11.0, steps=2549, speed=86.157 frames/s, elapsed=0:40:43.138608\n",
      "Episode 171: reward=-17.0, steps=2046, speed=86.197 frames/s, elapsed=0:41:06.344077\n",
      "Episode 172: reward=-21.0, steps=1240, speed=86.251 frames/s, elapsed=0:41:20.316509\n",
      "Episode 173: reward=-14.0, steps=1929, speed=86.315 frames/s, elapsed=0:41:41.888431\n",
      "Episode 174: reward=-15.0, steps=2368, speed=86.350 frames/s, elapsed=0:42:08.764430\n",
      "Episode 175: reward=-11.0, steps=2267, speed=86.394 frames/s, elapsed=0:42:34.370067\n",
      "Episode 176: reward=-15.0, steps=1852, speed=86.438 frames/s, elapsed=0:42:55.267219\n",
      "Episode 177: reward=-15.0, steps=2138, speed=86.476 frames/s, elapsed=0:43:19.475551\n",
      "Episode 178: reward=-18.0, steps=1714, speed=86.519 frames/s, elapsed=0:43:38.812079\n",
      "Episode 179: reward=-17.0, steps=1853, speed=86.546 frames/s, elapsed=0:43:59.912298\n",
      "Episode 180: reward=-13.0, steps=1959, speed=86.568 frames/s, elapsed=0:44:22.252383\n",
      "Episode 181: reward=-11.0, steps=2479, speed=86.603 frames/s, elapsed=0:44:50.312608\n",
      "Episode 182: reward=-12.0, steps=2320, speed=86.647 frames/s, elapsed=0:45:16.434664\n",
      "Episode 183: reward=-15.0, steps=1977, speed=86.683 frames/s, elapsed=0:45:38.787468\n",
      "Episode 184: reward=-14.0, steps=2714, speed=86.738 frames/s, elapsed=0:46:09.138729\n",
      "Episode 185: reward=-15.0, steps=2192, speed=86.769 frames/s, elapsed=0:46:33.982024\n",
      "Episode 186: reward=-17.0, steps=2042, speed=86.805 frames/s, elapsed=0:46:57.006597\n",
      "Episode 187: reward=-11.0, steps=2437, speed=86.851 frames/s, elapsed=0:47:24.387873\n",
      "Episode 188: reward=-14.0, steps=2260, speed=86.877 frames/s, elapsed=0:47:50.012555\n",
      "Episode 189: reward=-11.0, steps=2413, speed=86.908 frames/s, elapsed=0:48:17.291081\n",
      "Episode 190: reward=-12.0, steps=2188, speed=86.940 frames/s, elapsed=0:48:42.036318\n",
      "Episode 191: reward=-9.0, steps=2701, speed=86.976 frames/s, elapsed=0:49:12.452456\n",
      "Episode 192: reward=-11.0, steps=2094, speed=87.005 frames/s, elapsed=0:49:36.141314\n",
      "Episode 193: reward=-15.0, steps=2060, speed=87.020 frames/s, elapsed=0:49:59.624922\n",
      "Episode 194: reward=-16.0, steps=1757, speed=87.058 frames/s, elapsed=0:50:19.362965\n",
      "Episode 195: reward=-15.0, steps=1889, speed=87.083 frames/s, elapsed=0:50:40.766222\n",
      "Episode 196: reward=-15.0, steps=1717, speed=87.090 frames/s, elapsed=0:51:00.386508\n",
      "Episode 197: reward=-10.0, steps=2138, speed=87.106 frames/s, elapsed=0:51:24.721370\n",
      "Episode 198: reward=-15.0, steps=2194, speed=87.131 frames/s, elapsed=0:51:49.541265\n",
      "Episode 199: reward=-19.0, steps=1522, speed=87.141 frames/s, elapsed=0:52:06.938492\n",
      "Episode 200: reward=-16.0, steps=2127, speed=87.159 frames/s, elapsed=0:52:31.098697\n",
      "Episode 201: reward=-9.0, steps=2456, speed=87.188 frames/s, elapsed=0:52:58.782536\n",
      "Episode 202: reward=-14.0, steps=1882, speed=87.209 frames/s, elapsed=0:53:20.143082\n",
      "Episode 203: reward=-10.0, steps=2561, speed=87.251 frames/s, elapsed=0:53:48.789683\n",
      "Episode 204: reward=-11.0, steps=2853, speed=87.276 frames/s, elapsed=0:54:21.035758\n",
      "Episode 205: reward=-15.0, steps=2106, speed=87.314 frames/s, elapsed=0:54:44.650506\n",
      "Episode 206: reward=-2.0, steps=3642, speed=87.340 frames/s, elapsed=0:55:25.753375\n",
      "Episode 207: reward=-5.0, steps=3388, speed=87.374 frames/s, elapsed=0:56:03.822421\n",
      "Episode 208: reward=-13.0, steps=2414, speed=87.390 frames/s, elapsed=0:56:31.179244\n",
      "Episode 209: reward=-13.0, steps=2841, speed=87.413 frames/s, elapsed=0:57:03.267519\n",
      "Episode 210: reward=1.0, steps=3668, speed=87.409 frames/s, elapsed=0:57:45.330631\n",
      "Episode 211: reward=-12.0, steps=2782, speed=87.216 frames/s, elapsed=0:58:21.087620\n",
      "Episode 212: reward=3.0, steps=3510, speed=86.959 frames/s, elapsed=0:59:08.304085\n",
      "Episode 213: reward=-1.0, steps=3878, speed=86.679 frames/s, elapsed=1:00:01.468634\n",
      "Episode 214: reward=-2.0, steps=3973, speed=86.415 frames/s, elapsed=1:00:55.526947\n",
      "Episode 215: reward=1.0, steps=3602, speed=86.122 frames/s, elapsed=1:01:45.735603\n",
      "Episode 216: reward=9.0, steps=3084, speed=85.801 frames/s, elapsed=1:02:29.739769\n",
      "Episode 217: reward=-6.0, steps=3365, speed=85.641 frames/s, elapsed=1:03:12.993305\n",
      "Episode 218: reward=-3.0, steps=4360, speed=85.609 frames/s, elapsed=1:04:04.867881\n",
      "Episode 219: reward=5.0, steps=4114, speed=85.656 frames/s, elapsed=1:04:51.632745\n",
      "Episode 220: reward=4.0, steps=3756, speed=85.654 frames/s, elapsed=1:05:35.522854\n",
      "Episode 221: reward=1.0, steps=4098, speed=85.589 frames/s, elapsed=1:06:25.253776\n",
      "Episode 222: reward=1.0, steps=3680, speed=85.463 frames/s, elapsed=1:07:11.696110\n",
      "Episode 223: reward=4.0, steps=3849, speed=85.387 frames/s, elapsed=1:07:58.816689\n",
      "Episode 224: reward=5.0, steps=3721, speed=85.394 frames/s, elapsed=1:08:42.200061\n",
      "Episode 225: reward=12.0, steps=2793, speed=85.322 frames/s, elapsed=1:09:16.354805\n",
      "Episode 226: reward=8.0, steps=3509, speed=85.262 frames/s, elapsed=1:09:58.995897\n",
      "Episode 227: reward=6.0, steps=3013, speed=85.147 frames/s, elapsed=1:10:36.877131\n",
      "Episode 228: reward=9.0, steps=2961, speed=85.004 frames/s, elapsed=1:11:14.825140\n",
      "Episode 229: reward=10.0, steps=3359, speed=84.870 frames/s, elapsed=1:11:57.758818\n",
      "Episode 230: reward=17.0, steps=2143, speed=84.707 frames/s, elapsed=1:12:25.670500\n",
      "Episode 231: reward=16.0, steps=2027, speed=84.627 frames/s, elapsed=1:12:50.802715\n",
      "Episode 232: reward=16.0, steps=2207, speed=84.504 frames/s, elapsed=1:13:18.930775\n",
      "Episode 233: reward=10.0, steps=3069, speed=84.413 frames/s, elapsed=1:13:57.324002\n",
      "Episode 234: reward=15.0, steps=2227, speed=84.365 frames/s, elapsed=1:14:24.461654\n",
      "Episode 235: reward=13.0, steps=2487, speed=84.296 frames/s, elapsed=1:14:55.199676\n",
      "Episode 236: reward=17.0, steps=1954, speed=84.323 frames/s, elapsed=1:15:18.001652\n",
      "Episode 237: reward=13.0, steps=2236, speed=84.409 frames/s, elapsed=1:15:43.255263\n",
      "Episode 238: reward=20.0, steps=1881, speed=84.498 frames/s, elapsed=1:16:04.425919\n",
      "Episode 239: reward=18.0, steps=1903, speed=84.577 frames/s, elapsed=1:16:25.927770\n",
      "Episode 240: reward=18.0, steps=2064, speed=84.652 frames/s, elapsed=1:16:49.299172\n",
      "Episode 241: reward=15.0, steps=2480, speed=84.721 frames/s, elapsed=1:17:17.453873\n",
      "Episode 242: reward=17.0, steps=2305, speed=84.785 frames/s, elapsed=1:17:43.662220\n",
      "Episode 243: reward=17.0, steps=2303, speed=84.862 frames/s, elapsed=1:18:09.656382\n",
      "Episode 244: reward=19.0, steps=1956, speed=84.943 frames/s, elapsed=1:18:31.658746\n",
      "Episode 245: reward=12.0, steps=2732, speed=85.032 frames/s, elapsed=1:19:02.193797\n",
      "Episode 246: reward=13.0, steps=2503, speed=85.086 frames/s, elapsed=1:19:30.745745\n",
      "Episode 247: reward=19.0, steps=1777, speed=85.105 frames/s, elapsed=1:19:51.391136\n",
      "Episode 248: reward=16.0, steps=1926, speed=85.176 frames/s, elapsed=1:20:13.114505\n",
      "Episode 249: reward=19.0, steps=1819, speed=85.259 frames/s, elapsed=1:20:33.467897\n",
      "Episode 250: reward=17.0, steps=2385, speed=85.331 frames/s, elapsed=1:21:00.304527\n",
      "Episode 251: reward=13.0, steps=2878, speed=85.402 frames/s, elapsed=1:21:32.704895\n",
      "Episode 252: reward=17.0, steps=1995, speed=85.466 frames/s, elapsed=1:21:55.216879\n",
      "Episode 253: reward=18.0, steps=1918, speed=85.454 frames/s, elapsed=1:22:17.808230\n",
      "Episode 254: reward=19.0, steps=2054, speed=85.524 frames/s, elapsed=1:22:40.915979\n",
      "Episode 255: reward=17.0, steps=2273, speed=85.570 frames/s, elapsed=1:23:06.771059\n",
      "Episode 256: reward=21.0, steps=1770, speed=85.616 frames/s, elapsed=1:23:26.909645\n",
      "Episode 257: reward=19.0, steps=1762, speed=85.651 frames/s, elapsed=1:23:47.102364\n",
      "Episode 258: reward=19.0, steps=1831, speed=85.697 frames/s, elapsed=1:24:07.918121\n",
      "Episode 259: reward=19.0, steps=1827, speed=85.770 frames/s, elapsed=1:24:28.357905\n",
      "Episode 260: reward=17.0, steps=2181, speed=85.805 frames/s, elapsed=1:24:53.288421\n",
      "Episode 261: reward=10.0, steps=3302, speed=85.846 frames/s, elapsed=1:25:30.868934\n",
      "Episode 262: reward=15.0, steps=2461, speed=85.900 frames/s, elapsed=1:25:58.660787\n",
      "Episode 263: reward=20.0, steps=1746, speed=85.941 frames/s, elapsed=1:26:18.509100\n",
      "Episode 264: reward=14.0, steps=2226, speed=86.003 frames/s, elapsed=1:26:43.505132\n",
      "Episode 265: reward=20.0, steps=1667, speed=86.047 frames/s, elapsed=1:27:02.417857\n",
      "Episode 266: reward=20.0, steps=1669, speed=86.077 frames/s, elapsed=1:27:21.469489\n",
      "Episode 267: reward=19.0, steps=1738, speed=86.125 frames/s, elapsed=1:27:41.107252\n",
      "Episode 268: reward=17.0, steps=2253, speed=86.182 frames/s, elapsed=1:28:06.422598\n",
      "Episode 269: reward=19.0, steps=1977, speed=86.217 frames/s, elapsed=1:28:28.912374\n",
      "Episode 270: reward=16.0, steps=2262, speed=86.284 frames/s, elapsed=1:28:54.164592\n",
      "Episode 271: reward=14.0, steps=2464, speed=86.321 frames/s, elapsed=1:29:22.142627\n",
      "Episode 272: reward=19.0, steps=2037, speed=86.372 frames/s, elapsed=1:29:45.062315\n",
      "Episode 273: reward=20.0, steps=1675, speed=86.429 frames/s, elapsed=1:30:03.826812\n",
      "Episode 274: reward=18.0, steps=1966, speed=86.475 frames/s, elapsed=1:30:25.969454\n",
      "Episode 275: reward=20.0, steps=1808, speed=86.511 frames/s, elapsed=1:30:46.466541\n",
      "Episode 276: reward=19.0, steps=1789, speed=86.569 frames/s, elapsed=1:31:06.461795\n",
      "Episode 277: reward=18.0, steps=2276, speed=86.622 frames/s, elapsed=1:31:31.987664\n",
      "Episode 278: reward=20.0, steps=1762, speed=86.642 frames/s, elapsed=1:31:52.080800\n",
      "Episode 279: reward=18.0, steps=1786, speed=86.700 frames/s, elapsed=1:32:12.047277\n",
      "Episode 280: reward=21.0, steps=1755, speed=86.751 frames/s, elapsed=1:32:31.714873\n",
      "Episode 281: reward=18.0, steps=2019, speed=86.774 frames/s, elapsed=1:32:54.678304\n",
      "Episode 282: reward=18.0, steps=1941, speed=86.811 frames/s, elapsed=1:33:16.585917\n",
      "Episode 283: reward=11.0, steps=2615, speed=86.846 frames/s, elapsed=1:33:46.092846\n",
      "Episode 284: reward=14.0, steps=2414, speed=86.883 frames/s, elapsed=1:34:13.313218\n",
      "Episode 285: reward=15.0, steps=2432, speed=86.937 frames/s, elapsed=1:34:40.481766\n",
      "Episode 286: reward=19.0, steps=1960, speed=86.950 frames/s, elapsed=1:35:02.838462\n",
      "Episode 287: reward=18.0, steps=1928, speed=86.990 frames/s, elapsed=1:35:24.523406\n",
      "Episode 288: reward=15.0, steps=2182, speed=87.030 frames/s, elapsed=1:35:49.037673\n",
      "Episode 289: reward=21.0, steps=1637, speed=87.058 frames/s, elapsed=1:36:07.565522\n",
      "Episode 290: reward=18.0, steps=1799, speed=87.102 frames/s, elapsed=1:36:27.691723\n",
      "Episode 291: reward=14.0, steps=2440, speed=87.142 frames/s, elapsed=1:36:55.107176\n",
      "Episode 292: reward=19.0, steps=1824, speed=87.153 frames/s, elapsed=1:37:15.905015\n",
      "Episode 293: reward=14.0, steps=2306, speed=87.198 frames/s, elapsed=1:37:41.668213\n",
      "Episode 294: reward=15.0, steps=2542, speed=87.230 frames/s, elapsed=1:38:10.326045\n",
      "Episode 295: reward=16.0, steps=2270, speed=87.260 frames/s, elapsed=1:38:35.883977\n",
      "Episode 296: reward=20.0, steps=1812, speed=87.295 frames/s, elapsed=1:38:56.242259\n",
      "Episode 297: reward=19.0, steps=1852, speed=87.324 frames/s, elapsed=1:39:17.133277\n",
      "Episode 298: reward=20.0, steps=1665, speed=87.347 frames/s, elapsed=1:39:35.951016\n",
      "Episode 299: reward=20.0, steps=1898, speed=87.348 frames/s, elapsed=1:39:57.649115\n",
      "Episode 300: reward=17.0, steps=1974, speed=87.375 frames/s, elapsed=1:40:19.896338\n",
      "Episode 301: reward=16.0, steps=2294, speed=87.402 frames/s, elapsed=1:40:45.763348\n",
      "Episode 302: reward=16.0, steps=2572, speed=87.425 frames/s, elapsed=1:41:14.797920\n",
      "Episode 303: reward=16.0, steps=2297, speed=87.451 frames/s, elapsed=1:41:40.698311\n",
      "Episode 304: reward=19.0, steps=1773, speed=87.489 frames/s, elapsed=1:42:00.548196\n",
      "Episode 305: reward=20.0, steps=1724, speed=87.514 frames/s, elapsed=1:42:19.982155\n",
      "Episode 306: reward=18.0, steps=2110, speed=87.514 frames/s, elapsed=1:42:44.081103\n",
      "Episode 307: reward=17.0, steps=2065, speed=87.537 frames/s, elapsed=1:43:07.360699\n",
      "Episode 308: reward=18.0, steps=2075, speed=87.560 frames/s, elapsed=1:43:30.773241\n",
      "Episode 309: reward=19.0, steps=2061, speed=87.558 frames/s, elapsed=1:43:54.330042\n",
      "Episode 310: reward=20.0, steps=1846, speed=87.579 frames/s, elapsed=1:44:15.155998\n",
      "Episode 311: reward=17.0, steps=2165, speed=87.604 frames/s, elapsed=1:44:39.536964\n",
      "Episode 312: reward=19.0, steps=1727, speed=87.601 frames/s, elapsed=1:44:59.303491\n",
      "Episode 313: reward=18.0, steps=2205, speed=87.623 frames/s, elapsed=1:45:24.149637\n",
      "Episode 314: reward=19.0, steps=2047, speed=87.567 frames/s, elapsed=1:45:48.279231\n",
      "Episode 315: reward=20.0, steps=1934, speed=87.577 frames/s, elapsed=1:46:10.245383\n",
      "Episode 316: reward=16.0, steps=2313, speed=87.585 frames/s, elapsed=1:46:36.538156\n",
      "Episode 317: reward=20.0, steps=1775, speed=87.594 frames/s, elapsed=1:46:56.683581\n",
      "Episode 318: reward=17.0, steps=2146, speed=87.558 frames/s, elapsed=1:47:21.710664\n",
      "Episode 319: reward=14.0, steps=2398, speed=87.502 frames/s, elapsed=1:47:49.996744\n",
      "Episode 320: reward=13.0, steps=3477, speed=87.410 frames/s, elapsed=1:48:31.934907\n",
      "Episode 321: reward=20.0, steps=1674, speed=87.173 frames/s, elapsed=1:48:54.089287\n",
      "Episode 322: reward=14.0, steps=2593, speed=87.092 frames/s, elapsed=1:49:25.282672\n",
      "Episode 323: reward=14.0, steps=2536, speed=87.032 frames/s, elapsed=1:49:55.459990\n",
      "Episode 324: reward=19.0, steps=2165, speed=86.990 frames/s, elapsed=1:50:20.918627\n",
      "Episode 325: reward=21.0, steps=1934, speed=86.938 frames/s, elapsed=1:50:43.851885\n",
      "Episode 326: reward=15.0, steps=2616, speed=86.810 frames/s, elapsed=1:51:16.344248\n",
      "Episode 327: reward=14.0, steps=2357, speed=86.800 frames/s, elapsed=1:51:43.655173\n",
      "Episode 328: reward=16.0, steps=2749, speed=86.829 frames/s, elapsed=1:52:14.791155\n",
      "Episode 329: reward=17.0, steps=2453, speed=86.758 frames/s, elapsed=1:52:44.262120\n",
      "Episode 330: reward=11.0, steps=2607, speed=86.704 frames/s, elapsed=1:53:15.268803\n",
      "Episode 331: reward=16.0, steps=2129, speed=86.689 frames/s, elapsed=1:53:40.020985\n",
      "Episode 332: reward=7.0, steps=3694, speed=86.715 frames/s, elapsed=1:54:22.031947\n",
      "Episode 333: reward=16.0, steps=2275, speed=86.671 frames/s, elapsed=1:54:48.943254\n",
      "Episode 334: reward=13.0, steps=2459, speed=86.592 frames/s, elapsed=1:55:18.680472\n",
      "Episode 335: reward=18.0, steps=2304, speed=86.491 frames/s, elapsed=1:55:46.936891\n",
      "Episode 336: reward=17.0, steps=2216, speed=86.398 frames/s, elapsed=1:56:13.982487\n",
      "Episode 337: reward=18.0, steps=1963, speed=86.291 frames/s, elapsed=1:56:38.220913\n",
      "Episode 338: reward=17.0, steps=2114, speed=86.166 frames/s, elapsed=1:57:04.613630\n",
      "Episode 339: reward=16.0, steps=2214, speed=86.092 frames/s, elapsed=1:57:31.457386\n",
      "Episode 340: reward=19.0, steps=2214, speed=86.082 frames/s, elapsed=1:57:57.332985\n",
      "Episode 341: reward=16.0, steps=2429, speed=86.076 frames/s, elapsed=1:58:25.663336\n",
      "Episode 342: reward=19.0, steps=1898, speed=86.073 frames/s, elapsed=1:58:47.763708\n",
      "Episode 343: reward=19.0, steps=1875, speed=85.985 frames/s, elapsed=1:59:10.710983\n",
      "Episode 344: reward=18.0, steps=2050, speed=85.949 frames/s, elapsed=1:59:35.059043\n",
      "Episode 345: reward=19.0, steps=2070, speed=85.989 frames/s, elapsed=1:59:58.595141\n",
      "Episode 346: reward=15.0, steps=2244, speed=86.020 frames/s, elapsed=2:00:24.230666\n",
      "Episode 347: reward=18.0, steps=2026, speed=86.070 frames/s, elapsed=2:00:47.095721\n",
      "Episode 348: reward=14.0, steps=2538, speed=86.109 frames/s, elapsed=2:01:15.938018\n",
      "Episode 349: reward=18.0, steps=1973, speed=86.154 frames/s, elapsed=2:01:38.272946\n",
      "Episode 350: reward=19.0, steps=1880, speed=86.208 frames/s, elapsed=2:01:59.448852\n",
      "Episode 351: reward=21.0, steps=1755, speed=86.238 frames/s, elapsed=2:02:19.453627\n",
      "Episode 352: reward=15.0, steps=2558, speed=86.272 frames/s, elapsed=2:02:48.520541\n",
      "Episode 353: reward=17.0, steps=2041, speed=86.319 frames/s, elapsed=2:03:11.577666\n",
      "Episode 354: reward=19.0, steps=1851, speed=86.327 frames/s, elapsed=2:03:32.921213\n",
      "Episode 355: reward=11.0, steps=2850, speed=86.364 frames/s, elapsed=2:04:05.242519\n",
      "Episode 356: reward=14.0, steps=2644, speed=86.395 frames/s, elapsed=2:04:35.302147\n",
      "Episode 357: reward=19.0, steps=1785, speed=86.437 frames/s, elapsed=2:04:55.472379\n",
      "Episode 358: reward=14.0, steps=2592, speed=86.475 frames/s, elapsed=2:05:24.812915\n",
      "Episode 359: reward=18.0, steps=1987, speed=86.493 frames/s, elapsed=2:05:47.554016\n",
      "Episode 360: reward=13.0, steps=2870, speed=86.522 frames/s, elapsed=2:06:20.194121\n",
      "Episode 361: reward=17.0, steps=2212, speed=86.532 frames/s, elapsed=2:06:45.593297\n",
      "Episode 362: reward=19.0, steps=1966, speed=86.571 frames/s, elapsed=2:07:07.839037\n",
      "Game solved in 2:07:07.839037, after 362 episodes and 215170 iterations!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 215170\n",
       "\tepoch: 1\n",
       "\tepoch_length: <class 'NoneType'>\n",
       "\tmax_epochs: 1\n",
       "\toutput: <class 'dict'>\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'generator'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>\n",
       "\tepisode: 362\n",
       "\tepisode_reward: 19.0\n",
       "\tepisode_steps: 1966"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@engine.on(ptan_ignite.EpisodeEvents.EPISODE_COMPLETED)\n",
    "def episode_completed(trainer: Engine):\n",
    "    print(\"Episode %d: reward=%s, steps=%s, speed=%.3f frames/s, elapsed=%s\" % (\n",
    "        trainer.state.episode, trainer.state.episode_reward,\n",
    "        trainer.state.episode_steps, trainer.state.metrics.get('avg_fps', 0),\n",
    "        timedelta(seconds=trainer.state.metrics.get('time_passed', 0))))\n",
    "    \n",
    "@engine.on(ptan_ignite.EpisodeEvents.BOUND_REWARD_REACHED)\n",
    "def game_solved(trainer: Engine):\n",
    "    print(\"Game solved in %s, after %d episodes and %d iterations!\" % (\n",
    "        timedelta(seconds=trainer.state.metrics['time_passed']),\n",
    "        trainer.state.episode, trainer.state.iteration))\n",
    "    trainer.should_terminate = True\n",
    "    \n",
    "logdir = f\"runs/{datetime.now().minute}-{params.run_name}-{NAME}\"\n",
    "tb = tb_logger.TensorboardLogger(log_dir=logdir)\n",
    "RunningAverage(output_transform=lambda v: v['loss']).attach(engine, \"avg_loss\")\n",
    "\n",
    "episode_handler = tb_logger.OutputHandler(tag='episodes', metric_names=['reward', 'steps', 'avg_reward'])\n",
    "tb.attach(engine, log_handler=episode_handler, event_name=ptan_ignite.EpisodeEvents.EPISODE_COMPLETED)\n",
    "\n",
    "# writing to tensorboard every 100 iterations\n",
    "ptan_ignite.PeriodicEvents().attach(engine)\n",
    "handler = tb_logger.OutputHandler(tag=\"train\", metric_names=['avg_loss', 'avg_fps'],\n",
    "                                  output_transform=lambda a: a)\n",
    "tb.attach(engine, log_handler=handler, event_name=ptan_ignite.PeriodEvents.ITERS_100_COMPLETED)\n",
    "\n",
    "engine.run(batch_generator(buffer, params.replay_initial, params.batch_size, n_envs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89bd6d-bd8d-4530-aba2-2347a61b6afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprl",
   "language": "python",
   "name": "deeprl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
